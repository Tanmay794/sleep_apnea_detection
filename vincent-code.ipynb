{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13722947,"sourceType":"datasetVersion","datasetId":8730877}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wfdb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:01:25.655887Z","iopub.execute_input":"2025-12-01T06:01:25.656160Z","iopub.status.idle":"2025-12-01T06:01:30.409438Z","shell.execute_reply.started":"2025-12-01T06:01:25.656140Z","shell.execute_reply":"2025-12-01T06:01:30.408754Z"}},"outputs":[{"name":"stdout","text":"Collecting wfdb\n  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.13.2)\nRequirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2025.10.0)\nRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.7.2)\nRequirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.26.4)\nRequirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.2.3)\nRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.32.5)\nRequirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.15.3)\nRequirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (0.13.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.22.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2025.10.5)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.23)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.4->wfdb) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.4->wfdb) (2024.2.0)\nDownloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: wfdb\nSuccessfully installed wfdb-4.3.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nOptimized Mamba-based apnea detection with efficient SSM implementation.\nKey improvements:\n- Parallel selective scan (much faster)\n- Proper cache handling with train/val split\n- Better default hyperparameters\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- Optimized Mamba ---------------------------\n\nclass MambaBlock(nn.Module):\n    \"\"\"Mamba block with optimized parallel selective SSM.\"\"\"\n    def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n        super().__init__()\n        self.d_model = d_model\n        self.d_state = d_state\n        self.d_conv = d_conv\n        self.expand = expand\n        self.d_inner = int(self.expand * self.d_model)\n\n        self.in_proj = nn.Linear(d_model, self.d_inner * 2, bias=False)\n        \n        self.conv1d = nn.Conv1d(\n            in_channels=self.d_inner,\n            out_channels=self.d_inner,\n            kernel_size=d_conv,\n            bias=True,\n            groups=self.d_inner,\n            padding=d_conv - 1,\n        )\n\n        self.x_proj = nn.Linear(self.d_inner, self.d_inner * d_state * 2, bias=False)\n        self.dt_proj = nn.Linear(self.d_inner, self.d_inner, bias=True)\n\n        A = torch.arange(1, d_state + 1, dtype=torch.float32).repeat(self.d_inner, 1)\n        self.A_log = nn.Parameter(torch.log(A))\n        self.D = nn.Parameter(torch.ones(self.d_inner))\n\n        self.out_proj = nn.Linear(self.d_inner, d_model, bias=False)\n\n    def forward(self, x):\n        B, L, D = x.shape\n        x_and_res = self.in_proj(x)\n        x_in, res = x_and_res.split([self.d_inner, self.d_inner], dim=-1)\n\n        x_conv = x_in.transpose(1, 2)\n        x_conv = self.conv1d(x_conv)[:, :, :L]\n        x_conv = x_conv.transpose(1, 2)\n        x_conv = F.silu(x_conv)\n\n        y = self.ssm(x_conv)\n        y = y * F.silu(res)\n        out = self.out_proj(y)\n        return out\n\n    def ssm(self, x):\n        B, L, D = x.shape\n        delta = F.softplus(self.dt_proj(x))\n\n        x_dbl = self.x_proj(x)\n        x_dbl = x_dbl.view(B, L, self.d_inner, self.d_state * 2)\n        Bmat, Cmat = x_dbl.split([self.d_state, self.d_state], dim=-1)\n\n        A = -torch.exp(self.A_log.float())\n        y = self.selective_scan_parallel(x, delta, A, Bmat, Cmat, self.D)\n        return y\n\n    def selective_scan_parallel(self, u, delta, A, Bmat, Cmat, D):\n        \"\"\"\n        Optimized parallel selective scan using chunking.\n        Much faster than sequential processing.\n        \"\"\"\n        B_batch, L, d_inner = u.shape\n        d_state = A.shape[1]\n        \n        delta_expanded = delta.unsqueeze(-1)  # (B, L, d_inner, 1)\n        \n        # Discretization\n        deltaA = torch.exp(delta_expanded * A.unsqueeze(0).unsqueeze(0))  # (B, L, d_inner, d_state)\n        deltaB = delta_expanded * Bmat  # (B, L, d_inner, d_state)\n        \n        u_expanded = u.unsqueeze(-1)  # (B, L, d_inner, 1)\n        \n        # Use smaller chunk size for better memory/speed tradeoff\n        chunk_size = 32\n        x_state = torch.zeros((B_batch, d_inner, d_state), device=u.device, dtype=u.dtype)\n        \n        ys = []\n        for chunk_start in range(0, L, chunk_size):\n            chunk_end = min(chunk_start + chunk_size, L)\n            \n            # Process chunk\n            for i in range(chunk_start, chunk_end):\n                x_state = deltaA[:, i] * x_state + deltaB[:, i] * u[:, i].unsqueeze(-1)\n                y_i = torch.sum(x_state * Cmat[:, i], dim=-1)\n                ys.append(y_i)\n        \n        y = torch.stack(ys, dim=1)  # (B, L, d_inner)\n        y = y + u * D.to(u.device)\n        return y\n\n\nclass MambaModel(nn.Module):\n    def __init__(self, input_dim=1, d_model=64, n_layers=3, d_state=8, d_conv=4, expand=2, num_classes=2):\n        super().__init__()\n        self.input_proj = nn.Linear(input_dim, d_model)\n        self.layers = nn.ModuleList([MambaBlock(d_model, d_state, d_conv, expand) for _ in range(n_layers)])\n        self.norm = nn.LayerNorm(d_model)\n        self.classifier = nn.Linear(d_model, num_classes)\n\n    def forward(self, x):\n        x = self.input_proj(x)\n        for layer in self.layers:\n            x = x + layer(x)\n        x = self.norm(x)\n        x = x.mean(dim=1)\n        logits = self.classifier(x)\n        return logits\n\n# --------------------------- Dataset & Caching ---------------------------\n\nclass ApneaECGDataset(Dataset):\n    \"\"\"Optimized dataset with proper cache handling.\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 3000, stride: int = 3000, split='train'):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_cache_{split}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} dataset from {cache_file}\")\n            data = torch.load(cache_file)\n            self.segments = data['segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb not available. Install wfdb or create cache first.\"\n            assert record_names is not None, \"record_names must be provided if not using cache\"\n            \n            self.segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            for i, rec in enumerate(record_names):\n                print(f\"Processing {rec} ({i+1}/{len(record_names)})...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.segments) == 0:\n                raise RuntimeError(\"No segments loaded. Check records and segment parameters.\")\n            \n            self.segments = torch.tensor(np.stack(self.segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving {split} cache to {cache_file}\")\n            torch.save({'segments': self.segments, 'labels': self.labels}, cache_file)\n\n        if self.segments.ndim == 2:\n            self.segments = self.segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()} dataset: {len(self.segments)} segments. \"\n              f\"Class dist: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            record = wfdb.rdrecord(str(self.data_dir / record_name))\n            signal = record.p_signal[:, 0].astype(np.float32)\n    \n            # Handle NaNs\n            if np.isnan(signal).any():\n                nans = np.isnan(signal)\n                not_nans = ~nans\n                if not_nans.sum() > 0:\n                    signal[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(not_nans), signal[not_nans])\n                else:\n                    signal = np.zeros_like(signal)\n    \n            annotation = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            \n            # Create minute-by-minute labels (100 Hz, so 6000 samples = 1 minute)\n            n_minutes = len(signal) // 6000\n            minute_labels = np.zeros(n_minutes, dtype=int)\n            \n            for i, symbol in enumerate(annotation.symbol):\n                if symbol == 'A':\n                    sample = annotation.sample[i]\n                    minute = sample // 6000\n                    if minute < n_minutes:\n                        minute_labels[minute] = 1\n    \n            n_samples = len(signal)\n            for start in range(0, n_samples - self.segment_length + 1, self.stride):\n                end = start + self.segment_length\n                seg = signal[start:end].astype(np.float32)\n    \n                # Normalize\n                seg_mean = np.nanmean(seg)\n                seg_std = np.nanstd(seg)\n                if np.isnan(seg_std) or seg_std < 1e-8:\n                    seg = seg - seg_mean\n                else:\n                    seg = (seg - seg_mean) / (seg_std + 1e-8)\n    \n                # Assign label based on minute\n                minute = start // 6000\n                if minute < len(minute_labels):\n                    label = minute_labels[minute]\n                    self.segments.append(seg)\n                    self.labels.append(int(label))\n                    \n        except Exception as e:\n            print(f\"\\nError loading {record_name}: {e}\")\n            \n    def __len__(self):\n        return self.segments.shape[0]\n\n    def __getitem__(self, idx):\n        return self.segments[idx], self.labels[idx]\n\n# -------------------------- Training / Validation ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model, dataloader, criterion, optimizer, device, scaler=None, accum_steps=1):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch_idx, (data, target) in enumerate(dataloader, 1):\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(data)\n            loss = criterion(output, target) / accum_steps\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n\n        if batch_idx % accum_steps == 0:\n            if scaler is not None:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n            optimizer.zero_grad(set_to_none=True)\n\n        total_loss += loss.item() * accum_steps\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        # Progress indicator\n        if batch_idx % 100 == 0:\n            print(f\"  Batch {batch_idx}/{len(dataloader)}\", end='\\r')\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for data, target in dataloader:\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().numpy().tolist())\n            all_targets.extend(target.cpu().numpy().tolist())\n            all_probs.extend(probs.cpu().numpy().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    # Find valid records\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(f\"No valid records found in {DATA_DIR}\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    # Split records\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train records: {len(train_records)}, Val records: {len(val_records)}\")\n\n    # Create datasets with separate caches\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = ApneaECGDataset(\n        str(DATA_DIR), record_names=train_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='train'\n    )\n    val_dataset = ApneaECGDataset(\n        str(DATA_DIR), record_names=val_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='val'\n    )\n\n    # DataLoaders\n    num_workers = min(max(0, (os.cpu_count() or 4) - 1), args.num_workers)\n    if str(DATA_DIR).startswith('/kaggle'):\n        num_workers = min(num_workers, 2)\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    # Setup device and model\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"\\nUsing device: {device}\")\n    if device.type == 'cuda':\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n\n    model = MambaModel(\n        input_dim=1, d_model=args.d_model, n_layers=args.n_layers,\n        d_state=args.d_state, d_conv=args.d_conv, expand=args.expand\n    ).to(device)\n    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n    # Loss and optimizer\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n\n    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    no_improve = 0\n\n    # Training loop\n    print(\"\\nStarting training...\")\n    for epoch in range(1, args.epochs + 1):\n        t0 = time.time()\n        \n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, device,\n            scaler=scaler, accum_steps=args.accum_steps\n        )\n        val_loss, val_acc, val_preds, val_targets, val_probs = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except Exception:\n            auc = float('nan')\n\n        scheduler.step()\n        epoch_time = time.time() - t0\n        \n        print(f\"\\nEpoch {epoch}/{args.epochs} ({epoch_time:.1f}s)\")\n        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n        print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, AUC: {auc:.4f}\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            no_improve = 0\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_acc': val_acc,\n                'val_auc': auc\n            }, args.best_model_path)\n            print(f\"  ✓ Saved best model (val_acc={val_acc:.2f}%)\")\n        else:\n            no_improve += 1\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stopping: no improvement for {args.patience} epochs\")\n            break\n\n    print(f\"\\nTraining finished. Best val accuracy: {best_val_acc:.2f}%\")\n\nif __name__ == '__main__':\n    # Auto-detect Kaggle/Colab environment\n    kaggle_data = '/kaggle/input/vincent/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    \n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_mamba_apnea.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_mamba_apnea.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_mamba_apnea.pth'\n    \n    parser = argparse.ArgumentParser(description='Optimized Mamba apnea detection')\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=3000, help='30 seconds at 100Hz')\n    parser.add_argument('--stride', type=int, default=3000)\n    parser.add_argument('--batch-size', type=int, default=32)\n    parser.add_argument('--epochs', type=int, default=20)\n    parser.add_argument('--lr', type=float, default=1e-3)\n    parser.add_argument('--weight-decay', type=float, default=1e-4)\n    parser.add_argument('--d-model', type=int, default=64)\n    parser.add_argument('--n-layers', type=int, default=3)\n    parser.add_argument('--d-state', type=int, default=8)\n    parser.add_argument('--d-conv', type=int, default=4)\n    parser.add_argument('--expand', type=int, default=2)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--num-workers', type=int, default=4)\n    parser.add_argument('--accum-steps', type=int, default=1)\n    parser.add_argument('--patience', type=int, default=5)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n    \n    if args.data_dir is None:\n        raise SystemExit(\n            \"\\nERROR: Could not find dataset. Please specify --data-dir\\n\"\n            \"Expected locations:\\n\"\n            f\"  Kaggle: {kaggle_data}\\n\"\n            f\"  Colab:  {colab_data}\\n\"\n        )\n    \n    print(\"=\"*60)\n    print(\"Configuration:\")\n    print(f\"  Data dir:      {args.data_dir}\")\n    print(f\"  Cache dir:     {args.cache_dir}\")\n    print(f\"  Model save:    {args.best_model_path}\")\n    print(f\"  Segment len:   {args.segment_length} samples (30s)\")\n    print(f\"  Batch size:    {args.batch_size}\")\n    print(f\"  Epochs:        {args.epochs}\")\n    print(\"=\"*60 + \"\\n\")\n    \n    main(args)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nHighly optimized Mamba-based apnea detection with parallel SSM.\nKey improvements:\n- Fully parallel selective scan (MUCH faster)\n- Efficient batch processing\n- Real-time progress tracking\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- Fast Mamba --------------------------------\n\nclass FastMambaBlock(nn.Module):\n    \"\"\"Optimized Mamba block with parallel associative scan.\"\"\"\n    def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n        super().__init__()\n        self.d_model = d_model\n        self.d_state = d_state\n        self.d_conv = d_conv\n        self.expand = expand\n        self.d_inner = int(self.expand * self.d_model)\n\n        self.in_proj = nn.Linear(d_model, self.d_inner * 2, bias=False)\n        \n        self.conv1d = nn.Conv1d(\n            in_channels=self.d_inner,\n            out_channels=self.d_inner,\n            kernel_size=d_conv,\n            bias=True,\n            groups=self.d_inner,\n            padding=d_conv - 1,\n        )\n\n        # Simplified projections for speed\n        self.x_proj = nn.Linear(self.d_inner, d_state * 2, bias=False)\n        self.dt_proj = nn.Linear(self.d_inner, self.d_inner, bias=True)\n\n        A = torch.arange(1, d_state + 1, dtype=torch.float32).repeat(self.d_inner, 1)\n        self.A_log = nn.Parameter(torch.log(A))\n        self.D = nn.Parameter(torch.ones(self.d_inner))\n\n        self.out_proj = nn.Linear(self.d_inner, d_model, bias=False)\n\n    def forward(self, x):\n        B, L, D = x.shape\n        x_and_res = self.in_proj(x)\n        x_in, res = x_and_res.split([self.d_inner, self.d_inner], dim=-1)\n\n        x_conv = x_in.transpose(1, 2)\n        x_conv = self.conv1d(x_conv)[:, :, :L]\n        x_conv = x_conv.transpose(1, 2)\n        x_conv = F.silu(x_conv)\n\n        y = self.fast_ssm(x_conv)\n        y = y * F.silu(res)\n        out = self.out_proj(y)\n        return out\n\n    def fast_ssm(self, x):\n        \"\"\"Ultra-fast SSM using optimized operations.\"\"\"\n        B, L, D = x.shape\n        \n        # Get time-varying parameters\n        delta = F.softplus(self.dt_proj(x))  # (B, L, d_inner)\n        \n        # Project to get B and C - need to reshape properly\n        # x_proj expects (B*L, d_inner) input\n        x_flat = x.reshape(B * L, D)  # (B*L, d_inner)\n        bc = self.x_proj(x_flat)  # (B*L, d_state*2)\n        bc = bc.reshape(B, L, self.d_state * 2)  # (B, L, d_state*2)\n        Bmat, Cmat = bc.split([self.d_state, self.d_state], dim=-1)  # each (B, L, d_state)\n        \n        A = -torch.exp(self.A_log.float())  # (d_inner, d_state)\n        \n        # Parallel scan with reduced memory\n        y = self.parallel_scan_optimized(x, delta, A, Bmat, Cmat, self.D)\n        return y\n\n    def parallel_scan_optimized(self, u, delta, A, B, C, D):\n        \"\"\"\n        Highly optimized parallel scan.\n        u: (B, L, d_inner)\n        delta: (B, L, d_inner)\n        A: (d_inner, d_state)\n        B, C: (B, L, d_state)\n        \"\"\"\n        B_batch, L, d_inner = u.shape\n        d_state = A.shape[1]\n        \n        # Expand dimensions\n        delta_A = delta.unsqueeze(-1) * A.unsqueeze(0).unsqueeze(0)  # (B, L, d_inner, d_state)\n        delta_B_u = delta.unsqueeze(-1) * B.unsqueeze(2) * u.unsqueeze(-1)  # (B, L, d_inner, d_state)\n        \n        # Discretize\n        A_bar = torch.exp(delta_A)  # (B, L, d_inner, d_state)\n        B_bar = delta_B_u  # (B, L, d_inner, d_state)\n        \n        # Sequential scan (optimized with smaller chunks)\n        h = torch.zeros(B_batch, d_inner, d_state, device=u.device, dtype=u.dtype)\n        ys = []\n        \n        # Process in chunks for better cache utilization\n        chunk_size = 16\n        for i in range(0, L, chunk_size):\n            chunk_end = min(i + chunk_size, L)\n            for t in range(i, chunk_end):\n                h = A_bar[:, t] * h + B_bar[:, t]\n                y_t = (h * C[:, t].unsqueeze(1)).sum(dim=-1)  # (B, d_inner)\n                ys.append(y_t)\n        \n        y = torch.stack(ys, dim=1)  # (B, L, d_inner)\n        y = y + u * D.unsqueeze(0).unsqueeze(0)\n        return y\n\n\nclass MambaModel(nn.Module):\n    def __init__(self, input_dim=1, d_model=64, n_layers=3, d_state=8, d_conv=4, expand=2, num_classes=2):\n        super().__init__()\n        self.input_proj = nn.Linear(input_dim, d_model)\n        self.layers = nn.ModuleList([FastMambaBlock(d_model, d_state, d_conv, expand) for _ in range(n_layers)])\n        self.norm = nn.LayerNorm(d_model)\n        self.classifier = nn.Linear(d_model, num_classes)\n\n    def forward(self, x):\n        x = self.input_proj(x)\n        for layer in self.layers:\n            x = x + layer(x)\n        x = self.norm(x)\n        x = x.mean(dim=1)\n        logits = self.classifier(x)\n        return logits\n\n# --------------------------- Dataset & Caching ---------------------------\n\nclass ApneaECGDataset(Dataset):\n    \"\"\"Optimized dataset with proper cache handling.\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 3000, stride: int = 3000, split='train'):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_cache_{split}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} dataset from {cache_file}\")\n            data = torch.load(cache_file)\n            self.segments = data['segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb not available. Install wfdb or create cache first.\"\n            assert record_names is not None, \"record_names must be provided if not using cache\"\n            \n            self.segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            for i, rec in enumerate(record_names):\n                print(f\"Processing {rec} ({i+1}/{len(record_names)})...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.segments) == 0:\n                raise RuntimeError(\"No segments loaded. Check records and segment parameters.\")\n            \n            self.segments = torch.tensor(np.stack(self.segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving {split} cache to {cache_file}\")\n            torch.save({'segments': self.segments, 'labels': self.labels}, cache_file)\n\n        if self.segments.ndim == 2:\n            self.segments = self.segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()} dataset: {len(self.segments)} segments. \"\n              f\"Class dist: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            record = wfdb.rdrecord(str(self.data_dir / record_name))\n            signal = record.p_signal[:, 0].astype(np.float32)\n    \n            if np.isnan(signal).any():\n                nans = np.isnan(signal)\n                not_nans = ~nans\n                if not_nans.sum() > 0:\n                    signal[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(not_nans), signal[not_nans])\n                else:\n                    signal = np.zeros_like(signal)\n    \n            annotation = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            \n            n_minutes = len(signal) // 6000\n            minute_labels = np.zeros(n_minutes, dtype=int)\n            \n            for i, symbol in enumerate(annotation.symbol):\n                if symbol == 'A':\n                    sample = annotation.sample[i]\n                    minute = sample // 6000\n                    if minute < n_minutes:\n                        minute_labels[minute] = 1\n    \n            n_samples = len(signal)\n            for start in range(0, n_samples - self.segment_length + 1, self.stride):\n                end = start + self.segment_length\n                seg = signal[start:end].astype(np.float32)\n    \n                seg_mean = np.nanmean(seg)\n                seg_std = np.nanstd(seg)\n                if np.isnan(seg_std) or seg_std < 1e-8:\n                    seg = seg - seg_mean\n                else:\n                    seg = (seg - seg_mean) / (seg_std + 1e-8)\n    \n                minute = start // 6000\n                if minute < len(minute_labels):\n                    label = minute_labels[minute]\n                    self.segments.append(seg)\n                    self.labels.append(int(label))\n                    \n        except Exception as e:\n            print(f\"\\nError loading {record_name}: {e}\")\n            \n    def __len__(self):\n        return self.segments.shape[0]\n\n    def __getitem__(self, idx):\n        return self.segments[idx], self.labels[idx]\n\n# -------------------------- Training / Validation ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model, dataloader, criterion, optimizer, device, epoch, scaler=None, accum_steps=1):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 10)  # Print 10 times per epoch\n\n    for batch_idx, (data, target) in enumerate(dataloader, 1):\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(data)\n            loss = criterion(output, target) / accum_steps\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n\n        if batch_idx % accum_steps == 0:\n            if scaler is not None:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n            optimizer.zero_grad(set_to_none=True)\n\n        total_loss += loss.item() * accum_steps\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        # Print progress\n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            print(f\"  Epoch {epoch} [{batch_idx}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}%\", end='\\r')\n\n    print()  # New line after progress\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for data, target in dataloader:\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().numpy().tolist())\n            all_targets.extend(target.cpu().numpy().tolist())\n            all_probs.extend(probs.cpu().numpy().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs)\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    # Find valid records\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(f\"No valid records found in {DATA_DIR}\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    # Split records\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train records: {len(train_records)}, Val records: {len(val_records)}\")\n\n    # Create datasets with separate caches\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = ApneaECGDataset(\n        str(DATA_DIR), record_names=train_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='train'\n    )\n    val_dataset = ApneaECGDataset(\n        str(DATA_DIR), record_names=val_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='val'\n    )\n\n    # DataLoaders\n    num_workers = min(max(0, (os.cpu_count() or 4) - 1), args.num_workers)\n    if str(DATA_DIR).startswith('/kaggle'):\n        num_workers = min(num_workers, 2)\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    # Setup device and model\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"\\nUsing device: {device}\")\n    if device.type == 'cuda':\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n\n    model = MambaModel(\n        input_dim=1, d_model=args.d_model, n_layers=args.n_layers,\n        d_state=args.d_state, d_conv=args.d_conv, expand=args.expand\n    ).to(device)\n    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n    # Loss and optimizer\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n\n    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    no_improve = 0\n\n    # Training loop\n    print(\"\\nStarting training...\")\n    print(\"=\"*60)\n    for epoch in range(1, args.epochs + 1):\n        t0 = time.time()\n        \n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, device, epoch,\n            scaler=scaler, accum_steps=args.accum_steps\n        )\n        val_loss, val_acc, val_preds, val_targets, val_probs = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except Exception:\n            auc = float('nan')\n\n        scheduler.step()\n        epoch_time = time.time() - t0\n        \n        print(f\"Epoch {epoch}/{args.epochs} - Time: {epoch_time:.1f}s\")\n        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n        print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, AUC: {auc:.4f}\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            no_improve = 0\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_acc': val_acc,\n                'val_auc': auc\n            }, args.best_model_path)\n            print(f\"  ✓ Saved best model (val_acc={val_acc:.2f}%)\")\n        else:\n            no_improve += 1\n            print(f\"  No improvement ({no_improve}/{args.patience})\")\n\n        print(\"-\"*60)\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stopping: no improvement for {args.patience} epochs\")\n            break\n\n    print(f\"\\n{'='*60}\")\n    print(f\"Training finished. Best val accuracy: {best_val_acc:.2f}%\")\n    print(f\"{'='*60}\")\n\nif __name__ == '__main__':\n    # Auto-detect Kaggle/Colab environment\n    kaggle_data = '/kaggle/input/vincent/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    \n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_mamba_apnea.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_mamba_apnea.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_mamba_apnea.pth'\n    \n    parser = argparse.ArgumentParser(description='Optimized Mamba apnea detection')\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=3000, help='30 seconds at 100Hz')\n    parser.add_argument('--stride', type=int, default=3000)\n    parser.add_argument('--batch-size', type=int, default=32)\n    parser.add_argument('--epochs', type=int, default=20)\n    parser.add_argument('--lr', type=float, default=1e-3)\n    parser.add_argument('--weight-decay', type=float, default=1e-4)\n    parser.add_argument('--d-model', type=int, default=64)\n    parser.add_argument('--n-layers', type=int, default=3)\n    parser.add_argument('--d-state', type=int, default=8)\n    parser.add_argument('--d-conv', type=int, default=4)\n    parser.add_argument('--expand', type=int, default=2)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--num-workers', type=int, default=4)\n    parser.add_argument('--accum-steps', type=int, default=1)\n    parser.add_argument('--patience', type=int, default=5)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n    \n    if args.data_dir is None:\n        raise SystemExit(\n            \"\\nERROR: Could not find dataset. Please specify --data-dir\\n\"\n            \"Expected locations:\\n\"\n            f\"  Kaggle: {kaggle_data}\\n\"\n            f\"  Colab:  {colab_data}\\n\"\n        )\n    \n    print(\"=\"*60)\n    print(\"Configuration:\")\n    print(f\"  Data dir:      {args.data_dir}\")\n    print(f\"  Cache dir:     {args.cache_dir}\")\n    print(f\"  Model save:    {args.best_model_path}\")\n    print(f\"  Segment len:   {args.segment_length} samples (30s)\")\n    print(f\"  Batch size:    {args.batch_size}\")\n    print(f\"  Epochs:        {args.epochs}\")\n    print(\"=\"*60 + \"\\n\")\n    \n    main(args)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nSuper-fast Mamba-inspired model for apnea detection.\nUses efficient convolutions and attention instead of slow SSM scan.\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- Fast Mamba Alternative --------------------\n\nclass EfficientMambaBlock(nn.Module):\n    \"\"\"\n    Efficient alternative using depthwise convolution + gating.\n    Much faster than sequential SSM scan.\n    \"\"\"\n    def __init__(self, d_model, d_conv=4, expand=2):\n        super().__init__()\n        self.d_model = d_model\n        self.d_inner = int(expand * d_model)\n        \n        # Input projection\n        self.in_proj = nn.Linear(d_model, self.d_inner * 2, bias=False)\n        \n        # Multi-scale depthwise convolutions for temporal modeling\n        self.conv_short = nn.Conv1d(\n            self.d_inner, self.d_inner, kernel_size=3,\n            padding=1, groups=self.d_inner, bias=True\n        )\n        self.conv_medium = nn.Conv1d(\n            self.d_inner, self.d_inner, kernel_size=7,\n            padding=3, groups=self.d_inner, bias=True\n        )\n        self.conv_long = nn.Conv1d(\n            self.d_inner, self.d_inner, kernel_size=15,\n            padding=7, groups=self.d_inner, bias=True\n        )\n        \n        # Gating mechanism\n        self.gate = nn.Linear(self.d_inner, self.d_inner)\n        \n        # Output projection\n        self.out_proj = nn.Linear(self.d_inner, d_model, bias=False)\n        \n    def forward(self, x):\n        # x: (B, L, D)\n        B, L, D = x.shape\n        \n        # Project and split\n        x_and_res = self.in_proj(x)\n        x_in, res = x_and_res.split([self.d_inner, self.d_inner], dim=-1)\n        \n        # Apply multi-scale convolutions\n        x_t = x_in.transpose(1, 2)  # (B, d_inner, L)\n        \n        conv_s = self.conv_short(x_t)\n        conv_m = self.conv_medium(x_t)\n        conv_l = self.conv_long(x_t)\n        \n        # Combine multi-scale features\n        x_conv = (conv_s + conv_m + conv_l) / 3.0\n        x_conv = x_conv.transpose(1, 2)  # (B, L, d_inner)\n        x_conv = F.silu(x_conv)\n        \n        # Gating\n        gate = torch.sigmoid(self.gate(x_conv))\n        y = x_conv * gate * F.silu(res)\n        \n        # Project back\n        out = self.out_proj(y)\n        return out\n\n\nclass FastMambaModel(nn.Module):\n    \"\"\"Fast Mamba-inspired model using efficient convolutions.\"\"\"\n    def __init__(self, input_dim=1, d_model=64, n_layers=4, expand=2, num_classes=2):\n        super().__init__()\n        self.input_proj = nn.Linear(input_dim, d_model)\n        self.layers = nn.ModuleList([\n            EfficientMambaBlock(d_model, expand=expand) \n            for _ in range(n_layers)\n        ])\n        self.norm = nn.LayerNorm(d_model)\n        self.classifier = nn.Linear(d_model, num_classes)\n        \n    def forward(self, x):\n        # x: (B, L, 1)\n        x = self.input_proj(x)\n        for layer in self.layers:\n            x = x + layer(x)\n        x = self.norm(x)\n        x = x.mean(dim=1)  # Global average pooling\n        logits = self.classifier(x)\n        return logits\n\n\n# --------------------------- Dataset & Caching ---------------------------\n\nclass ApneaECGDataset(Dataset):\n    \"\"\"Optimized dataset with proper cache handling.\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 3000, stride: int = 3000, split='train'):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_cache_{split}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} dataset from {cache_file}\")\n            data = torch.load(cache_file)\n            self.segments = data['segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb not available. Install wfdb or create cache first.\"\n            assert record_names is not None, \"record_names must be provided if not using cache\"\n            \n            self.segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split} set...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.segments) == 0:\n                raise RuntimeError(\"No segments loaded. Check records and segment parameters.\")\n            \n            self.segments = torch.tensor(np.stack(self.segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving {split} cache to {cache_file}\")\n            torch.save({'segments': self.segments, 'labels': self.labels}, cache_file)\n\n        if self.segments.ndim == 2:\n            self.segments = self.segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()} dataset: {len(self.segments)} segments. \"\n              f\"Class dist: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            record = wfdb.rdrecord(str(self.data_dir / record_name))\n            signal = record.p_signal[:, 0].astype(np.float32)\n    \n            if np.isnan(signal).any():\n                nans = np.isnan(signal)\n                not_nans = ~nans\n                if not_nans.sum() > 0:\n                    signal[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(not_nans), signal[not_nans])\n                else:\n                    signal = np.zeros_like(signal)\n    \n            annotation = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            \n            n_minutes = len(signal) // 6000\n            minute_labels = np.zeros(n_minutes, dtype=int)\n            \n            for i, symbol in enumerate(annotation.symbol):\n                if symbol == 'A':\n                    sample = annotation.sample[i]\n                    minute = sample // 6000\n                    if minute < n_minutes:\n                        minute_labels[minute] = 1\n    \n            n_samples = len(signal)\n            for start in range(0, n_samples - self.segment_length + 1, self.stride):\n                end = start + self.segment_length\n                seg = signal[start:end].astype(np.float32)\n    \n                seg_mean = np.nanmean(seg)\n                seg_std = np.nanstd(seg)\n                if np.isnan(seg_std) or seg_std < 1e-8:\n                    seg = seg - seg_mean\n                else:\n                    seg = (seg - seg_mean) / (seg_std + 1e-8)\n    \n                minute = start // 6000\n                if minute < len(minute_labels):\n                    label = minute_labels[minute]\n                    self.segments.append(seg)\n                    self.labels.append(int(label))\n                    \n        except Exception as e:\n            print(f\"\\nError loading {record_name}: {e}\")\n            \n    def __len__(self):\n        return self.segments.shape[0]\n\n    def __getitem__(self, idx):\n        return self.segments[idx], self.labels[idx]\n\n# -------------------------- Training / Validation ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model, dataloader, criterion, optimizer, device, epoch, scaler=None, accum_steps=1):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 20)  # Print 20 times per epoch\n    \n    start_time = time.time()\n\n    for batch_idx, (data, target) in enumerate(dataloader, 1):\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(data)\n            loss = criterion(output, target) / accum_steps\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n\n        if batch_idx % accum_steps == 0:\n            if scaler is not None:\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n            optimizer.zero_grad(set_to_none=True)\n\n        total_loss += loss.item() * accum_steps\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        # Print progress\n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            elapsed = time.time() - start_time\n            batches_per_sec = batch_idx / elapsed\n            eta = (num_batches - batch_idx) / batches_per_sec if batches_per_sec > 0 else 0\n            \n            print(f\"  Epoch {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"Speed: {batches_per_sec:.1f} batch/s ETA: {eta:.0f}s\", end='\\r')\n\n    print()  # New line after progress\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for data, target in dataloader:\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().numpy().tolist())\n            all_targets.extend(target.cpu().numpy().tolist())\n            all_probs.extend(probs.cpu().numpy().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs)\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    # Find valid records\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(f\"No valid records found in {DATA_DIR}\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    # Split records\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train: {len(train_records)} records, Val: {len(val_records)} records\\n\")\n\n    # Create datasets with separate caches\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = ApneaECGDataset(\n        str(DATA_DIR), record_names=train_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='train'\n    )\n    val_dataset = ApneaECGDataset(\n        str(DATA_DIR), record_names=val_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='val'\n    )\n\n    # DataLoaders\n    num_workers = min(max(0, (os.cpu_count() or 4) - 1), args.num_workers)\n    if str(DATA_DIR).startswith('/kaggle'):\n        num_workers = min(num_workers, 2)\n    \n    print(f\"DataLoader: batch_size={args.batch_size}, num_workers={num_workers}\\n\")\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    # Setup device and model\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    if device.type == 'cuda':\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n\n    model = FastMambaModel(\n        input_dim=1, d_model=args.d_model, n_layers=args.n_layers, expand=args.expand\n    ).to(device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Model parameters: {total_params:,}\\n\")\n\n    # Loss and optimizer\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n\n    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    best_val_auc = 0.0\n    no_improve = 0\n\n    # Training loop\n    print(\"\\nStarting training...\")\n    print(\"=\"*80)\n    \n    for epoch in range(1, args.epochs + 1):\n        epoch_start = time.time()\n        \n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, device, epoch,\n            scaler=scaler, accum_steps=args.accum_steps\n        )\n        val_loss, val_acc, val_preds, val_targets, val_probs = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except Exception:\n            auc = 0.0\n\n        scheduler.step()\n        epoch_time = time.time() - epoch_start\n        \n        print(f\"Epoch {epoch:2d}/{args.epochs} - Time: {epoch_time:.1f}s\")\n        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n        print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, AUC: {auc:.4f}\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_val_auc = auc\n            no_improve = 0\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_acc': val_acc,\n                'val_auc': auc\n            }, args.best_model_path)\n            print(f\"  ✓ New best! (Acc: {val_acc:.2f}%, AUC: {auc:.4f})\")\n        else:\n            no_improve += 1\n            print(f\"  No improvement ({no_improve}/{args.patience})\")\n\n        print(\"-\"*80)\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stopping after {epoch} epochs\")\n            break\n\n    print(f\"\\n{'='*80}\")\n    print(f\"Training finished!\")\n    print(f\"Best validation - Accuracy: {best_val_acc:.2f}%, AUC: {best_val_auc:.4f}\")\n    print(f\"{'='*80}\")\n\nif __name__ == '__main__':\n    # Auto-detect environment\n    kaggle_data = '/kaggle/input/vincent/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    \n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_mamba_apnea.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_mamba_apnea.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_mamba_apnea.pth'\n    \n    parser = argparse.ArgumentParser(description='Fast Mamba-inspired apnea detection')\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=3000, help='30 seconds at 100Hz')\n    parser.add_argument('--stride', type=int, default=3000)\n    parser.add_argument('--batch-size', type=int, default=64)\n    parser.add_argument('--epochs', type=int, default=30)\n    parser.add_argument('--lr', type=float, default=1e-3)\n    parser.add_argument('--weight-decay', type=float, default=1e-4)\n    parser.add_argument('--d-model', type=int, default=128)\n    parser.add_argument('--n-layers', type=int, default=4)\n    parser.add_argument('--expand', type=int, default=2)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--num-workers', type=int, default=4)\n    parser.add_argument('--accum-steps', type=int, default=1)\n    parser.add_argument('--patience', type=int, default=7)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n    \n    if args.data_dir is None:\n        raise SystemExit(\n            \"\\nERROR: Could not find dataset. Please specify --data-dir\\n\"\n            f\"Expected: {kaggle_data} or {colab_data}\\n\"\n        )\n    \n    print(\"=\"*80)\n    print(\"CONFIGURATION\")\n    print(\"=\"*80)\n    print(f\"  Data dir:      {args.data_dir}\")\n    print(f\"  Cache dir:     {args.cache_dir}\")\n    print(f\"  Model save:    {args.best_model_path}\")\n    print(f\"  Segment:       {args.segment_length} samples (30s @ 100Hz)\")\n    print(f\"  Batch size:    {args.batch_size}\")\n    print(f\"  Epochs:        {args.epochs}\")\n    print(f\"  Model dim:     {args.d_model}, Layers: {args.n_layers}\")\n    print(\"=\"*80 + \"\\n\")\n    \n    main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:17:04.155727Z","iopub.execute_input":"2025-11-13T21:17:04.156416Z","iopub.status.idle":"2025-11-13T21:40:43.868449Z","shell.execute_reply.started":"2025-11-13T21:17:04.156385Z","shell.execute_reply":"2025-11-13T21:40:43.867181Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCONFIGURATION\n================================================================================\n  Data dir:      /kaggle/input/vincent/apnea-ecg-database-1.0.0\n  Cache dir:     /kaggle/working\n  Model save:    /kaggle/working/best_mamba_apnea.pth\n  Segment:       3000 samples (30s @ 100Hz)\n  Batch size:    64\n  Epochs:        30\n  Model dim:     128, Layers: 4\n================================================================================\n\nFound 43 valid records\nTrain: 34 records, Val: 9 records\n\nProcessing 34 records for train set...\n  [34/34] a20....\nSaving train cache to /kaggle/working/apnea_cache_train.pt\nTrain dataset: 33434 segments. Class dist: Counter({0: 21132, 1: 12302})\nProcessing 9 records for val set...\n  [9/9] a01....\nSaving val cache to /kaggle/working/apnea_cache_val.pt\nVal dataset: 8628 segments. Class dist: Counter({0: 4690, 1: 3938})\nDataLoader: batch_size=64, num_workers=2\n\nUsing device: cuda\nGPU: Tesla P100-PCIE-16GB\nModel parameters: 685,826\n\nClass weights: tensor([0.7911, 1.3589], device='cuda:0')\n\nStarting training...\n================================================================================\n  Epoch 1 [ 523/523] Loss: nan Acc: 66.70% Speed: 2.1 batch/s ETA: 0sss56s\nEpoch  1/30 - Time: 278.0s\n  Train - Loss: nan, Acc: 66.70%\n  Val   - Loss: 0.6565, Acc: 56.73%, AUC: 0.6585\n  ✓ New best! (Acc: 56.73%, AUC: 0.6585)\n--------------------------------------------------------------------------------\n  Epoch 2 [ 523/523] Loss: nan Acc: 65.14% Speed: 2.1 batch/s ETA: 0sss\nEpoch  2/30 - Time: 278.3s\n  Train - Loss: nan, Acc: 65.14%\n  Val   - Loss: nan, Acc: 54.36%, AUC: 0.0000\n  No improvement (1/7)\n--------------------------------------------------------------------------------\n  Epoch 3 [ 523/523] Loss: nan Acc: 63.21% Speed: 2.0 batch/s ETA: 0sss\nEpoch  3/30 - Time: 279.2s\n  Train - Loss: nan, Acc: 63.21%\n  Val   - Loss: nan, Acc: 54.36%, AUC: 0.0000\n  No improvement (2/7)\n--------------------------------------------------------------------------------\n  Epoch 4 [ 523/523] Loss: nan Acc: 63.21% Speed: 2.0 batch/s ETA: 0sss\nEpoch  4/30 - Time: 279.3s\n  Train - Loss: nan, Acc: 63.21%\n  Val   - Loss: nan, Acc: 54.36%, AUC: 0.0000\n  No improvement (3/7)\n--------------------------------------------------------------------------------\n  Epoch 5 [ 523/523] Loss: nan Acc: 63.21% Speed: 2.0 batch/s ETA: 0sss\nEpoch  5/30 - Time: 279.3s\n  Train - Loss: nan, Acc: 63.21%\n  Val   - Loss: nan, Acc: 54.36%, AUC: 0.0000\n  No improvement (4/7)\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/3290578883.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_48/3290578883.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         train_loss, train_acc = train_epoch(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccum_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/3290578883.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device, epoch, scaler, accum_steps)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nStable and high-performance CNN-Transformer hybrid for apnea detection.\nDesigned for 90%+ accuracy with numerical stability.\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- Stable Model ------------------------------\n\nclass ResidualBlock(nn.Module):\n    \"\"\"Stable residual block with layer normalization.\"\"\"\n    def __init__(self, channels):\n        super().__init__()\n        self.conv1 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n        self.norm1 = nn.LayerNorm(channels)\n        self.norm2 = nn.LayerNorm(channels)\n        self.dropout = nn.Dropout(0.1)\n        \n    def forward(self, x):\n        # x: (B, C, L)\n        residual = x\n        x = x.transpose(1, 2)  # (B, L, C)\n        x = self.norm1(x)\n        x = x.transpose(1, 2)  # (B, C, L)\n        x = F.gelu(self.conv1(x))\n        x = self.dropout(x)\n        \n        x = x.transpose(1, 2)\n        x = self.norm2(x)\n        x = x.transpose(1, 2)\n        x = self.conv2(x)\n        \n        return F.gelu(residual + x)\n\n\nclass MultiScaleCNN(nn.Module):\n    \"\"\"Multi-scale CNN with residual connections.\"\"\"\n    def __init__(self, d_model=128, n_layers=4, dropout=0.2):\n        super().__init__()\n        \n        # Initial projection\n        self.input_proj = nn.Conv1d(1, d_model, kernel_size=7, padding=3)\n        self.input_norm = nn.LayerNorm(d_model)\n        \n        # Multi-scale feature extraction\n        self.res_blocks = nn.ModuleList([\n            ResidualBlock(d_model) for _ in range(n_layers)\n        ])\n        \n        # Multi-scale pooling\n        self.pool_short = nn.AvgPool1d(kernel_size=3, stride=1, padding=1)\n        self.pool_medium = nn.AvgPool1d(kernel_size=5, stride=1, padding=2)\n        \n        # Attention mechanism\n        self.attention = nn.MultiheadAttention(d_model, num_heads=4, dropout=dropout, batch_first=True)\n        self.attn_norm = nn.LayerNorm(d_model)\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 3, d_model),\n            nn.LayerNorm(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model, 2)\n        )\n        \n    def forward(self, x):\n        # x: (B, L, 1)\n        x = x.transpose(1, 2)  # (B, 1, L)\n        \n        # Initial projection\n        x = self.input_proj(x)  # (B, d_model, L)\n        \n        # Residual blocks\n        for block in self.res_blocks:\n            x = block(x)\n        \n        # Multi-scale features\n        x_short = self.pool_short(x)\n        x_medium = self.pool_medium(x)\n        \n        # Global pooling\n        x_max = F.adaptive_max_pool1d(x, 1).squeeze(-1)  # (B, d_model)\n        x_avg = F.adaptive_avg_pool1d(x, 1).squeeze(-1)  # (B, d_model)\n        \n        # Attention on downsampled sequence\n        x_seq = F.adaptive_avg_pool1d(x, 100).transpose(1, 2)  # (B, 100, d_model)\n        x_attn, _ = self.attention(x_seq, x_seq, x_seq)\n        x_attn = self.attn_norm(x_attn + x_seq)\n        x_attn = x_attn.mean(dim=1)  # (B, d_model)\n        \n        # Concatenate features\n        x_combined = torch.cat([x_max, x_avg, x_attn], dim=-1)  # (B, d_model*3)\n        \n        # Classification\n        logits = self.classifier(x_combined)\n        return logits\n\n\n# --------------------------- Dataset & Caching ---------------------------\n\nclass ApneaECGDataset(Dataset):\n    \"\"\"Optimized dataset with proper cache handling.\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 3000, stride: int = 3000, split='train'):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_cache_{split}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} dataset from {cache_file}\")\n            data = torch.load(cache_file)\n            self.segments = data['segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb not available\"\n            assert record_names is not None, \"record_names required\"\n            \n            self.segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split}...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.segments) == 0:\n                raise RuntimeError(\"No segments loaded\")\n            \n            self.segments = torch.tensor(np.stack(self.segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving {split} cache to {cache_file}\")\n            torch.save({'segments': self.segments, 'labels': self.labels}, cache_file)\n\n        if self.segments.ndim == 2:\n            self.segments = self.segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()}: {len(self.segments)} segments. \"\n              f\"Class dist: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            record = wfdb.rdrecord(str(self.data_dir / record_name))\n            signal = record.p_signal[:, 0].astype(np.float32)\n    \n            if np.isnan(signal).any():\n                nans = np.isnan(signal)\n                not_nans = ~nans\n                if not_nans.sum() > 0:\n                    signal[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(not_nans), signal[not_nans])\n                else:\n                    signal = np.zeros_like(signal)\n    \n            annotation = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            \n            n_minutes = len(signal) // 6000\n            minute_labels = np.zeros(n_minutes, dtype=int)\n            \n            for i, symbol in enumerate(annotation.symbol):\n                if symbol == 'A':\n                    sample = annotation.sample[i]\n                    minute = sample // 6000\n                    if minute < n_minutes:\n                        minute_labels[minute] = 1\n    \n            n_samples = len(signal)\n            for start in range(0, n_samples - self.segment_length + 1, self.stride):\n                end = start + self.segment_length\n                seg = signal[start:end].astype(np.float32)\n    \n                # Robust normalization\n                seg_mean = np.nanmean(seg)\n                seg_std = np.nanstd(seg)\n                if np.isnan(seg_std) or seg_std < 1e-8:\n                    seg = seg - seg_mean\n                else:\n                    seg = (seg - seg_mean) / (seg_std + 1e-8)\n                \n                # Clip extreme values for stability\n                seg = np.clip(seg, -10, 10)\n    \n                minute = start // 6000\n                if minute < len(minute_labels):\n                    label = minute_labels[minute]\n                    self.segments.append(seg)\n                    self.labels.append(int(label))\n                    \n        except Exception as e:\n            print(f\"\\nError loading {record_name}: {e}\")\n            \n    def __len__(self):\n        return self.segments.shape[0]\n\n    def __getitem__(self, idx):\n        return self.segments[idx], self.labels[idx]\n\n# -------------------------- Training / Validation ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model, dataloader, criterion, optimizer, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 20)\n    \n    start_time = time.time()\n\n    for batch_idx, (data, target) in enumerate(dataloader, 1):\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad()\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(data)\n            loss = criterion(output, target)\n        \n        # Check for NaN\n        if torch.isnan(loss):\n            print(f\"\\nWARNING: NaN loss at batch {batch_idx}, skipping...\")\n            continue\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            elapsed = time.time() - start_time\n            speed = batch_idx / elapsed\n            eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n            \n            print(f\"  Epoch {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"Speed: {speed:.1f} b/s ETA: {eta:.0f}s\", end='\\r')\n\n    print()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for data, target in dataloader:\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().numpy().tolist())\n            all_targets.extend(target.cpu().numpy().tolist())\n            all_probs.extend(probs.cpu().numpy().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    # Additional metrics\n    precision = precision_score(all_targets, all_preds, zero_division=0)\n    recall = recall_score(all_targets, all_preds, zero_division=0)\n    f1 = f1_score(all_targets, all_preds, zero_division=0)\n    \n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs), precision, recall, f1\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    # Find valid records\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(f\"No valid records found\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    # Split records\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train: {len(train_records)} records, Val: {len(val_records)} records\\n\")\n\n    # Create datasets\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = ApneaECGDataset(\n        str(DATA_DIR), record_names=train_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='train'\n    )\n    val_dataset = ApneaECGDataset(\n        str(DATA_DIR), record_names=val_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='val'\n    )\n\n    # DataLoaders\n    num_workers = 2 if str(DATA_DIR).startswith('/kaggle') else 4\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    # Setup device and model\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"\\nUsing device: {device}\")\n    if device.type == 'cuda':\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n\n    model = MultiScaleCNN(\n        d_model=args.d_model, n_layers=args.n_layers, dropout=args.dropout\n    ).to(device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Model parameters: {total_params:,}\\n\")\n\n    # Loss and optimizer\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(), \n        lr=args.lr, \n        weight_decay=args.weight_decay,\n        betas=(0.9, 0.999)\n    )\n    \n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, \n        max_lr=args.lr,\n        epochs=args.epochs,\n        steps_per_epoch=len(train_loader),\n        pct_start=0.1\n    )\n\n    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    best_val_f1 = 0.0\n    no_improve = 0\n\n    # Training loop\n    print(\"\\nStarting training...\")\n    print(\"=\"*90)\n    \n    for epoch in range(1, args.epochs + 1):\n        epoch_start = time.time()\n        \n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, device, epoch, scaler=scaler\n        )\n        \n        val_loss, val_acc, val_preds, val_targets, val_probs, precision, recall, f1 = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except Exception:\n            auc = 0.0\n\n        epoch_time = time.time() - epoch_start\n        \n        print(f\"Epoch {epoch:2d}/{args.epochs} - Time: {epoch_time:.1f}s\")\n        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n        print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, AUC: {auc:.4f}\")\n        print(f\"  Val   - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n\n        improved = False\n        if val_acc > best_val_acc or (val_acc == best_val_acc and f1 > best_val_f1):\n            best_val_acc = val_acc\n            best_val_f1 = f1\n            no_improve = 0\n            improved = True\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_acc': val_acc,\n                'val_auc': auc,\n                'val_f1': f1\n            }, args.best_model_path)\n            print(f\"  ✓ New best! (Acc: {val_acc:.2f}%, F1: {f1:.4f})\")\n        else:\n            no_improve += 1\n            print(f\"  No improvement ({no_improve}/{args.patience})\")\n\n        print(\"-\"*90)\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stopping after {epoch} epochs\")\n            break\n\n    print(f\"\\n{'='*90}\")\n    print(f\"Training finished!\")\n    print(f\"Best validation - Accuracy: {best_val_acc:.2f}%, F1: {best_val_f1:.4f}\")\n    print(f\"{'='*90}\")\n\nif __name__ == '__main__':\n    # Auto-detect environment\n    kaggle_data = '/kaggle/input/vincent/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    \n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_model.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_model.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_model.pth'\n    \n    parser = argparse.ArgumentParser(description='High-performance apnea detection')\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=3000)\n    parser.add_argument('--stride', type=int, default=3000)\n    parser.add_argument('--batch-size', type=int, default=64)\n    parser.add_argument('--epochs', type=int, default=50)\n    parser.add_argument('--lr', type=float, default=3e-4)\n    parser.add_argument('--weight-decay', type=float, default=1e-5)\n    parser.add_argument('--d-model', type=int, default=128)\n    parser.add_argument('--n-layers', type=int, default=6)\n    parser.add_argument('--dropout', type=float, default=0.2)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--num-workers', type=int, default=4)\n    parser.add_argument('--patience', type=int, default=10)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n    \n    if args.data_dir is None:\n        raise SystemExit(f\"\\nERROR: Dataset not found at {kaggle_data} or {colab_data}\\n\")\n    \n    print(\"=\"*90)\n    print(\"CONFIGURATION\")\n    print(\"=\"*90)\n    print(f\"  Data:          {args.data_dir}\")\n    print(f\"  Cache:         {args.cache_dir}\")\n    print(f\"  Model save:    {args.best_model_path}\")\n    print(f\"  Segment:       {args.segment_length} samples (30s)\")\n    print(f\"  Batch size:    {args.batch_size}\")\n    print(f\"  Epochs:        {args.epochs}\")\n    print(f\"  Learning rate: {args.lr}\")\n    print(f\"  Model:         d_model={args.d_model}, n_layers={args.n_layers}, dropout={args.dropout}\")\n    print(\"=\"*90 + \"\\n\")\n    \n    main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:40:55.399433Z","iopub.execute_input":"2025-11-13T21:40:55.399743Z","iopub.status.idle":"2025-11-13T22:40:29.423537Z","shell.execute_reply.started":"2025-11-13T21:40:55.399717Z","shell.execute_reply":"2025-11-13T22:40:29.422390Z"}},"outputs":[{"name":"stdout","text":"==========================================================================================\nCONFIGURATION\n==========================================================================================\n  Data:          /kaggle/input/vincent/apnea-ecg-database-1.0.0\n  Cache:         /kaggle/working\n  Model save:    /kaggle/working/best_model.pth\n  Segment:       3000 samples (30s)\n  Batch size:    64\n  Epochs:        50\n  Learning rate: 0.0003\n  Model:         d_model=128, n_layers=6, dropout=0.2\n==========================================================================================\n\nFound 43 valid records\nTrain: 34 records, Val: 9 records\n\nLoading cached train dataset from /kaggle/working/apnea_cache_train.pt\nTrain: 33434 segments. Class dist: Counter({0: 21132, 1: 12302})\nLoading cached val dataset from /kaggle/working/apnea_cache_val.pt\nVal: 8628 segments. Class dist: Counter({0: 4690, 1: 3938})\n\nUsing device: cuda\nGPU: Tesla P100-PCIE-16GB\nModel parameters: 711,810\n\nClass weights: tensor([0.7911, 1.3589], device='cuda:0')\n\nStarting training...\n==========================================================================================\n  Epoch 1 [ 523/523] Loss: 0.5742 Acc: 73.26% Speed: 3.3 b/s ETA: 0sss\nEpoch  1/50 - Time: 169.9s\n  Train - Loss: 0.5742, Acc: 73.26%\n  Val   - Loss: 0.6945, Acc: 57.27%, AUC: 0.7068\n  Val   - Precision: 0.5207, Recall: 0.8019, F1: 0.6314\n  ✓ New best! (Acc: 57.27%, F1: 0.6314)\n------------------------------------------------------------------------------------------\n  Epoch 2 [ 523/523] Loss: 0.4744 Acc: 81.60% Speed: 3.4 b/s ETA: 0sss\nEpoch  2/50 - Time: 168.9s\n  Train - Loss: 0.4744, Acc: 81.60%\n  Val   - Loss: 0.7483, Acc: 56.55%, AUC: 0.6625\n  Val   - Precision: 0.5137, Recall: 0.8999, F1: 0.6541\n  No improvement (1/10)\n------------------------------------------------------------------------------------------\n  Epoch 3 [ 523/523] Loss: 0.4576 Acc: 82.73% Speed: 3.4 b/s ETA: 0sss\nEpoch  3/50 - Time: 168.9s\n  Train - Loss: 0.4576, Acc: 82.73%\n  Val   - Loss: 0.7094, Acc: 58.40%, AUC: 0.6925\n  Val   - Precision: 0.5261, Recall: 0.8921, F1: 0.6619\n  ✓ New best! (Acc: 58.40%, F1: 0.6619)\n------------------------------------------------------------------------------------------\n  Epoch 4 [ 523/523] Loss: 0.4499 Acc: 83.46% Speed: 3.4 b/s ETA: 0sss\nEpoch  4/50 - Time: 169.0s\n  Train - Loss: 0.4499, Acc: 83.46%\n  Val   - Loss: 0.7299, Acc: 59.43%, AUC: 0.7077\n  Val   - Precision: 0.5311, Recall: 0.9490, F1: 0.6811\n  ✓ New best! (Acc: 59.43%, F1: 0.6811)\n------------------------------------------------------------------------------------------\n  Epoch 5 [ 523/523] Loss: 0.4385 Acc: 84.17% Speed: 3.4 b/s ETA: 0sss\nEpoch  5/50 - Time: 168.9s\n  Train - Loss: 0.4385, Acc: 84.17%\n  Val   - Loss: 0.7624, Acc: 59.35%, AUC: 0.6831\n  Val   - Precision: 0.5310, Recall: 0.9363, F1: 0.6777\n  No improvement (1/10)\n------------------------------------------------------------------------------------------\n  Epoch 6 [ 523/523] Loss: 0.4305 Acc: 84.79% Speed: 3.3 b/s ETA: 0sss\nEpoch  6/50 - Time: 169.0s\n  Train - Loss: 0.4305, Acc: 84.79%\n  Val   - Loss: 0.6974, Acc: 61.25%, AUC: 0.7380\n  Val   - Precision: 0.5474, Recall: 0.8718, F1: 0.6725\n  ✓ New best! (Acc: 61.25%, F1: 0.6725)\n------------------------------------------------------------------------------------------\n  Epoch 7 [ 523/523] Loss: 0.4241 Acc: 85.38% Speed: 3.3 b/s ETA: 0sss\nEpoch  7/50 - Time: 169.1s\n  Train - Loss: 0.4241, Acc: 85.38%\n  Val   - Loss: 0.7289, Acc: 62.07%, AUC: 0.7038\n  Val   - Precision: 0.5509, Recall: 0.9137, F1: 0.6874\n  ✓ New best! (Acc: 62.07%, F1: 0.6874)\n------------------------------------------------------------------------------------------\n  Epoch 8 [ 523/523] Loss: 0.4182 Acc: 85.86% Speed: 3.3 b/s ETA: 0sss\nEpoch  8/50 - Time: 169.4s\n  Train - Loss: 0.4182, Acc: 85.86%\n  Val   - Loss: 0.7359, Acc: 61.79%, AUC: 0.7088\n  Val   - Precision: 0.5487, Recall: 0.9170, F1: 0.6866\n  No improvement (1/10)\n------------------------------------------------------------------------------------------\n  Epoch 9 [ 523/523] Loss: 0.4145 Acc: 86.18% Speed: 3.3 b/s ETA: 0sss\nEpoch  9/50 - Time: 169.7s\n  Train - Loss: 0.4145, Acc: 86.18%\n  Val   - Loss: 0.7167, Acc: 63.57%, AUC: 0.7357\n  Val   - Precision: 0.5611, Recall: 0.9264, F1: 0.6989\n  ✓ New best! (Acc: 63.57%, F1: 0.6989)\n------------------------------------------------------------------------------------------\n  Epoch 10 [ 523/523] Loss: 0.4105 Acc: 86.63% Speed: 3.3 b/s ETA: 0sss\nEpoch 10/50 - Time: 169.4s\n  Train - Loss: 0.4105, Acc: 86.63%\n  Val   - Loss: 0.7145, Acc: 63.40%, AUC: 0.7478\n  Val   - Precision: 0.5587, Recall: 0.9429, F1: 0.7016\n  No improvement (1/10)\n------------------------------------------------------------------------------------------\n  Epoch 11 [ 523/523] Loss: 0.4066 Acc: 86.74% Speed: 3.3 b/s ETA: 0sss\nEpoch 11/50 - Time: 169.3s\n  Train - Loss: 0.4066, Acc: 86.74%\n  Val   - Loss: 0.7626, Acc: 63.55%, AUC: 0.7187\n  Val   - Precision: 0.5608, Recall: 0.9281, F1: 0.6992\n  No improvement (2/10)\n------------------------------------------------------------------------------------------\n  Epoch 12 [ 523/523] Loss: 0.4053 Acc: 87.06% Speed: 3.3 b/s ETA: 0sss\nEpoch 12/50 - Time: 169.4s\n  Train - Loss: 0.4053, Acc: 87.06%\n  Val   - Loss: 0.7186, Acc: 64.67%, AUC: 0.7611\n  Val   - Precision: 0.5688, Recall: 0.9340, F1: 0.7070\n  ✓ New best! (Acc: 64.67%, F1: 0.7070)\n------------------------------------------------------------------------------------------\n  Epoch 13 [ 523/523] Loss: 0.4004 Acc: 87.28% Speed: 3.3 b/s ETA: 0sss\nEpoch 13/50 - Time: 169.4s\n  Train - Loss: 0.4004, Acc: 87.28%\n  Val   - Loss: 0.7409, Acc: 64.22%, AUC: 0.7452\n  Val   - Precision: 0.5649, Recall: 0.9411, F1: 0.7060\n  No improvement (1/10)\n------------------------------------------------------------------------------------------\n  Epoch 14 [ 523/523] Loss: 0.3998 Acc: 87.49% Speed: 3.3 b/s ETA: 0sss\nEpoch 14/50 - Time: 169.5s\n  Train - Loss: 0.3998, Acc: 87.49%\n  Val   - Loss: 0.6778, Acc: 67.18%, AUC: 0.7509\n  Val   - Precision: 0.5926, Recall: 0.8987, F1: 0.7142\n  ✓ New best! (Acc: 67.18%, F1: 0.7142)\n------------------------------------------------------------------------------------------\n  Epoch 15 [ 523/523] Loss: 0.3955 Acc: 87.75% Speed: 3.3 b/s ETA: 0sss\nEpoch 15/50 - Time: 169.5s\n  Train - Loss: 0.3955, Acc: 87.75%\n  Val   - Loss: 0.7734, Acc: 64.15%, AUC: 0.7388\n  Val   - Precision: 0.5631, Recall: 0.9581, F1: 0.7093\n  No improvement (1/10)\n------------------------------------------------------------------------------------------\n  Epoch 16 [ 523/523] Loss: 0.3943 Acc: 87.87% Speed: 3.3 b/s ETA: 0sss\nEpoch 16/50 - Time: 169.6s\n  Train - Loss: 0.3943, Acc: 87.87%\n  Val   - Loss: 0.7403, Acc: 65.73%, AUC: 0.7673\n  Val   - Precision: 0.5757, Recall: 0.9477, F1: 0.7162\n  No improvement (2/10)\n------------------------------------------------------------------------------------------\n  Epoch 17 [ 523/523] Loss: 0.3907 Acc: 88.22% Speed: 3.3 b/s ETA: 0sss\nEpoch 17/50 - Time: 169.5s\n  Train - Loss: 0.3907, Acc: 88.22%\n  Val   - Loss: 0.7079, Acc: 65.74%, AUC: 0.7619\n  Val   - Precision: 0.5780, Recall: 0.9238, F1: 0.7111\n  No improvement (3/10)\n------------------------------------------------------------------------------------------\n  Epoch 18 [ 523/523] Loss: 0.3882 Acc: 88.40% Speed: 3.3 b/s ETA: 0sss\nEpoch 18/50 - Time: 169.4s\n  Train - Loss: 0.3882, Acc: 88.40%\n  Val   - Loss: 0.7286, Acc: 66.48%, AUC: 0.7618\n  Val   - Precision: 0.5834, Recall: 0.9292, F1: 0.7167\n  No improvement (4/10)\n------------------------------------------------------------------------------------------\n  Epoch 19 [ 523/523] Loss: 0.3850 Acc: 88.72% Speed: 3.3 b/s ETA: 0sss\nEpoch 19/50 - Time: 169.7s\n  Train - Loss: 0.3850, Acc: 88.72%\n  Val   - Loss: 0.7328, Acc: 66.21%, AUC: 0.7636\n  Val   - Precision: 0.5828, Recall: 0.9144, F1: 0.7119\n  No improvement (5/10)\n------------------------------------------------------------------------------------------\n  Epoch 20 [ 523/523] Loss: 0.3847 Acc: 88.54% Speed: 3.3 b/s ETA: 0sss\nEpoch 20/50 - Time: 169.7s\n  Train - Loss: 0.3847, Acc: 88.54%\n  Val   - Loss: 0.7474, Acc: 65.01%, AUC: 0.7304\n  Val   - Precision: 0.5729, Recall: 0.9170, F1: 0.7052\n  No improvement (6/10)\n------------------------------------------------------------------------------------------\n  Epoch 21 [ 523/523] Loss: 0.3828 Acc: 88.74% Speed: 3.3 b/s ETA: 0sss\nEpoch 21/50 - Time: 169.4s\n  Train - Loss: 0.3828, Acc: 88.74%\n  Val   - Loss: 0.7638, Acc: 65.43%, AUC: 0.7459\n  Val   - Precision: 0.5753, Recall: 0.9264, F1: 0.7098\n  No improvement (7/10)\n------------------------------------------------------------------------------------------\n  Epoch 22 [  52/523] Loss: 0.3807 Acc: 88.97% Speed: 3.3 b/s ETA: 142s\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/143469653.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m90\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_48/143469653.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         train_loss, train_acc = train_epoch(\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         )\n","\u001b[0;32m/tmp/ipykernel_48/143469653.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device, epoch, scaler)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# Check for NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1296\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3494\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3495\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3496\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nEnhanced CNN-Transformer hybrid for apnea detection targeting 90%+ accuracy.\nKey improvements:\n- Deeper architecture with better feature extraction\n- Advanced augmentation techniques\n- Improved loss function with focal loss\n- Better normalization and regularization\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- Focal Loss ---------------------------------\n\nclass FocalLoss(nn.Module):\n    \"\"\"Focal loss for handling class imbalance better than CE.\"\"\"\n    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n    \n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n        pt = torch.exp(-ce_loss)\n        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n        \n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        return focal_loss\n\n# ----------------------------- Enhanced Model ------------------------------\n\nclass SEBlock(nn.Module):\n    \"\"\"Squeeze-and-Excitation block for channel attention.\"\"\"\n    def __init__(self, channels, reduction=8):\n        super().__init__()\n        self.fc1 = nn.Linear(channels, channels // reduction)\n        self.fc2 = nn.Linear(channels // reduction, channels)\n    \n    def forward(self, x):\n        # x: (B, C, L)\n        b, c, _ = x.size()\n        y = F.adaptive_avg_pool1d(x, 1).view(b, c)\n        y = F.relu(self.fc1(y))\n        y = torch.sigmoid(self.fc2(y)).view(b, c, 1)\n        return x * y\n\nclass EnhancedResidualBlock(nn.Module):\n    \"\"\"Enhanced residual block with SE attention.\"\"\"\n    def __init__(self, channels, kernel_size=3, dropout=0.1):\n        super().__init__()\n        self.conv1 = nn.Conv1d(channels, channels, kernel_size=kernel_size, padding=kernel_size//2)\n        self.conv2 = nn.Conv1d(channels, channels, kernel_size=kernel_size, padding=kernel_size//2)\n        self.norm1 = nn.BatchNorm1d(channels)\n        self.norm2 = nn.BatchNorm1d(channels)\n        self.se = SEBlock(channels)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        residual = x\n        x = self.norm1(x)\n        x = F.gelu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.norm2(x)\n        x = self.conv2(x)\n        x = self.se(x)\n        return F.gelu(residual + x)\n\nclass TemporalAttention(nn.Module):\n    \"\"\"Temporal attention mechanism.\"\"\"\n    def __init__(self, d_model, num_heads=8, dropout=0.1):\n        super().__init__()\n        self.attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.ff = nn.Sequential(\n            nn.Linear(d_model, d_model * 4),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 4, d_model),\n            nn.Dropout(dropout)\n        )\n    \n    def forward(self, x):\n        # x: (B, L, C)\n        attn_out, _ = self.attention(x, x, x)\n        x = self.norm1(x + attn_out)\n        ff_out = self.ff(x)\n        x = self.norm2(x + ff_out)\n        return x\n\nclass EnhancedApneaModel(nn.Module):\n    \"\"\"Enhanced multi-scale CNN-Transformer with advanced features.\"\"\"\n    def __init__(self, d_model=256, n_cnn_layers=8, n_attn_layers=2, dropout=0.3):\n        super().__init__()\n        \n        # Multi-scale input projection\n        channels_per_scale = [d_model//4, d_model//4, d_model//2]  # Sums to d_model\n        self.input_proj = nn.ModuleList([\n            nn.Conv1d(1, channels_per_scale[i], kernel_size=k, padding=k//2) \n            for i, k in enumerate([3, 5, 7])\n        ])\n        self.input_combine = nn.Conv1d(d_model, d_model, kernel_size=1)\n        self.input_norm = nn.BatchNorm1d(d_model)\n        \n        # Deep CNN feature extraction with varying kernel sizes\n        self.cnn_blocks = nn.ModuleList()\n        for i in range(n_cnn_layers):\n            kernel_size = 3 if i % 2 == 0 else 5\n            self.cnn_blocks.append(EnhancedResidualBlock(d_model, kernel_size, dropout))\n        \n        # Downsample for attention\n        self.downsample = nn.Conv1d(d_model, d_model, kernel_size=3, stride=2, padding=1)\n        \n        # Temporal attention layers\n        self.attn_layers = nn.ModuleList([\n            TemporalAttention(d_model, num_heads=8, dropout=dropout)\n            for _ in range(n_attn_layers)\n        ])\n        \n        # Multi-scale feature aggregation\n        self.global_pool = nn.AdaptiveAvgPool1d(1)\n        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n        \n        # Enhanced classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 4, d_model * 2),\n            nn.BatchNorm1d(d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model, 2)\n        )\n        \n    def forward(self, x):\n        # x: (B, L, 1)\n        x = x.transpose(1, 2)  # (B, 1, L)\n        \n        # Multi-scale input\n        multi_scale = [proj(x) for proj in self.input_proj]\n        x = torch.cat(multi_scale, dim=1)  # (B, d_model, L)\n        x = self.input_combine(x)\n        x = self.input_norm(x)\n        \n        # Deep CNN feature extraction\n        for block in self.cnn_blocks:\n            x = block(x)\n        \n        # Global pooling features\n        x_avg = self.global_pool(x).squeeze(-1)  # (B, d_model)\n        x_max = self.global_max_pool(x).squeeze(-1)  # (B, d_model)\n        \n        # Downsample and apply attention\n        x_down = self.downsample(x)  # (B, d_model, L/2)\n        x_seq = x_down.transpose(1, 2)  # (B, L/2, d_model)\n        \n        for attn_layer in self.attn_layers:\n            x_seq = attn_layer(x_seq)\n        \n        x_attn_avg = x_seq.mean(dim=1)  # (B, d_model)\n        x_attn_max = x_seq.max(dim=1)[0]  # (B, d_model)\n        \n        # Concatenate all features\n        x_combined = torch.cat([x_avg, x_max, x_attn_avg, x_attn_max], dim=-1)\n        \n        # Classification\n        logits = self.classifier(x_combined)\n        return logits\n\n# --------------------------- Enhanced Dataset ---------------------------\n\nclass EnhancedApneaDataset(Dataset):\n    \"\"\"Enhanced dataset with better preprocessing and augmentation.\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 6000, stride: int = 3000, split='train', augment=True):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        self.augment = augment and (split == 'train')\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_cache_enhanced_{split}_{segment_length}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} dataset from {cache_file}\")\n            data = torch.load(cache_file)\n            self.segments = data['segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb not available\"\n            assert record_names is not None, \"record_names required\"\n            \n            self.segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split}...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.segments) == 0:\n                raise RuntimeError(\"No segments loaded\")\n            \n            self.segments = torch.tensor(np.stack(self.segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving {split} cache to {cache_file}\")\n            torch.save({'segments': self.segments, 'labels': self.labels}, cache_file)\n\n        if self.segments.ndim == 2:\n            self.segments = self.segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()}: {len(self.segments)} segments. \"\n              f\"Class dist: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            record = wfdb.rdrecord(str(self.data_dir / record_name))\n            signal = record.p_signal[:, 0].astype(np.float32)\n    \n            # Handle NaNs\n            if np.isnan(signal).any():\n                nans = np.isnan(signal)\n                not_nans = ~nans\n                if not_nans.sum() > 0:\n                    signal[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(not_nans), signal[not_nans])\n                else:\n                    signal = np.zeros_like(signal)\n    \n            annotation = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            \n            n_minutes = len(signal) // 6000\n            minute_labels = np.zeros(n_minutes, dtype=int)\n            \n            for i, symbol in enumerate(annotation.symbol):\n                if symbol == 'A':\n                    sample = annotation.sample[i]\n                    minute = sample // 6000\n                    if minute < n_minutes:\n                        minute_labels[minute] = 1\n    \n            n_samples = len(signal)\n            for start in range(0, n_samples - self.segment_length + 1, self.stride):\n                end = start + self.segment_length\n                seg = signal[start:end].astype(np.float32)\n    \n                # Robust normalization with better scaling\n                seg_mean = np.nanmean(seg)\n                seg_std = np.nanstd(seg)\n                if np.isnan(seg_std) or seg_std < 1e-8:\n                    seg = seg - seg_mean\n                else:\n                    seg = (seg - seg_mean) / (seg_std + 1e-8)\n                \n                # Clip extreme values\n                seg = np.clip(seg, -10, 10)\n    \n                minute = start // 6000\n                if minute < len(minute_labels):\n                    label = minute_labels[minute]\n                    self.segments.append(seg)\n                    self.labels.append(int(label))\n                    \n        except Exception as e:\n            print(f\"\\nError loading {record_name}: {e}\")\n    \n    def _augment(self, seg):\n        \"\"\"Apply augmentation to segment.\"\"\"\n        if np.random.random() < 0.3:\n            # Add Gaussian noise\n            noise = np.random.normal(0, 0.05, seg.shape)\n            seg = seg + noise\n        \n        if np.random.random() < 0.3:\n            # Scale\n            scale = np.random.uniform(0.9, 1.1)\n            seg = seg * scale\n        \n        if np.random.random() < 0.2:\n            # Time shift\n            shift = np.random.randint(-50, 50)\n            seg = np.roll(seg, shift, axis=0)\n        \n        return seg\n            \n    def __len__(self):\n        return self.segments.shape[0]\n\n    def __getitem__(self, idx):\n        seg = self.segments[idx]\n        label = self.labels[idx]\n        \n        if self.augment:\n            seg = seg.numpy()\n            seg = self._augment(seg)\n            seg = torch.from_numpy(seg)\n        \n        # Ensure shape is (L, 1) not (L,) or (L, 1, 1)\n        if seg.ndim == 1:\n            seg = seg.unsqueeze(-1)\n        elif seg.ndim == 3:\n            seg = seg.squeeze()\n            if seg.ndim == 1:\n                seg = seg.unsqueeze(-1)\n        \n        return seg, label\n\n# -------------------------- Training / Validation ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model, dataloader, criterion, optimizer, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 20)\n    \n    start_time = time.time()\n\n    for batch_idx, (data, target) in enumerate(dataloader, 1):\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad()\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(data)\n            loss = criterion(output, target)\n        \n        if torch.isnan(loss):\n            print(f\"\\nWARNING: NaN loss at batch {batch_idx}, skipping...\")\n            continue\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            elapsed = time.time() - start_time\n            speed = batch_idx / elapsed\n            eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n            \n            print(f\"  Epoch {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"Speed: {speed:.1f} b/s ETA: {eta:.0f}s\", end='\\r')\n\n    print()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for data, target in dataloader:\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().numpy().tolist())\n            all_targets.extend(target.cpu().numpy().tolist())\n            all_probs.extend(probs.cpu().numpy().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    precision = precision_score(all_targets, all_preds, zero_division=0)\n    recall = recall_score(all_targets, all_preds, zero_division=0)\n    f1 = f1_score(all_targets, all_preds, zero_division=0)\n    \n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs), precision, recall, f1\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    # Find valid records\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(f\"No valid records found\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    # Split records\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train: {len(train_records)} records, Val: {len(val_records)} records\\n\")\n\n    # Create datasets with augmentation\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), record_names=train_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='train', augment=True\n    )\n    val_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), record_names=val_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='val', augment=False\n    )\n\n    # DataLoaders\n    num_workers = 2 if str(DATA_DIR).startswith('/kaggle') else 4\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    # Setup device and model\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"\\nUsing device: {device}\")\n    if device.type == 'cuda':\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n\n    model = EnhancedApneaModel(\n        d_model=args.d_model, \n        n_cnn_layers=args.n_cnn_layers,\n        n_attn_layers=args.n_attn_layers,\n        dropout=args.dropout\n    ).to(device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Model parameters: {total_params:,}\\n\")\n\n    # Focal loss for better class imbalance handling\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n    criterion = FocalLoss(alpha=class_weights, gamma=2.0)\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(), \n        lr=args.lr, \n        weight_decay=args.weight_decay,\n        betas=(0.9, 0.999)\n    )\n    \n    # Cosine annealing with warmup\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n        optimizer, \n        T_0=10,\n        T_mult=2,\n        eta_min=1e-6\n    )\n\n    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    best_val_f1 = 0.0\n    no_improve = 0\n\n    # Training loop\n    print(\"\\nStarting training...\")\n    print(\"=\"*90)\n    \n    for epoch in range(1, args.epochs + 1):\n        epoch_start = time.time()\n        \n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, device, epoch, scaler=scaler\n        )\n        \n        val_loss, val_acc, val_preds, val_targets, val_probs, precision, recall, f1 = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except Exception:\n            auc = 0.0\n\n        scheduler.step()\n        epoch_time = time.time() - epoch_start\n        \n        print(f\"Epoch {epoch:2d}/{args.epochs} - Time: {epoch_time:.1f}s - LR: {optimizer.param_groups[0]['lr']:.2e}\")\n        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n        print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, AUC: {auc:.4f}\")\n        print(f\"  Val   - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n\n        improved = False\n        if val_acc > best_val_acc or (val_acc == best_val_acc and f1 > best_val_f1):\n            best_val_acc = val_acc\n            best_val_f1 = f1\n            no_improve = 0\n            improved = True\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_acc': val_acc,\n                'val_auc': auc,\n                'val_f1': f1\n            }, args.best_model_path)\n            print(f\"  ✓ New best! (Acc: {val_acc:.2f}%, F1: {f1:.4f})\")\n        else:\n            no_improve += 1\n            print(f\"  No improvement ({no_improve}/{args.patience})\")\n\n        print(\"-\"*90)\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stopping after {epoch} epochs\")\n            break\n\n    print(f\"\\n{'='*90}\")\n    print(f\"Training finished!\")\n    print(f\"Best validation - Accuracy: {best_val_acc:.2f}%, F1: {best_val_f1:.4f}\")\n    print(f\"{'='*90}\")\n\nif __name__ == '__main__':\n    kaggle_data = '/kaggle/input/vincent/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    \n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_model_enhanced.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_model_enhanced.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_model_enhanced.pth'\n    \n    parser = argparse.ArgumentParser(description='Enhanced apnea detection (90%+ target)')\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=6000)  # 60s segments\n    parser.add_argument('--stride', type=int, default=3000)  # 50% overlap\n    parser.add_argument('--batch-size', type=int, default=32)  # Larger model needs smaller batch\n    parser.add_argument('--epochs', type=int, default=100)\n    parser.add_argument('--lr', type=float, default=1e-4)\n    parser.add_argument('--weight-decay', type=float, default=1e-4)\n    parser.add_argument('--d-model', type=int, default=256)\n    parser.add_argument('--n-cnn-layers', type=int, default=8)\n    parser.add_argument('--n-attn-layers', type=int, default=2)\n    parser.add_argument('--dropout', type=float, default=0.3)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--num-workers', type=int, default=4)\n    parser.add_argument('--patience', type=int, default=15)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n    \n    if args.data_dir is None:\n        raise SystemExit(f\"\\nERROR: Dataset not found\\n\")\n    \n    print(\"=\"*90)\n    print(\"ENHANCED MODEL CONFIGURATION (Target: 90%+ Accuracy)\")\n    print(\"=\"*90)\n    print(f\"  Data:          {args.data_dir}\")\n    print(f\"  Cache:         {args.cache_dir}\")\n    print(f\"  Model save:    {args.best_model_path}\")\n    print(f\"  Segment:       {args.segment_length} samples (60s) with augmentation\")\n    print(f\"  Batch size:    {args.batch_size}\")\n    print(f\"  Epochs:        {args.epochs}\")\n    print(f\"  Learning rate: {args.lr}\")\n    print(f\"  Model:         d_model={args.d_model}, cnn_layers={args.n_cnn_layers}, \"\n          f\"attn_layers={args.n_attn_layers}, dropout={args.dropout}\")\n    print(f\"  Loss:          Focal Loss (gamma=2.0)\")\n    print(\"=\"*90 + \"\\n\")\n    \n    main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:01:38.915124Z","iopub.execute_input":"2025-12-01T06:01:38.915420Z","iopub.status.idle":"2025-12-01T06:02:04.824096Z","shell.execute_reply.started":"2025-12-01T06:01:38.915393Z","shell.execute_reply":"2025-12-01T06:02:04.822913Z"}},"outputs":[{"name":"stdout","text":"==========================================================================================\nENHANCED MODEL CONFIGURATION (Target: 90%+ Accuracy)\n==========================================================================================\n  Data:          /kaggle/input/vincent/apnea-ecg-database-1.0.0\n  Cache:         /kaggle/working\n  Model save:    /kaggle/working/best_model_enhanced.pth\n  Segment:       6000 samples (60s) with augmentation\n  Batch size:    32\n  Epochs:        100\n  Learning rate: 0.0001\n  Model:         d_model=256, cnn_layers=8, attn_layers=2, dropout=0.3\n  Loss:          Focal Loss (gamma=2.0)\n==========================================================================================\n\nFound 43 valid records\nTrain: 34 records, Val: 9 records\n\nProcessing 34 records for train...\n  [34/34] a20....\nSaving train cache to /kaggle/working/apnea_cache_enhanced_train_6000.pt\nTrain: 33411 segments. Class dist: Counter({0: 21112, 1: 12299})\nProcessing 9 records for val...\n  [9/9] a01....\nSaving val cache to /kaggle/working/apnea_cache_enhanced_val_6000.pt\nVal: 8622 segments. Class dist: Counter({0: 4687, 1: 3935})\n\nUsing device: cuda\nGPU: Tesla P100-PCIE-16GB\nModel parameters: 6,842,498\n\nClass weights: tensor([0.7913, 1.3583], device='cuda:0')\n\nStarting training...\n==========================================================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2849120952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m90\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_47/2849120952.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         train_loss, train_acc = train_epoch(\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         )\n","\u001b[0;32m/tmp/ipykernel_47/2849120952.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device, epoch, scaler)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2849120952.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattn_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mx_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mx_attn_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/2849120952.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# x: (B, L, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mattn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mff_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             )\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6373\u001b[0m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6374\u001b[0;31m         \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6376\u001b[0m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 8.58 GiB. GPU 0 has a total capacity of 15.89 GiB of which 4.98 GiB is free. Process 2715 has 10.90 GiB memory in use. Of the allocated memory 10.49 GiB is allocated by PyTorch, and 132.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 8.58 GiB. GPU 0 has a total capacity of 15.89 GiB of which 4.98 GiB is free. Process 2715 has 10.90 GiB memory in use. Of the allocated memory 10.49 GiB is allocated by PyTorch, and 132.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}