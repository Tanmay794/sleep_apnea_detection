{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13805488,"sourceType":"datasetVersion","datasetId":8790446}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wfdb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T08:25:36.713457Z","iopub.execute_input":"2025-11-29T08:25:36.714174Z","iopub.status.idle":"2025-11-29T08:25:41.483279Z","shell.execute_reply.started":"2025-11-29T08:25:36.714153Z","shell.execute_reply":"2025-11-29T08:25:41.482090Z"}},"outputs":[{"name":"stdout","text":"Collecting wfdb\n  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.13.2)\nRequirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2025.10.0)\nRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.7.2)\nRequirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.26.4)\nRequirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.2.3)\nRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.32.5)\nRequirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.15.3)\nRequirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (0.13.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.22.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2025.10.5)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.23)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.4->wfdb) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.4->wfdb) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.4->wfdb) (2024.2.0)\nDownloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: wfdb\nSuccessfully installed wfdb-4.3.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nEnhanced CNN-Transformer hybrid for apnea detection targeting 90%+ accuracy.\nKey improvements:\n- Deeper architecture with better feature extraction\n- Advanced augmentation techniques\n- Improved loss function with focal loss\n- Better normalization and regularization\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- Focal Loss ---------------------------------\n\nclass FocalLoss(nn.Module):\n    \"\"\"Focal loss for handling class imbalance better than CE.\"\"\"\n    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n    \n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n        pt = torch.exp(-ce_loss)\n        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n        \n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        return focal_loss\n\n# ----------------------------- Enhanced Model ------------------------------\n\nclass SEBlock(nn.Module):\n    \"\"\"Squeeze-and-Excitation block for channel attention.\"\"\"\n    def __init__(self, channels, reduction=8):\n        super().__init__()\n        self.fc1 = nn.Linear(channels, channels // reduction)\n        self.fc2 = nn.Linear(channels // reduction, channels)\n    \n    def forward(self, x):\n        # x: (B, C, L)\n        b, c, _ = x.size()\n        y = F.adaptive_avg_pool1d(x, 1).view(b, c)\n        y = F.relu(self.fc1(y))\n        y = torch.sigmoid(self.fc2(y)).view(b, c, 1)\n        return x * y\n\nclass EnhancedResidualBlock(nn.Module):\n    \"\"\"Enhanced residual block with SE attention.\"\"\"\n    def __init__(self, channels, kernel_size=3, dropout=0.1):\n        super().__init__()\n        self.conv1 = nn.Conv1d(channels, channels, kernel_size=kernel_size, padding=kernel_size//2)\n        self.conv2 = nn.Conv1d(channels, channels, kernel_size=kernel_size, padding=kernel_size//2)\n        self.norm1 = nn.BatchNorm1d(channels)\n        self.norm2 = nn.BatchNorm1d(channels)\n        self.se = SEBlock(channels)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        residual = x\n        x = self.norm1(x)\n        x = F.gelu(self.conv1(x))\n        x = self.dropout(x)\n        x = self.norm2(x)\n        x = self.conv2(x)\n        x = self.se(x)\n        return F.gelu(residual + x)\n\nclass TemporalAttention(nn.Module):\n    \"\"\"Temporal attention mechanism.\"\"\"\n    def __init__(self, d_model, num_heads=8, dropout=0.1):\n        super().__init__()\n        self.attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.ff = nn.Sequential(\n            nn.Linear(d_model, d_model * 4),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 4, d_model),\n            nn.Dropout(dropout)\n        )\n    \n    def forward(self, x):\n        # x: (B, L, C)\n        attn_out, _ = self.attention(x, x, x)\n        x = self.norm1(x + attn_out)\n        ff_out = self.ff(x)\n        x = self.norm2(x + ff_out)\n        return x\n\nclass EnhancedApneaModel(nn.Module):\n    \"\"\"Enhanced multi-scale CNN-Transformer with advanced features.\"\"\"\n    def __init__(self, d_model=256, n_cnn_layers=8, n_attn_layers=2, dropout=0.3):\n        super().__init__()\n        \n        # Multi-scale input projection\n        channels_per_scale = [d_model//4, d_model//4, d_model//2]  # Sums to d_model\n        self.input_proj = nn.ModuleList([\n            nn.Conv1d(1, channels_per_scale[i], kernel_size=k, padding=k//2) \n            for i, k in enumerate([3, 5, 7])\n        ])\n        self.input_combine = nn.Conv1d(d_model, d_model, kernel_size=1)\n        self.input_norm = nn.BatchNorm1d(d_model)\n        \n        # Deep CNN feature extraction with varying kernel sizes\n        self.cnn_blocks = nn.ModuleList()\n        for i in range(n_cnn_layers):\n            kernel_size = 3 if i % 2 == 0 else 5\n            self.cnn_blocks.append(EnhancedResidualBlock(d_model, kernel_size, dropout))\n        \n        # Downsample for attention\n        self.downsample = nn.Conv1d(d_model, d_model, kernel_size=3, stride=2, padding=1)\n        \n        # Temporal attention layers\n        self.attn_layers = nn.ModuleList([\n            TemporalAttention(d_model, num_heads=8, dropout=dropout)\n            for _ in range(n_attn_layers)\n        ])\n        \n        # Multi-scale feature aggregation\n        self.global_pool = nn.AdaptiveAvgPool1d(1)\n        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n        \n        # Enhanced classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 4, d_model * 2),\n            nn.BatchNorm1d(d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model, 2)\n        )\n        \n    def forward(self, x):\n        # x: (B, L, 1)\n        x = x.transpose(1, 2)  # (B, 1, L)\n        \n        # Multi-scale input\n        multi_scale = [proj(x) for proj in self.input_proj]\n        x = torch.cat(multi_scale, dim=1)  # (B, d_model, L)\n        x = self.input_combine(x)\n        x = self.input_norm(x)\n        \n        # Deep CNN feature extraction\n        for block in self.cnn_blocks:\n            x = block(x)\n        \n        # Global pooling features\n        x_avg = self.global_pool(x).squeeze(-1)  # (B, d_model)\n        x_max = self.global_max_pool(x).squeeze(-1)  # (B, d_model)\n        \n        # Downsample and apply attention\n        x_down = self.downsample(x)  # (B, d_model, L/2)\n        x_seq = x_down.transpose(1, 2)  # (B, L/2, d_model)\n        \n        for attn_layer in self.attn_layers:\n            x_seq = attn_layer(x_seq)\n        \n        x_attn_avg = x_seq.mean(dim=1)  # (B, d_model)\n        x_attn_max = x_seq.max(dim=1)[0]  # (B, d_model)\n        \n        # Concatenate all features\n        x_combined = torch.cat([x_avg, x_max, x_attn_avg, x_attn_max], dim=-1)\n        \n        # Classification\n        logits = self.classifier(x_combined)\n        return logits\n\n# --------------------------- Enhanced Dataset ---------------------------\n\nclass EnhancedApneaDataset(Dataset):\n    \"\"\"Enhanced dataset with better preprocessing and augmentation.\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 6000, stride: int = 3000, split='train', augment=True):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        self.augment = augment and (split == 'train')\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_cache_enhanced_{split}_{segment_length}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} dataset from {cache_file}\")\n            data = torch.load(cache_file)\n            self.segments = data['segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb not available\"\n            assert record_names is not None, \"record_names required\"\n            \n            self.segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split}...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.segments) == 0:\n                raise RuntimeError(\"No segments loaded\")\n            \n            self.segments = torch.tensor(np.stack(self.segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving {split} cache to {cache_file}\")\n            torch.save({'segments': self.segments, 'labels': self.labels}, cache_file)\n\n        if self.segments.ndim == 2:\n            self.segments = self.segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()}: {len(self.segments)} segments. \"\n              f\"Class dist: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            record = wfdb.rdrecord(str(self.data_dir / record_name))\n            signal = record.p_signal[:, 0].astype(np.float32)\n    \n            # Handle NaNs\n            if np.isnan(signal).any():\n                nans = np.isnan(signal)\n                not_nans = ~nans\n                if not_nans.sum() > 0:\n                    signal[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(not_nans), signal[not_nans])\n                else:\n                    signal = np.zeros_like(signal)\n    \n            annotation = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            \n            n_minutes = len(signal) // 6000\n            minute_labels = np.zeros(n_minutes, dtype=int)\n            \n            for i, symbol in enumerate(annotation.symbol):\n                if symbol == 'A':\n                    sample = annotation.sample[i]\n                    minute = sample // 6000\n                    if minute < n_minutes:\n                        minute_labels[minute] = 1\n    \n            n_samples = len(signal)\n            for start in range(0, n_samples - self.segment_length + 1, self.stride):\n                end = start + self.segment_length\n                seg = signal[start:end].astype(np.float32)\n    \n                # Robust normalization with better scaling\n                seg_mean = np.nanmean(seg)\n                seg_std = np.nanstd(seg)\n                if np.isnan(seg_std) or seg_std < 1e-8:\n                    seg = seg - seg_mean\n                else:\n                    seg = (seg - seg_mean) / (seg_std + 1e-8)\n                \n                # Clip extreme values\n                seg = np.clip(seg, -10, 10)\n    \n                minute = start // 6000\n                if minute < len(minute_labels):\n                    label = minute_labels[minute]\n                    self.segments.append(seg)\n                    self.labels.append(int(label))\n                    \n        except Exception as e:\n            print(f\"\\nError loading {record_name}: {e}\")\n    \n    def _augment(self, seg):\n        \"\"\"Apply augmentation to segment.\"\"\"\n        if np.random.random() < 0.3:\n            # Add Gaussian noise\n            noise = np.random.normal(0, 0.05, seg.shape)\n            seg = seg + noise\n        \n        if np.random.random() < 0.3:\n            # Scale\n            scale = np.random.uniform(0.9, 1.1)\n            seg = seg * scale\n        \n        if np.random.random() < 0.2:\n            # Time shift\n            shift = np.random.randint(-50, 50)\n            seg = np.roll(seg, shift, axis=0)\n        \n        return seg\n            \n    def __len__(self):\n        return self.segments.shape[0]\n\n    def __getitem__(self, idx):\n        seg = self.segments[idx]\n        label = self.labels[idx]\n        \n        if self.augment:\n            seg = seg.numpy()\n            seg = self._augment(seg)\n            seg = torch.from_numpy(seg)\n        \n        # Ensure shape is (L, 1) not (L,) or (L, 1, 1)\n        if seg.ndim == 1:\n            seg = seg.unsqueeze(-1)\n        elif seg.ndim == 3:\n            seg = seg.squeeze()\n            if seg.ndim == 1:\n                seg = seg.unsqueeze(-1)\n        \n        return seg, label\n\n# -------------------------- Training / Validation ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model, dataloader, criterion, optimizer, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 20)\n    \n    start_time = time.time()\n\n    for batch_idx, (data, target) in enumerate(dataloader, 1):\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad()\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(data)\n            loss = criterion(output, target)\n        \n        if torch.isnan(loss):\n            print(f\"\\nWARNING: NaN loss at batch {batch_idx}, skipping...\")\n            continue\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            elapsed = time.time() - start_time\n            speed = batch_idx / elapsed\n            eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n            \n            print(f\"  Epoch {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"Speed: {speed:.1f} b/s ETA: {eta:.0f}s\", end='\\r')\n\n    print()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for data, target in dataloader:\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().numpy().tolist())\n            all_targets.extend(target.cpu().numpy().tolist())\n            all_probs.extend(probs.cpu().numpy().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    precision = precision_score(all_targets, all_preds, zero_division=0)\n    recall = recall_score(all_targets, all_preds, zero_division=0)\n    f1 = f1_score(all_targets, all_preds, zero_division=0)\n    \n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs), precision, recall, f1\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    # Find valid records\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(f\"No valid records found\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    # Split records\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train: {len(train_records)} records, Val: {len(val_records)} records\\n\")\n\n    # Create datasets with augmentation\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), record_names=train_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='train', augment=True\n    )\n    val_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), record_names=val_records, cache_dir=cache_dir,\n        segment_length=args.segment_length, stride=args.stride, split='val', augment=False\n    )\n\n    # DataLoaders\n    num_workers = 2 if str(DATA_DIR).startswith('/kaggle') else 4\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    # Setup device and model\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"\\nUsing device: {device}\")\n    if device.type == 'cuda':\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n\n    model = EnhancedApneaModel(\n        d_model=args.d_model, \n        n_cnn_layers=args.n_cnn_layers,\n        n_attn_layers=args.n_attn_layers,\n        dropout=args.dropout\n    ).to(device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Model parameters: {total_params:,}\\n\")\n\n    # Focal loss for better class imbalance handling\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n    criterion = FocalLoss(alpha=class_weights, gamma=2.0)\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(), \n        lr=args.lr, \n        weight_decay=args.weight_decay,\n        betas=(0.9, 0.999)\n    )\n    \n    # Cosine annealing with warmup\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n        optimizer, \n        T_0=10,\n        T_mult=2,\n        eta_min=1e-6\n    )\n\n    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    best_val_f1 = 0.0\n    no_improve = 0\n\n    # Training loop\n    print(\"\\nStarting training...\")\n    print(\"=\"*90)\n    \n    for epoch in range(1, args.epochs + 1):\n        epoch_start = time.time()\n        \n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, device, epoch, scaler=scaler\n        )\n        \n        val_loss, val_acc, val_preds, val_targets, val_probs, precision, recall, f1 = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except Exception:\n            auc = 0.0\n\n        scheduler.step()\n        epoch_time = time.time() - epoch_start\n        \n        print(f\"Epoch {epoch:2d}/{args.epochs} - Time: {epoch_time:.1f}s - LR: {optimizer.param_groups[0]['lr']:.2e}\")\n        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n        print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, AUC: {auc:.4f}\")\n        print(f\"  Val   - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n\n        improved = False\n        if val_acc > best_val_acc or (val_acc == best_val_acc and f1 > best_val_f1):\n            best_val_acc = val_acc\n            best_val_f1 = f1\n            no_improve = 0\n            improved = True\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_acc': val_acc,\n                'val_auc': auc,\n                'val_f1': f1\n            }, args.best_model_path)\n            print(f\"  ✓ New best! (Acc: {val_acc:.2f}%, F1: {f1:.4f})\")\n        else:\n            no_improve += 1\n            print(f\"  No improvement ({no_improve}/{args.patience})\")\n\n        print(\"-\"*90)\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stopping after {epoch} epochs\")\n            break\n\n    print(f\"\\n{'='*90}\")\n    print(f\"Training finished!\")\n    print(f\"Best validation - Accuracy: {best_val_acc:.2f}%, F1: {best_val_f1:.4f}\")\n    print(f\"{'='*90}\")\n\nif __name__ == '__main__':\n    kaggle_data = '/kaggle/input/vincent2/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    \n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_model_enhanced.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_model_enhanced.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_model_enhanced.pth'\n    \n    parser = argparse.ArgumentParser(description='Enhanced apnea detection (90%+ target)')\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=6000)  # 60s segments\n    parser.add_argument('--stride', type=int, default=3000)  # 50% overlap\n    parser.add_argument('--batch-size', type=int, default=32)  # Larger model needs smaller batch\n    parser.add_argument('--epochs', type=int, default=100)\n    parser.add_argument('--lr', type=float, default=1e-4)\n    parser.add_argument('--weight-decay', type=float, default=1e-4)\n    parser.add_argument('--d-model', type=int, default=256)\n    parser.add_argument('--n-cnn-layers', type=int, default=8)\n    parser.add_argument('--n-attn-layers', type=int, default=2)\n    parser.add_argument('--dropout', type=float, default=0.3)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--num-workers', type=int, default=4)\n    parser.add_argument('--patience', type=int, default=15)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n    \n    if args.data_dir is None:\n        raise SystemExit(f\"\\nERROR: Dataset not found\\n\")\n    \n    print(\"=\"*90)\n    print(\"ENHANCED MODEL CONFIGURATION (Target: 90%+ Accuracy)\")\n    print(\"=\"*90)\n    print(f\"  Data:          {args.data_dir}\")\n    print(f\"  Cache:         {args.cache_dir}\")\n    print(f\"  Model save:    {args.best_model_path}\")\n    print(f\"  Segment:       {args.segment_length} samples (60s) with augmentation\")\n    print(f\"  Batch size:    {args.batch_size}\")\n    print(f\"  Epochs:        {args.epochs}\")\n    print(f\"  Learning rate: {args.lr}\")\n    print(f\"  Model:         d_model={args.d_model}, cnn_layers={args.n_cnn_layers}, \"\n          f\"attn_layers={args.n_attn_layers}, dropout={args.dropout}\")\n    print(f\"  Loss:          Focal Loss (gamma=2.0)\")\n    print(\"=\"*90 + \"\\n\")\n    \n    main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T14:42:40.464402Z","iopub.execute_input":"2025-11-20T14:42:40.464681Z","iopub.status.idle":"2025-11-20T14:43:06.925248Z","shell.execute_reply.started":"2025-11-20T14:42:40.464649Z","shell.execute_reply":"2025-11-20T14:43:06.923893Z"}},"outputs":[{"name":"stdout","text":"==========================================================================================\nENHANCED MODEL CONFIGURATION (Target: 90%+ Accuracy)\n==========================================================================================\n  Data:          /kaggle/input/vincent2/apnea-ecg-database-1.0.0\n  Cache:         /kaggle/working\n  Model save:    /kaggle/working/best_model_enhanced.pth\n  Segment:       6000 samples (60s) with augmentation\n  Batch size:    32\n  Epochs:        100\n  Learning rate: 0.0001\n  Model:         d_model=256, cnn_layers=8, attn_layers=2, dropout=0.3\n  Loss:          Focal Loss (gamma=2.0)\n==========================================================================================\n\nFound 43 valid records\nTrain: 34 records, Val: 9 records\n\nProcessing 34 records for train...\n  [34/34] a20....\nSaving train cache to /kaggle/working/apnea_cache_enhanced_train_6000.pt\nTrain: 33411 segments. Class dist: Counter({0: 21112, 1: 12299})\nProcessing 9 records for val...\n  [9/9] a01....\nSaving val cache to /kaggle/working/apnea_cache_enhanced_val_6000.pt\nVal: 8622 segments. Class dist: Counter({0: 4687, 1: 3935})\n\nUsing device: cuda\nGPU: Tesla P100-PCIE-16GB\nModel parameters: 6,842,498\n\nClass weights: tensor([0.7913, 1.3583], device='cuda:0')\n\nStarting training...\n==========================================================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/2633684732.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m90\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_48/2633684732.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         train_loss, train_acc = train_epoch(\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         )\n","\u001b[0;32m/tmp/ipykernel_48/2633684732.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device, epoch, scaler)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/2633684732.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattn_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mx_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mx_attn_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/2633684732.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# x: (B, L, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mattn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mff_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             )\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6373\u001b[0m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6374\u001b[0;31m         \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6376\u001b[0m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 8.58 GiB. GPU 0 has a total capacity of 15.89 GiB of which 4.98 GiB is free. Process 2338 has 10.90 GiB memory in use. Of the allocated memory 10.49 GiB is allocated by PyTorch, and 132.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 8.58 GiB. GPU 0 has a total capacity of 15.89 GiB of which 4.98 GiB is free. Process 2338 has 10.90 GiB memory in use. Of the allocated memory 10.49 GiB is allocated by PyTorch, and 132.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nMemory-efficient high-performance model for 90%+ apnea detection accuracy.\nOptimized for Tesla P100 16GB GPU.\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- Efficient Model ---------------------------\n\nclass EfficientResBlock(nn.Module):\n    \"\"\"Efficient residual block with depthwise separable convolutions.\"\"\"\n    def __init__(self, channels, kernel_size=7):\n        super().__init__()\n        # Depthwise\n        self.depthwise = nn.Conv1d(channels, channels, kernel_size, padding=kernel_size//2, groups=channels)\n        # Pointwise\n        self.pointwise = nn.Conv1d(channels, channels, 1)\n        self.norm = nn.BatchNorm1d(channels)\n        self.dropout = nn.Dropout(0.1)\n        \n    def forward(self, x):\n        residual = x\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        x = self.norm(x)\n        x = self.dropout(x)\n        return F.gelu(residual + x)\n\n\nclass EfficientApneaNet(nn.Module):\n    \"\"\"Memory-efficient architecture for high accuracy.\"\"\"\n    def __init__(self, d_model=128, n_blocks=6, dropout=0.2):\n        super().__init__()\n        \n        # Input stem with multi-scale\n        self.stem = nn.Sequential(\n            nn.Conv1d(1, d_model//2, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(d_model//2),\n            nn.GELU(),\n            nn.Conv1d(d_model//2, d_model, kernel_size=5, padding=2, stride=2),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n        )\n        \n        # Efficient residual blocks with varying receptive fields\n        self.blocks = nn.ModuleList([\n            EfficientResBlock(d_model, kernel_size=7 if i % 2 == 0 else 11)\n            for i in range(n_blocks)\n        ])\n        \n        # Lightweight attention\n        self.channel_attn = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Conv1d(d_model, d_model//4, 1),\n            nn.GELU(),\n            nn.Conv1d(d_model//4, d_model, 1),\n            nn.Sigmoid()\n        )\n        \n        # Temporal attention (memory efficient)\n        self.temp_attn = nn.MultiheadAttention(d_model, num_heads=4, dropout=dropout, batch_first=True)\n        self.temp_norm = nn.LayerNorm(d_model)\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 3, d_model),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model, 2)\n        )\n        \n    def forward(self, x):\n        # x: (B, L, 1) -> (B, 1, L)\n        x = x.transpose(1, 2)\n        \n        # Stem reduces sequence length by 4x\n        x = self.stem(x)  # (B, d_model, L/4)\n        \n        # Residual blocks\n        for block in self.blocks:\n            x = block(x)\n        \n        # Channel attention\n        attn_weights = self.channel_attn(x)\n        x = x * attn_weights\n        \n        # Global features\n        x_avg = F.adaptive_avg_pool1d(x, 1).squeeze(-1)  # (B, d_model)\n        x_max = F.adaptive_max_pool1d(x, 1).squeeze(-1)  # (B, d_model)\n        \n        # Temporal attention on further downsampled sequence\n        x_seq = F.adaptive_avg_pool1d(x, 50).transpose(1, 2)  # (B, 50, d_model)\n        x_attn, _ = self.temp_attn(x_seq, x_seq, x_seq)\n        x_attn = self.temp_norm(x_attn + x_seq)\n        x_attn = x_attn.mean(dim=1)  # (B, d_model)\n        \n        # Combine features\n        x_combined = torch.cat([x_avg, x_max, x_attn], dim=1)\n        \n        # Classify\n        logits = self.classifier(x_combined)\n        return logits\n\n\n# --------------------------- Dataset ---------------------------\n\nclass ApneaDataset(Dataset):\n    \"\"\"Optimized dataset with data augmentation.\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 6000, stride: int = 3000, split='train', augment=True):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        self.augment = augment and (split == 'train')\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_{split}_{segment_length}_{stride}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} from {cache_file}\")\n            data = torch.load(cache_file)\n            self.segments = data['segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb required\"\n            assert record_names is not None, \"record_names required\"\n            \n            self.segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split}...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.segments) == 0:\n                raise RuntimeError(\"No segments loaded\")\n            \n            self.segments = torch.tensor(np.stack(self.segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving cache to {cache_file}\")\n            torch.save({'segments': self.segments, 'labels': self.labels}, cache_file)\n\n        if self.segments.ndim == 2:\n            self.segments = self.segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()}: {len(self.segments)} segments, \"\n              f\"Class: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            record = wfdb.rdrecord(str(self.data_dir / record_name))\n            signal = record.p_signal[:, 0].astype(np.float32)\n    \n            if np.isnan(signal).any():\n                nans = np.isnan(signal)\n                not_nans = ~nans\n                if not_nans.sum() > 0:\n                    signal[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(not_nans), signal[not_nans])\n                else:\n                    signal = np.zeros_like(signal)\n    \n            annotation = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            \n            n_minutes = len(signal) // 6000\n            minute_labels = np.zeros(n_minutes, dtype=int)\n            \n            for i, symbol in enumerate(annotation.symbol):\n                if symbol == 'A':\n                    sample = annotation.sample[i]\n                    minute = sample // 6000\n                    if minute < n_minutes:\n                        minute_labels[minute] = 1\n    \n            n_samples = len(signal)\n            for start in range(0, n_samples - self.segment_length + 1, self.stride):\n                end = start + self.segment_length\n                seg = signal[start:end].astype(np.float32)\n    \n                seg_mean = np.nanmean(seg)\n                seg_std = np.nanstd(seg)\n                if np.isnan(seg_std) or seg_std < 1e-8:\n                    seg = seg - seg_mean\n                else:\n                    seg = (seg - seg_mean) / (seg_std + 1e-8)\n                \n                seg = np.clip(seg, -10, 10)\n    \n                minute = start // 6000\n                if minute < len(minute_labels):\n                    label = minute_labels[minute]\n                    self.segments.append(seg)\n                    self.labels.append(int(label))\n                    \n        except Exception as e:\n            print(f\"\\nError loading {record_name}: {e}\")\n    \n    def _augment(self, seg):\n        \"\"\"Light augmentation.\"\"\"\n        seg = seg.numpy() if torch.is_tensor(seg) else seg\n        \n        if np.random.random() < 0.3:\n            # Gaussian noise\n            seg = seg + np.random.normal(0, 0.03, seg.shape).astype(np.float32)\n        \n        if np.random.random() < 0.2:\n            # Scale\n            seg = seg * np.random.uniform(0.95, 1.05)\n        \n        return torch.from_numpy(seg)\n            \n    def __len__(self):\n        return self.segments.shape[0]\n\n    def __getitem__(self, idx):\n        seg = self.segments[idx]\n        label = self.labels[idx]\n        \n        if self.augment:\n            seg = self._augment(seg)\n        \n        if seg.ndim == 1:\n            seg = seg.unsqueeze(-1)\n        elif seg.ndim == 3:\n            seg = seg.squeeze(1)\n        \n        return seg, label\n\n# -------------------------- Training ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model, dataloader, criterion, optimizer, scheduler, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 15)\n    start_time = time.time()\n\n    for batch_idx, (data, target) in enumerate(dataloader, 1):\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(data)\n            loss = criterion(output, target)\n        \n        if torch.isnan(loss):\n            print(f\"\\nWARNING: NaN loss, skipping batch {batch_idx}\")\n            continue\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n        \n        scheduler.step()\n\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            speed = batch_idx / (time.time() - start_time)\n            eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n            \n            print(f\"  Ep {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"({speed:.1f} b/s, ETA: {eta:.0f}s)\", end='\\r')\n\n    print()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for data, target in dataloader:\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().tolist())\n            all_targets.extend(target.cpu().tolist())\n            all_probs.extend(probs.cpu().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    precision = precision_score(all_targets, all_preds, zero_division=0)\n    recall = recall_score(all_targets, all_preds, zero_division=0)\n    f1 = f1_score(all_targets, all_preds, zero_division=0)\n    \n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs), precision, recall, f1\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(\"No valid records found\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train: {len(train_records)}, Val: {len(val_records)}\\n\")\n\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = ApneaDataset(\n        str(DATA_DIR), train_records, cache_dir,\n        args.segment_length, args.stride, 'train', augment=True\n    )\n    val_dataset = ApneaDataset(\n        str(DATA_DIR), val_records, cache_dir,\n        args.segment_length, args.stride, 'val', augment=False\n    )\n\n    num_workers = 2 if str(DATA_DIR).startswith('/kaggle') else 4\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Device: {device}\")\n    if device.type == 'cuda':\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        torch.cuda.empty_cache()\n\n    model = EfficientApneaNet(\n        d_model=args.d_model, n_blocks=args.n_blocks, dropout=args.dropout\n    ).to(device)\n    \n    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n    )\n    \n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, max_lr=args.lr, epochs=args.epochs,\n        steps_per_epoch=len(train_loader), pct_start=0.1\n    )\n\n    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    best_val_f1 = 0.0\n    no_improve = 0\n\n    print(\"\\nStarting training...\")\n    print(\"=\"*80)\n    \n    for epoch in range(1, args.epochs + 1):\n        epoch_start = time.time()\n        \n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, scheduler, device, epoch, scaler\n        )\n        \n        val_loss, val_acc, _, val_targets, val_probs, precision, recall, f1 = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except:\n            auc = 0.0\n\n        epoch_time = time.time() - epoch_start\n        \n        print(f\"Epoch {epoch:2d}/{args.epochs} ({epoch_time:.1f}s)\")\n        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n        print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={auc:.4f}\")\n        print(f\"         Prec={precision:.3f}, Rec={recall:.3f}, F1={f1:.3f}\")\n\n        if val_acc > best_val_acc or (val_acc >= best_val_acc and f1 > best_val_f1):\n            best_val_acc = val_acc\n            best_val_f1 = f1\n            no_improve = 0\n            torch.save({\n                'epoch': epoch, 'model_state_dict': model.state_dict(),\n                'val_acc': val_acc, 'val_auc': auc, 'val_f1': f1\n            }, args.best_model_path)\n            print(f\"  ✓ Best! (Acc={val_acc:.2f}%, F1={f1:.3f})\")\n        else:\n            no_improve += 1\n            print(f\"  No improvement ({no_improve}/{args.patience})\")\n\n        print(\"-\"*80)\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stop at epoch {epoch}\")\n            break\n\n    print(f\"\\n{'='*80}\")\n    print(f\"BEST - Accuracy: {best_val_acc:.2f}%, F1: {best_val_f1:.3f}\")\n    print(f\"{'='*80}\")\n\nif __name__ == '__main__':\n    kaggle_data = '/kaggle/input/vincent2/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    \n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_model.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_model.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_model.pth'\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=6000)  # 60s\n    parser.add_argument('--stride', type=int, default=3000)  # 50% overlap\n    parser.add_argument('--batch-size', type=int, default=48)  # Optimized for P100\n    parser.add_argument('--epochs', type=int, default=80)\n    parser.add_argument('--lr', type=float, default=3e-4)\n    parser.add_argument('--weight-decay', type=float, default=1e-4)\n    parser.add_argument('--d-model', type=int, default=128)  # Efficient size\n    parser.add_argument('--n-blocks', type=int, default=8)  # Deep but efficient\n    parser.add_argument('--dropout', type=float, default=0.2)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--patience', type=int, default=15)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n    \n    if args.data_dir is None:\n        raise SystemExit(\"ERROR: Dataset not found\")\n    \n    print(\"=\"*80)\n    print(\"MEMORY-EFFICIENT MODEL (Target: 90%+ Accuracy)\")\n    print(\"=\"*80)\n    print(f\"  Data:       {args.data_dir}\")\n    print(f\"  Segment:    {args.segment_length} samples (60s), stride={args.stride}\")\n    print(f\"  Batch:      {args.batch_size}\")\n    print(f\"  Epochs:     {args.epochs}\")\n    print(f\"  Model:      d_model={args.d_model}, blocks={args.n_blocks}\")\n    print(f\"  Optimizer:  AdamW (lr={args.lr}, wd={args.weight_decay})\")\n    print(\"=\"*80 + \"\\n\")\n    \n    main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T14:47:16.090367Z","iopub.execute_input":"2025-11-20T14:47:16.090985Z","iopub.status.idle":"2025-11-20T15:05:42.254844Z","shell.execute_reply.started":"2025-11-20T14:47:16.090952Z","shell.execute_reply":"2025-11-20T15:05:42.253865Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nMEMORY-EFFICIENT MODEL (Target: 90%+ Accuracy)\n================================================================================\n  Data:       /kaggle/input/vincent2/apnea-ecg-database-1.0.0\n  Segment:    6000 samples (60s), stride=3000\n  Batch:      48\n  Epochs:     80\n  Model:      d_model=128, blocks=8\n  Optimizer:  AdamW (lr=0.0003, wd=0.0001)\n================================================================================\n\nFound 43 valid records\nTrain: 34, Val: 9\n\nProcessing 34 records for train...\n  [34/34] a20....\nSaving cache to /kaggle/working/apnea_train_6000_3000.pt\nTrain: 33411 segments, Class: Counter({0: 21112, 1: 12299})\nProcessing 9 records for val...\n  [9/9] a01....\nSaving cache to /kaggle/working/apnea_val_6000_3000.pt\nVal: 8622 segments, Class: Counter({0: 4687, 1: 3935})\nDevice: cuda\nGPU: Tesla P100-PCIE-16GB\nParameters: 310,818\n\nClass weights: tensor([0.7913, 1.3583], device='cuda:0')\n\nStarting training...\n================================================================================\n  Ep 1 [ 697/697] Loss: 0.5680 Acc: 74.52% (15.0 b/s, ETA: 0s))\nEpoch  1/80 (50.3s)\n  Train: Loss=0.5680, Acc=74.52%\n  Val:   Loss=0.6762, Acc=64.59%, AUC=0.7138\n         Prec=0.615, Rec=0.600, F1=0.607\n  ✓ Best! (Acc=64.59%, F1=0.607)\n--------------------------------------------------------------------------------\n  Ep 2 [ 697/697] Loss: 0.4765 Acc: 81.57% (15.3 b/s, ETA: 0s))\nEpoch  2/80 (49.3s)\n  Train: Loss=0.4765, Acc=81.57%\n  Val:   Loss=0.7624, Acc=62.19%, AUC=0.7090\n         Prec=0.565, Rec=0.749, F1=0.644\n  No improvement (1/15)\n--------------------------------------------------------------------------------\n  Ep 3 [ 697/697] Loss: 0.4336 Acc: 85.48% (15.3 b/s, ETA: 0s))\nEpoch  3/80 (49.4s)\n  Train: Loss=0.4336, Acc=85.48%\n  Val:   Loss=0.7365, Acc=69.65%, AUC=0.7788\n         Prec=0.628, Rec=0.823, F1=0.712\n  ✓ Best! (Acc=69.65%, F1=0.712)\n--------------------------------------------------------------------------------\n  Ep 4 [ 697/697] Loss: 0.4055 Acc: 87.54% (15.3 b/s, ETA: 0s))\nEpoch  4/80 (49.4s)\n  Train: Loss=0.4055, Acc=87.54%\n  Val:   Loss=0.5420, Acc=78.22%, AUC=0.8506\n         Prec=0.761, Rec=0.762, F1=0.762\n  ✓ Best! (Acc=78.22%, F1=0.762)\n--------------------------------------------------------------------------------\n  Ep 5 [ 697/697] Loss: 0.3795 Acc: 89.26% (15.3 b/s, ETA: 0s))\nEpoch  5/80 (49.4s)\n  Train: Loss=0.3795, Acc=89.26%\n  Val:   Loss=0.5334, Acc=80.97%, AUC=0.8868\n         Prec=0.815, Rec=0.754, F1=0.783\n  ✓ Best! (Acc=80.97%, F1=0.783)\n--------------------------------------------------------------------------------\n  Ep 6 [ 697/697] Loss: 0.3698 Acc: 90.25% (15.3 b/s, ETA: 0s))\nEpoch  6/80 (49.3s)\n  Train: Loss=0.3698, Acc=90.25%\n  Val:   Loss=0.4970, Acc=82.46%, AUC=0.9144\n         Prec=0.872, Rec=0.722, F1=0.790\n  ✓ Best! (Acc=82.46%, F1=0.790)\n--------------------------------------------------------------------------------\n  Ep 7 [ 697/697] Loss: 0.3600 Acc: 90.71% (15.3 b/s, ETA: 0s))\nEpoch  7/80 (49.3s)\n  Train: Loss=0.3600, Acc=90.71%\n  Val:   Loss=0.4644, Acc=84.54%, AUC=0.9194\n         Prec=0.845, Rec=0.810, F1=0.827\n  ✓ Best! (Acc=84.54%, F1=0.827)\n--------------------------------------------------------------------------------\n  Ep 8 [ 697/697] Loss: 0.3532 Acc: 91.28% (15.3 b/s, ETA: 0s))\nEpoch  8/80 (49.3s)\n  Train: Loss=0.3532, Acc=91.28%\n  Val:   Loss=0.4906, Acc=82.81%, AUC=0.9133\n         Prec=0.882, Rec=0.719, F1=0.792\n  No improvement (1/15)\n--------------------------------------------------------------------------------\n  Ep 9 [ 697/697] Loss: 0.3457 Acc: 91.89% (15.3 b/s, ETA: 0s))\nEpoch  9/80 (49.3s)\n  Train: Loss=0.3457, Acc=91.89%\n  Val:   Loss=0.6325, Acc=66.43%, AUC=0.8272\n         Prec=0.592, Rec=0.854, F1=0.699\n  No improvement (2/15)\n--------------------------------------------------------------------------------\n  Ep 10 [ 697/697] Loss: 0.3400 Acc: 92.25% (15.3 b/s, ETA: 0s))\nEpoch 10/80 (49.4s)\n  Train: Loss=0.3400, Acc=92.25%\n  Val:   Loss=0.5247, Acc=77.74%, AUC=0.8824\n         Prec=0.726, Rec=0.823, F1=0.771\n  No improvement (3/15)\n--------------------------------------------------------------------------------\n  Ep 11 [ 697/697] Loss: 0.3346 Acc: 92.50% (15.2 b/s, ETA: 0s))\nEpoch 11/80 (49.6s)\n  Train: Loss=0.3346, Acc=92.50%\n  Val:   Loss=0.5027, Acc=83.53%, AUC=0.9141\n         Prec=0.877, Rec=0.743, F1=0.805\n  No improvement (4/15)\n--------------------------------------------------------------------------------\n  Ep 12 [ 697/697] Loss: 0.3346 Acc: 92.70% (15.2 b/s, ETA: 0s))\nEpoch 12/80 (49.8s)\n  Train: Loss=0.3346, Acc=92.70%\n  Val:   Loss=0.5199, Acc=77.85%, AUC=0.8803\n         Prec=0.724, Rec=0.832, F1=0.774\n  No improvement (5/15)\n--------------------------------------------------------------------------------\n  Ep 13 [ 697/697] Loss: 0.3294 Acc: 92.88% (15.1 b/s, ETA: 0s))\nEpoch 13/80 (49.8s)\n  Train: Loss=0.3294, Acc=92.88%\n  Val:   Loss=0.5090, Acc=78.91%, AUC=0.8850\n         Prec=0.738, Rec=0.833, F1=0.783\n  No improvement (6/15)\n--------------------------------------------------------------------------------\n  Ep 14 [ 697/697] Loss: 0.3246 Acc: 93.24% (15.2 b/s, ETA: 0s))\nEpoch 14/80 (49.8s)\n  Train: Loss=0.3246, Acc=93.24%\n  Val:   Loss=0.4937, Acc=82.92%, AUC=0.9091\n         Prec=0.874, Rec=0.731, F1=0.796\n  No improvement (7/15)\n--------------------------------------------------------------------------------\n  Ep 15 [ 697/697] Loss: 0.3208 Acc: 93.49% (15.1 b/s, ETA: 0s))\nEpoch 15/80 (50.1s)\n  Train: Loss=0.3208, Acc=93.49%\n  Val:   Loss=0.5261, Acc=78.88%, AUC=0.8749\n         Prec=0.744, Rec=0.819, F1=0.780\n  No improvement (8/15)\n--------------------------------------------------------------------------------\n  Ep 16 [ 697/697] Loss: 0.3173 Acc: 93.68% (15.3 b/s, ETA: 0s))\nEpoch 16/80 (49.5s)\n  Train: Loss=0.3173, Acc=93.68%\n  Val:   Loss=0.5724, Acc=74.15%, AUC=0.8649\n         Prec=0.667, Rec=0.867, F1=0.754\n  No improvement (9/15)\n--------------------------------------------------------------------------------\n  Ep 17 [ 697/697] Loss: 0.3155 Acc: 93.85% (15.1 b/s, ETA: 0s))\nEpoch 17/80 (49.9s)\n  Train: Loss=0.3155, Acc=93.85%\n  Val:   Loss=0.5833, Acc=75.33%, AUC=0.8423\n         Prec=0.708, Rec=0.781, F1=0.743\n  No improvement (10/15)\n--------------------------------------------------------------------------------\n  Ep 18 [ 697/697] Loss: 0.3104 Acc: 94.14% (15.0 b/s, ETA: 0s))\nEpoch 18/80 (50.3s)\n  Train: Loss=0.3104, Acc=94.14%\n  Val:   Loss=0.5270, Acc=79.90%, AUC=0.8754\n         Prec=0.809, Rec=0.732, F1=0.769\n  No improvement (11/15)\n--------------------------------------------------------------------------------\n  Ep 19 [ 697/697] Loss: 0.3074 Acc: 94.38% (15.0 b/s, ETA: 0s))\nEpoch 19/80 (50.3s)\n  Train: Loss=0.3074, Acc=94.38%\n  Val:   Loss=0.5397, Acc=78.64%, AUC=0.8739\n         Prec=0.781, Rec=0.740, F1=0.760\n  No improvement (12/15)\n--------------------------------------------------------------------------------\n  Ep 20 [ 697/697] Loss: 0.3064 Acc: 94.28% (15.0 b/s, ETA: 0s))\nEpoch 20/80 (50.3s)\n  Train: Loss=0.3064, Acc=94.28%\n  Val:   Loss=0.5231, Acc=79.24%, AUC=0.8792\n         Prec=0.785, Rec=0.751, F1=0.768\n  No improvement (13/15)\n--------------------------------------------------------------------------------\n  Ep 21 [ 697/697] Loss: 0.3037 Acc: 94.71% (15.2 b/s, ETA: 0s))\nEpoch 21/80 (49.6s)\n  Train: Loss=0.3037, Acc=94.71%\n  Val:   Loss=0.5695, Acc=76.90%, AUC=0.8424\n         Prec=0.735, Rec=0.772, F1=0.753\n  No improvement (14/15)\n--------------------------------------------------------------------------------\n  Ep 22 [ 697/697] Loss: 0.3003 Acc: 94.93% (15.0 b/s, ETA: 0s))\nEpoch 22/80 (50.3s)\n  Train: Loss=0.3003, Acc=94.93%\n  Val:   Loss=0.5509, Acc=77.13%, AUC=0.8605\n         Prec=0.717, Rec=0.825, F1=0.767\n  No improvement (15/15)\n--------------------------------------------------------------------------------\n\nEarly stop at epoch 22\n\n================================================================================\nBEST - Accuracy: 84.54%, F1: 0.827\n================================================================================\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nProduction-grade memory-efficient model for 90%+ apnea detection accuracy.\nOptimized for Tesla P100 16GB GPU with comprehensive validation and error handling.\n\nFeatures:\n- Record-level cross-validation to prevent data leakage\n- Comprehensive input validation and error handling\n- Enhanced data augmentation\n- Test set evaluation\n- Detailed logging and diagnostics\n- Configurable sampling rate and parameters\n\"\"\"\n\nimport argparse\nimport logging\nimport os\nimport sys\nimport time\nimport traceback\nfrom pathlib import Path\nfrom collections import Counter\nfrom typing import List, Tuple, Dict, Optional, Any\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import wfdb\n    WFDB_AVAILABLE = True\nexcept ImportError:\n    WFDB_AVAILABLE = False\n    wfdb = None\n\nfrom sklearn.metrics import (\n    roc_auc_score, precision_score, recall_score, \n    f1_score, confusion_matrix, classification_report\n)\n\n# ----------------------------- Configuration ---------------------------------\n\nclass Config:\n    \"\"\"Centralized configuration with validation.\"\"\"\n    \n    def __init__(self, **kwargs):\n        # Data parameters\n        self.sampling_rate = kwargs.get('sampling_rate', 100)  # Hz\n        self.segment_duration = kwargs.get('segment_duration', 60)  # seconds\n        self.segment_length = self.sampling_rate * self.segment_duration\n        self.stride_ratio = kwargs.get('stride_ratio', 0.5)  # 50% overlap\n        self.stride = int(self.segment_length * self.stride_ratio)\n        \n        # Model parameters\n        self.d_model = kwargs.get('d_model', 128)\n        self.n_blocks = kwargs.get('n_blocks', 8)\n        self.dropout = kwargs.get('dropout', 0.2)\n        \n        # Training parameters\n        self.batch_size = kwargs.get('batch_size', 48)\n        self.epochs = kwargs.get('epochs', 80)\n        self.lr = kwargs.get('lr', 3e-4)\n        self.weight_decay = kwargs.get('weight_decay', 1e-4)\n        self.patience = kwargs.get('patience', 15)\n        \n        # Splits (train/val/test)\n        self.train_split = kwargs.get('train_split', 0.7)\n        self.val_split = kwargs.get('val_split', 0.15)\n        self.test_split = kwargs.get('test_split', 0.15)\n        \n        # Paths\n        self.data_dir = kwargs.get('data_dir')\n        self.cache_dir = kwargs.get('cache_dir')\n        self.output_dir = kwargs.get('output_dir', '.')\n        \n        # Other\n        self.seed = kwargs.get('seed', 42)\n        self.num_workers = kwargs.get('num_workers', 4)\n        \n        self.validate()\n    \n    def validate(self):\n        \"\"\"Validate configuration parameters.\"\"\"\n        assert self.sampling_rate > 0, \"Sampling rate must be positive\"\n        assert self.segment_duration > 0, \"Segment duration must be positive\"\n        assert 0 < self.stride_ratio <= 1, \"Stride ratio must be in (0, 1]\"\n        assert self.d_model > 0 and self.d_model % 2 == 0, \"d_model must be positive and even\"\n        assert self.n_blocks > 0, \"n_blocks must be positive\"\n        assert 0 <= self.dropout < 1, \"Dropout must be in [0, 1)\"\n        assert self.batch_size > 0, \"Batch size must be positive\"\n        assert self.epochs > 0, \"Epochs must be positive\"\n        assert self.lr > 0, \"Learning rate must be positive\"\n        assert self.patience > 0, \"Patience must be positive\"\n        \n        # Split validation\n        split_sum = self.train_split + self.val_split + self.test_split\n        assert abs(split_sum - 1.0) < 1e-6, f\"Splits must sum to 1.0, got {split_sum}\"\n        \n        # Path validation\n        if self.data_dir:\n            data_path = Path(self.data_dir)\n            if not data_path.exists():\n                raise FileNotFoundError(f\"Data directory not found: {data_path}\")\n\n# ----------------------------- Logging Setup ---------------------------------\n\ndef setup_logging(output_dir: str, verbose: bool = True) -> logging.Logger:\n    \"\"\"Setup comprehensive logging.\"\"\"\n    log_dir = Path(output_dir)\n    log_dir.mkdir(parents=True, exist_ok=True)\n    \n    log_file = log_dir / f'training_{time.strftime(\"%Y%m%d_%H%M%S\")}.log'\n    \n    # Create logger\n    logger = logging.getLogger('ApneaDetection')\n    logger.setLevel(logging.DEBUG if verbose else logging.INFO)\n    \n    # File handler (detailed)\n    fh = logging.FileHandler(log_file)\n    fh.setLevel(logging.DEBUG)\n    fh.setFormatter(logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    ))\n    \n    # Console handler (concise)\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.INFO)\n    ch.setFormatter(logging.Formatter('%(message)s'))\n    \n    logger.addHandler(fh)\n    logger.addHandler(ch)\n    \n    return logger\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed: int = 42):\n    \"\"\"Set random seeds for reproducibility.\"\"\"\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\ndef validate_signal_shape(signal: np.ndarray, expected_length: int, record_name: str):\n    \"\"\"Validate signal dimensions and length.\"\"\"\n    if signal.ndim != 1:\n        raise ValueError(f\"Record {record_name}: Expected 1D signal, got shape {signal.shape}\")\n    \n    if len(signal) < expected_length:\n        raise ValueError(\n            f\"Record {record_name}: Signal too short ({len(signal)} < {expected_length})\"\n        )\n\n# ----------------------------- Enhanced Data Augmentation ---------------------------------\n\nclass SignalAugmenter:\n    \"\"\"Comprehensive signal augmentation for time-series ECG data.\"\"\"\n    \n    def __init__(self, sampling_rate: int = 100):\n        self.sampling_rate = sampling_rate\n    \n    def apply(self, signal: np.ndarray, augment_prob: float = 0.5) -> np.ndarray:\n        \"\"\"Apply random augmentations.\"\"\"\n        if np.random.random() > augment_prob:\n            return signal\n        \n        signal = signal.copy()\n        \n        # Gaussian noise (40% chance)\n        if np.random.random() < 0.4:\n            noise_level = np.random.uniform(0.02, 0.05)\n            signal += np.random.normal(0, noise_level, signal.shape).astype(np.float32)\n        \n        # Amplitude scaling (30% chance)\n        if np.random.random() < 0.3:\n            scale = np.random.uniform(0.9, 1.1)\n            signal *= scale\n        \n        # Time warping (20% chance)\n        if np.random.random() < 0.2:\n            signal = self._time_warp(signal)\n        \n        # Baseline wander (15% chance)\n        if np.random.random() < 0.15:\n            signal = self._add_baseline_wander(signal)\n        \n        # Random sign flip (10% chance) - physiologically valid\n        if np.random.random() < 0.1:\n            signal *= -1\n        \n        return signal\n    \n    def _time_warp(self, signal: np.ndarray, sigma: float = 0.2) -> np.ndarray:\n        \"\"\"Apply smooth time warping.\"\"\"\n        length = len(signal)\n        # Create smooth warping curve\n        warp = np.cumsum(np.random.normal(1.0, sigma, length))\n        warp = warp / warp[-1] * (length - 1)  # Normalize to signal length\n        warp = np.clip(warp, 0, length - 1)\n        \n        # Interpolate\n        indices = np.arange(length)\n        warped = np.interp(indices, warp, signal)\n        return warped.astype(np.float32)\n    \n    def _add_baseline_wander(self, signal: np.ndarray) -> np.ndarray:\n        \"\"\"Add low-frequency baseline wander.\"\"\"\n        length = len(signal)\n        # Create low-frequency sine wave\n        freq = np.random.uniform(0.1, 0.3)  # Hz\n        phase = np.random.uniform(0, 2 * np.pi)\n        amplitude = np.random.uniform(0.05, 0.15)\n        \n        t = np.arange(length) / self.sampling_rate\n        baseline = amplitude * np.sin(2 * np.pi * freq * t + phase)\n        \n        return signal + baseline.astype(np.float32)\n\n# ----------------------------- Efficient Model ---------------------------\n\nclass EfficientResBlock(nn.Module):\n    \"\"\"Efficient residual block with depthwise separable convolutions.\"\"\"\n    \n    def __init__(self, channels: int, kernel_size: int = 7, dropout: float = 0.1):\n        super().__init__()\n        if channels <= 0:\n            raise ValueError(f\"channels must be positive, got {channels}\")\n        if kernel_size < 1 or kernel_size % 2 == 0:\n            raise ValueError(f\"kernel_size must be positive odd number, got {kernel_size}\")\n        \n        self.depthwise = nn.Conv1d(\n            channels, channels, kernel_size, \n            padding=kernel_size//2, groups=channels\n        )\n        self.pointwise = nn.Conv1d(channels, channels, 1)\n        self.norm = nn.BatchNorm1d(channels)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        residual = x\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        x = self.norm(x)\n        x = self.dropout(x)\n        return F.gelu(residual + x)\n\n\nclass EfficientApneaNet(nn.Module):\n    \"\"\"Production-grade memory-efficient architecture for sleep apnea detection.\"\"\"\n    \n    def __init__(self, d_model: int = 128, n_blocks: int = 8, \n                 dropout: float = 0.2, input_length: int = 6000):\n        super().__init__()\n        \n        # Validate inputs\n        if d_model <= 0 or d_model % 2 != 0:\n            raise ValueError(f\"d_model must be positive even integer, got {d_model}\")\n        if n_blocks <= 0:\n            raise ValueError(f\"n_blocks must be positive, got {n_blocks}\")\n        if not 0 <= dropout < 1:\n            raise ValueError(f\"dropout must be in [0, 1), got {dropout}\")\n        \n        self.d_model = d_model\n        self.n_blocks = n_blocks\n        self.input_length = input_length\n        \n        # Input stem with multi-scale feature extraction\n        self.stem = nn.Sequential(\n            nn.Conv1d(1, d_model//2, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(d_model//2),\n            nn.GELU(),\n            nn.Conv1d(d_model//2, d_model, kernel_size=5, padding=2, stride=2),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n        )\n        \n        # Efficient residual blocks with varying receptive fields\n        self.blocks = nn.ModuleList([\n            EfficientResBlock(d_model, kernel_size=7 if i % 2 == 0 else 11, dropout=dropout)\n            for i in range(n_blocks)\n        ])\n        \n        # Lightweight channel attention (squeeze-and-excitation)\n        self.channel_attn = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Conv1d(d_model, d_model//4, 1),\n            nn.GELU(),\n            nn.Conv1d(d_model//4, d_model, 1),\n            nn.Sigmoid()\n        )\n        \n        # Temporal attention (memory efficient)\n        self.temp_attn = nn.MultiheadAttention(\n            d_model, num_heads=4, dropout=dropout, batch_first=True\n        )\n        self.temp_norm = nn.LayerNorm(d_model)\n        \n        # Classification head with batch normalization\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 3, d_model),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model, 2)\n        )\n        \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Forward pass.\n        \n        Args:\n            x: Input tensor of shape (B, L, 1) or (B, 1, L)\n        \n        Returns:\n            logits: Output logits of shape (B, 2)\n        \"\"\"\n        # Validate input\n        if x.ndim != 3:\n            raise ValueError(f\"Expected 3D input (B, L, C) or (B, C, L), got shape {x.shape}\")\n        \n        # Handle both (B, L, 1) and (B, 1, L) formats\n        if x.shape[-1] == 1:\n            x = x.transpose(1, 2)  # (B, L, 1) -> (B, 1, L)\n        \n        if x.shape[1] != 1:\n            raise ValueError(f\"Expected 1 input channel, got {x.shape[1]} channels\")\n        \n        # Stem reduces sequence length by 4x\n        x = self.stem(x)  # (B, d_model, L/4)\n        \n        # Residual blocks\n        for block in self.blocks:\n            x = block(x)\n        \n        # Channel attention\n        attn_weights = self.channel_attn(x)\n        x = x * attn_weights\n        \n        # Global features via pooling\n        x_avg = F.adaptive_avg_pool1d(x, 1).squeeze(-1)  # (B, d_model)\n        x_max = F.adaptive_max_pool1d(x, 1).squeeze(-1)  # (B, d_model)\n        \n        # Temporal attention on downsampled sequence\n        x_seq = F.adaptive_avg_pool1d(x, 50).transpose(1, 2)  # (B, 50, d_model)\n        x_attn, _ = self.temp_attn(x_seq, x_seq, x_seq)\n        x_attn = self.temp_norm(x_attn + x_seq)\n        x_attn = x_attn.mean(dim=1)  # (B, d_model)\n        \n        # Combine features\n        x_combined = torch.cat([x_avg, x_max, x_attn], dim=1)\n        \n        # Classify\n        logits = self.classifier(x_combined)\n        return logits\n\n# --------------------------- Dataset with Record-Level Split ---------------------------\n\nclass ApneaDataset(Dataset):\n    \"\"\"\n    Optimized dataset with proper record-level splitting to prevent data leakage.\n    \"\"\"\n\n    def __init__(self, \n                 data_dir: str,\n                 record_names: List[str],\n                 config: Config,\n                 cache_dir: Optional[str] = None,\n                 split: str = 'train',\n                 logger: Optional[logging.Logger] = None):\n        super().__init__()\n        \n        if not WFDB_AVAILABLE:\n            raise ImportError(\"wfdb package is required. Install with: pip install wfdb\")\n        \n        self.config = config\n        self.split = split\n        self.logger = logger or logging.getLogger('ApneaDataset')\n        self.augmenter = SignalAugmenter(config.sampling_rate) if split == 'train' else None\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_{split}_{config.segment_length}_{config.stride}_v2.pt'\n\n        if cache_file.exists():\n            self.logger.info(f\"Loading cached {split} from {cache_file}\")\n            try:\n                data = torch.load(cache_file, weights_only=True)\n                self.segments = data['segments']\n                self.labels = data['labels']\n                self.record_ids = data.get('record_ids', [])\n                self.logger.info(f\"Loaded {len(self.segments)} segments from cache\")\n            except Exception as e:\n                self.logger.error(f\"Failed to load cache: {e}\")\n                raise\n        else:\n            self.segments = []\n            self.labels = []\n            self.record_ids = []\n            self.data_dir = Path(data_dir)\n            \n            if not record_names:\n                raise ValueError(\"record_names cannot be empty\")\n            \n            self.logger.info(f\"Processing {len(record_names)} records for {split}...\")\n            \n            failed_records = []\n            for i, rec in enumerate(record_names):\n                try:\n                    self.logger.info(f\"  [{i+1}/{len(record_names)}] Processing {rec}...\")\n                    self._load_record(rec)\n                except Exception as e:\n                    self.logger.error(f\"Failed to load {rec}: {e}\")\n                    self.logger.debug(traceback.format_exc())\n                    failed_records.append(rec)\n            \n            if failed_records:\n                self.logger.warning(f\"Failed to load {len(failed_records)} records: {failed_records}\")\n            \n            if len(self.segments) == 0:\n                raise RuntimeError(f\"No segments loaded for {split} split from {len(record_names)} records\")\n            \n            self.segments = torch.tensor(np.stack(self.segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            self.logger.info(f\"Saving cache to {cache_file}\")\n            try:\n                torch.save({\n                    'segments': self.segments,\n                    'labels': self.labels,\n                    'record_ids': self.record_ids\n                }, cache_file)\n            except Exception as e:\n                self.logger.warning(f\"Failed to save cache: {e}\")\n\n        # Ensure proper shape\n        if self.segments.ndim == 2:\n            self.segments = self.segments.unsqueeze(-1)\n\n        # Log class distribution\n        class_dist = Counter(self.labels.tolist())\n        self.logger.info(\n            f\"{split.capitalize()}: {len(self.segments)} segments, \"\n            f\"Class distribution: {dict(class_dist)}\"\n        )\n\n    def _load_record(self, record_name: str):\n        \"\"\"Load and process a single record with comprehensive error handling.\"\"\"\n        try:\n            # Read signal\n            record = wfdb.rdrecord(str(self.data_dir / record_name))\n            \n            if record.p_signal is None or record.p_signal.shape[0] == 0:\n                raise ValueError(f\"Empty signal in record {record_name}\")\n            \n            if record.p_signal.shape[1] < 1:\n                raise ValueError(f\"No channels in record {record_name}\")\n            \n            signal = record.p_signal[:, 0].astype(np.float32)\n            \n            # Validate signal\n            validate_signal_shape(signal, self.config.segment_length, record_name)\n            \n            # Handle NaN values\n            if np.isnan(signal).any():\n                nans = np.isnan(signal)\n                not_nans = ~nans\n                if not_nans.sum() > 0:\n                    signal[nans] = np.interp(\n                        np.flatnonzero(nans),\n                        np.flatnonzero(not_nans),\n                        signal[not_nans]\n                    )\n                else:\n                    raise ValueError(f\"Record {record_name} contains only NaN values\")\n            \n            # Read annotations\n            annotation = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            \n            # Create minute-level labels\n            n_minutes = len(signal) // self.config.segment_length\n            minute_labels = np.zeros(n_minutes, dtype=int)\n            \n            apnea_count = 0\n            for i, symbol in enumerate(annotation.symbol):\n                if symbol == 'A':\n                    apnea_count += 1\n                    sample = annotation.sample[i]\n                    minute = sample // self.config.segment_length\n                    if 0 <= minute < n_minutes:\n                        minute_labels[minute] = 1\n            \n            self.logger.debug(f\"  {record_name}: {len(signal)} samples, {apnea_count} apnea events\")\n            \n            # Extract segments\n            n_samples = len(signal)\n            segments_added = 0\n            \n            for start in range(0, n_samples - self.config.segment_length + 1, self.config.stride):\n                end = start + self.config.segment_length\n                seg = signal[start:end].astype(np.float32)\n                \n                # Normalize segment\n                seg_mean = np.mean(seg)\n                seg_std = np.std(seg)\n                \n                if np.isnan(seg_std) or seg_std < 1e-8:\n                    seg = seg - seg_mean\n                else:\n                    seg = (seg - seg_mean) / (seg_std + 1e-8)\n                \n                # Clip outliers\n                seg = np.clip(seg, -10, 10)\n                \n                # Assign label based on minute\n                minute = start // self.config.segment_length\n                if minute < len(minute_labels):\n                    label = minute_labels[minute]\n                    self.segments.append(seg)\n                    self.labels.append(int(label))\n                    self.record_ids.append(record_name)\n                    segments_added += 1\n            \n            self.logger.debug(f\"  {record_name}: Added {segments_added} segments\")\n                    \n        except FileNotFoundError as e:\n            raise FileNotFoundError(f\"Record files not found for {record_name}: {e}\")\n        except Exception as e:\n            raise RuntimeError(f\"Error processing record {record_name}: {e}\")\n    \n    def __len__(self) -> int:\n        return self.segments.shape[0]\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        seg = self.segments[idx]\n        label = self.labels[idx]\n        \n        # Apply augmentation for training\n        if self.augmenter is not None:\n            seg = seg.numpy() if torch.is_tensor(seg) else seg\n            seg = self.augmenter.apply(seg, augment_prob=0.5)\n            seg = torch.from_numpy(seg)\n        \n        # Ensure shape is (L, 1)\n        if seg.ndim == 1:\n            seg = seg.unsqueeze(-1)\n        elif seg.ndim == 3:\n            seg = seg.squeeze(0)\n        \n        return seg, label\n\n# -------------------------- Training Utilities ------------------------\n\ndef compute_class_weights(labels_tensor: torch.Tensor, logger: logging.Logger) -> torch.Tensor:\n    \"\"\"Compute balanced class weights.\"\"\"\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    \n    if num_classes != 2:\n        logger.warning(f\"Expected 2 classes, found {num_classes}\")\n    \n    weights = []\n    for i in range(num_classes):\n        if counts[i] == 0:\n            logger.warning(f\"Class {i} has 0 samples!\")\n            weights.append(1.0)\n        else:\n            weights.append(total / (num_classes * counts[i]))\n    \n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model: nn.Module, \n                dataloader: DataLoader,\n                criterion: nn.Module,\n                optimizer: torch.optim.Optimizer,\n                scheduler: torch.optim.lr_scheduler._LRScheduler,\n                device: torch.device,\n                epoch: int,\n                logger: logging.Logger,\n                scaler: Optional[torch.amp.GradScaler] = None) -> Tuple[float, float]:\n    \"\"\"Train for one epoch with comprehensive logging.\"\"\"\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    skipped_batches = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 15)\n    start_time = time.time()\n\n    for batch_idx, (data, target) in enumerate(dataloader, 1):\n        try:\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n\n            optimizer.zero_grad(set_to_none=True)\n\n            with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n                output = model(data)\n                loss = criterion(output, target)\n            \n            # Check for NaN\n            if torch.isnan(loss) or torch.isinf(loss):\n                logger.warning(f\"Invalid loss at batch {batch_idx}, skipping\")\n                skipped_batches += 1\n                continue\n\n            if scaler is not None:\n                scaler.scale(loss).backward()\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n            \n            scheduler.step()\n\n            total_loss += loss.item()\n            pred = output.argmax(dim=1)\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n            \n            if batch_idx % print_freq == 0 or batch_idx == num_batches:\n                curr_acc = 100.0 * correct / total if total > 0 else 0.0\n                curr_loss = total_loss / (batch_idx - skipped_batches) if batch_idx > skipped_batches else 0.0\n                speed = batch_idx / (time.time() - start_time)\n                eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n                current_lr = optimizer.param_groups[0]['lr']\n                \n                logger.info(\n                    f\"  Ep {epoch} [{batch_idx:4d}/{num_batches}] \"\n                    f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                    f\"LR: {current_lr:.2e} ({speed:.1f} b/s, ETA: {eta:.0f}s)\"\n                )\n        \n        except Exception as e:\n            logger.error(f\"Error in batch {batch_idx}: {e}\")\n            logger.debug(traceback.format_exc())\n            skipped_batches += 1\n            continue\n\n    if skipped_batches > 0:\n        logger.warning(f\"Skipped {skipped_batches} batches due to errors\")\n\n    avg_loss = total_loss / (num_batches - skipped_batches) if num_batches > skipped_batches else float('inf')\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    return avg_loss, accuracy\n\ndef validate(model: nn.Module,\n             dataloader: DataLoader,\n             criterion: nn.Module,\n             device: torch.device,\n             logger: logging.Logger) -> Tuple[float, float, np.ndarray, np.ndarray, np.ndarray, float, float, float]:\n    \"\"\"Validate model with comprehensive metrics.\"\"\"\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for data, target in dataloader:\n            try:\n                data = data.to(device, non_blocking=True)\n                target = target.to(device, non_blocking=True)\n                output = model(data)\n                loss = criterion(output, target)\n\n                if not (torch.isnan(loss) or torch.isinf(loss)):\n                    total_loss += loss.item()\n\n                probs = F.softmax(output, dim=1)[:, 1]\n                pred = output.argmax(dim=1)\n\n                correct += pred.eq(target).sum().item()\n                total += target.size(0)\n\n                all_preds.extend(pred.cpu().tolist())\n                all_targets.extend(target.cpu().tolist())\n                all_probs.extend(probs.cpu().tolist())\n            \n            except Exception as e:\n                logger.error(f\"Error in validation batch: {e}\")\n                continue\n\n    avg_loss = total_loss / len(dataloader) if len(dataloader) > 0 else float('inf')\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    # Compute metrics with error handling\n    try:\n        precision = precision_score(all_targets, all_preds, zero_division=0)\n        recall = recall_score(all_targets, all_preds, zero_division=0)\n        f1 = f1_score(all_targets, all_preds, zero_division=0)\n    except Exception as e:\n        logger.error(f\"Error computing metrics: {e}\")\n        precision = recall = f1 = 0.0\n    \n    return (avg_loss, accuracy, np.array(all_preds), np.array(all_targets),\n            np.array(all_probs), precision, recall, f1)\n\ndef evaluate_test_set(model: nn.Module,\n                     dataloader: DataLoader,\n                     device: torch.device,\n                     logger: logging.Logger,\n                     output_dir: str):\n    \"\"\"Comprehensive evaluation on test set.\"\"\"\n    logger.info(\"\\n\" + \"=\"*80)\n    logger.info(\"FINAL TEST SET EVALUATION\")\n    logger.info(\"=\"*80)\n    \n    model.eval()\n    all_preds = []\n    all_targets = []\n    all_probs = []\n    \n    with torch.no_grad():\n        for data, target in dataloader:\n            try:\n                data = data.to(device, non_blocking=True)\n                target = target.to(device, non_blocking=True)\n                output = model(data)\n                \n                probs = F.softmax(output, dim=1)[:, 1]\n                pred = output.argmax(dim=1)\n                \n                all_preds.extend(pred.cpu().tolist())\n                all_targets.extend(target.cpu().tolist())\n                all_probs.extend(probs.cpu().tolist())\n            except Exception as e:\n                logger.error(f\"Error in test batch: {e}\")\n                continue\n    \n    # Convert to numpy\n    all_preds = np.array(all_preds)\n    all_targets = np.array(all_targets)\n    all_probs = np.array(all_probs)\n    \n    # Compute comprehensive metrics\n    accuracy = 100.0 * np.sum(all_preds == all_targets) / len(all_targets)\n    precision = precision_score(all_targets, all_preds, zero_division=0)\n    recall = recall_score(all_targets, all_preds, zero_division=0)\n    f1 = f1_score(all_targets, all_preds, zero_division=0)\n    \n    try:\n        auc = roc_auc_score(all_targets, all_probs)\n    except Exception as e:\n        logger.warning(f\"Could not compute AUC: {e}\")\n        auc = 0.0\n    \n    # Confusion matrix\n    cm = confusion_matrix(all_targets, all_preds)\n    \n    # Log results\n    logger.info(f\"\\nTest Set Performance:\")\n    logger.info(f\"  Accuracy:  {accuracy:.2f}%\")\n    logger.info(f\"  Precision: {precision:.4f}\")\n    logger.info(f\"  Recall:    {recall:.4f}\")\n    logger.info(f\"  F1 Score:  {f1:.4f}\")\n    logger.info(f\"  AUC:       {auc:.4f}\")\n    logger.info(f\"\\nConfusion Matrix:\")\n    logger.info(f\"  {cm}\")\n    \n    # Classification report\n    logger.info(f\"\\nDetailed Classification Report:\")\n    report = classification_report(all_targets, all_preds, \n                                   target_names=['Normal', 'Apnea'],\n                                   digits=4)\n    logger.info(f\"\\n{report}\")\n    \n    # Save results\n    results_file = Path(output_dir) / 'test_results.txt'\n    with open(results_file, 'w') as f:\n        f.write(\"=\"*80 + \"\\n\")\n        f.write(\"FINAL TEST SET EVALUATION\\n\")\n        f.write(\"=\"*80 + \"\\n\\n\")\n        f.write(f\"Accuracy:  {accuracy:.2f}%\\n\")\n        f.write(f\"Precision: {precision:.4f}\\n\")\n        f.write(f\"Recall:    {recall:.4f}\\n\")\n        f.write(f\"F1 Score:  {f1:.4f}\\n\")\n        f.write(f\"AUC:       {auc:.4f}\\n\\n\")\n        f.write(\"Confusion Matrix:\\n\")\n        f.write(f\"{cm}\\n\\n\")\n        f.write(\"Classification Report:\\n\")\n        f.write(report)\n    \n    logger.info(f\"\\nResults saved to {results_file}\")\n    \n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'auc': auc,\n        'confusion_matrix': cm\n    }\n\n# ------------------------------ Main ------------------------------------\n\ndef split_records(records: List[str], \n                 train_split: float, \n                 val_split: float,\n                 test_split: float,\n                 seed: int,\n                 logger: logging.Logger) -> Tuple[List[str], List[str], List[str]]:\n    \"\"\"\n    Split records into train/val/test ensuring no data leakage.\n    Each record appears in exactly one split.\n    \"\"\"\n    import random\n    \n    # Validate splits\n    split_sum = train_split + val_split + test_split\n    if abs(split_sum - 1.0) > 1e-6:\n        raise ValueError(f\"Splits must sum to 1.0, got {split_sum}\")\n    \n    # Shuffle records\n    records_shuffled = records.copy()\n    random.Random(seed).shuffle(records_shuffled)\n    \n    # Calculate split indices\n    n_records = len(records_shuffled)\n    train_end = int(n_records * train_split)\n    val_end = train_end + int(n_records * val_split)\n    \n    train_records = records_shuffled[:train_end]\n    val_records = records_shuffled[train_end:val_end]\n    test_records = records_shuffled[val_end:]\n    \n    logger.info(f\"\\nRecord-level split (seed={seed}):\")\n    logger.info(f\"  Train: {len(train_records)} records\")\n    logger.info(f\"  Val:   {len(val_records)} records\")\n    logger.info(f\"  Test:  {len(test_records)} records\")\n    logger.info(f\"  Total: {len(records)} records\")\n    \n    # Verify no overlap\n    train_set = set(train_records)\n    val_set = set(val_records)\n    test_set = set(test_records)\n    \n    if train_set & val_set:\n        raise RuntimeError(\"Train and validation sets overlap!\")\n    if train_set & test_set:\n        raise RuntimeError(\"Train and test sets overlap!\")\n    if val_set & test_set:\n        raise RuntimeError(\"Validation and test sets overlap!\")\n    \n    return train_records, val_records, test_records\n\ndef main(config: Config, logger: logging.Logger):\n    \"\"\"Main training pipeline with comprehensive error handling.\"\"\"\n    \n    set_seed(config.seed)\n    \n    # Validate data directory\n    DATA_DIR = Path(config.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    # Find all valid records\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    \n    # Filter valid records (must have .apn annotation, exclude error records)\n    valid_records = []\n    for rec in all_records:\n        if rec.endswith('er'):\n            logger.debug(f\"Skipping error record: {rec}\")\n            continue\n        \n        apn_file = DATA_DIR / (rec + '.apn')\n        if not apn_file.exists():\n            logger.debug(f\"Skipping {rec}: no .apn annotation\")\n            continue\n        \n        valid_records.append(rec)\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(\"No valid records found in data directory\")\n\n    logger.info(f\"\\nFound {len(all_records)} total records\")\n    logger.info(f\"Valid records with annotations: {len(valid_records)}\")\n\n    # Record-level split to prevent data leakage\n    train_records, val_records, test_records = split_records(\n        valid_records,\n        config.train_split,\n        config.val_split,\n        config.test_split,\n        config.seed,\n        logger\n    )\n    \n    if len(test_records) == 0:\n        logger.warning(\"No test records! Consider adjusting split ratios.\")\n\n    # Create datasets\n    logger.info(\"\\nCreating datasets...\")\n    try:\n        train_dataset = ApneaDataset(\n            str(DATA_DIR), train_records, config,\n            config.cache_dir, 'train', logger\n        )\n        val_dataset = ApneaDataset(\n            str(DATA_DIR), val_records, config,\n            config.cache_dir, 'val', logger\n        )\n        \n        if test_records:\n            test_dataset = ApneaDataset(\n                str(DATA_DIR), test_records, config,\n                config.cache_dir, 'test', logger\n            )\n        else:\n            test_dataset = None\n    except Exception as e:\n        logger.error(f\"Failed to create datasets: {e}\")\n        logger.debug(traceback.format_exc())\n        raise\n\n    # Create data loaders\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=config.batch_size,\n        shuffle=True,\n        num_workers=config.num_workers,\n        pin_memory=True,\n        persistent_workers=True if config.num_workers > 0 else False\n    )\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config.batch_size,\n        shuffle=False,\n        num_workers=config.num_workers,\n        pin_memory=True,\n        persistent_workers=True if config.num_workers > 0 else False\n    )\n    \n    if test_dataset:\n        test_loader = DataLoader(\n            test_dataset,\n            batch_size=config.batch_size,\n            shuffle=False,\n            num_workers=config.num_workers,\n            pin_memory=True\n        )\n\n    # Setup device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    logger.info(f\"\\nDevice: {device}\")\n    if device.type == 'cuda':\n        logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n        torch.cuda.empty_cache()\n\n    # Create model\n    try:\n        model = EfficientApneaNet(\n            d_model=config.d_model,\n            n_blocks=config.n_blocks,\n            dropout=config.dropout,\n            input_length=config.segment_length\n        ).to(device)\n        \n        total_params = sum(p.numel() for p in model.parameters())\n        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n        logger.info(f\"\\nModel: EfficientApneaNet\")\n        logger.info(f\"  Total parameters:     {total_params:,}\")\n        logger.info(f\"  Trainable parameters: {trainable_params:,}\")\n        logger.info(f\"  Model size: ~{total_params * 4 / 1e6:.2f} MB (fp32)\")\n    except Exception as e:\n        logger.error(f\"Failed to create model: {e}\")\n        logger.debug(traceback.format_exc())\n        raise\n\n    # Setup training\n    class_weights = compute_class_weights(train_dataset.labels, logger)\n    class_weights = class_weights.to(device)\n    logger.info(f\"\\nClass weights: {class_weights.tolist()}\")\n    \n    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=config.lr,\n        weight_decay=config.weight_decay,\n        betas=(0.9, 0.999)\n    )\n    \n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=config.lr,\n        epochs=config.epochs,\n        steps_per_epoch=len(train_loader),\n        pct_start=0.1,\n        anneal_strategy='cos'\n    )\n\n    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n\n    # Training loop\n    best_val_acc = 0.0\n    best_val_f1 = 0.0\n    no_improve = 0\n    best_model_path = Path(config.output_dir) / 'best_model.pth'\n\n    logger.info(\"\\n\" + \"=\"*80)\n    logger.info(\"STARTING TRAINING\")\n    logger.info(\"=\"*80)\n    \n    training_history = {\n        'train_loss': [], 'train_acc': [],\n        'val_loss': [], 'val_acc': [],\n        'val_precision': [], 'val_recall': [], 'val_f1': [], 'val_auc': []\n    }\n    \n    try:\n        for epoch in range(1, config.epochs + 1):\n            epoch_start = time.time()\n            \n            # Train\n            train_loss, train_acc = train_epoch(\n                model, train_loader, criterion, optimizer,\n                scheduler, device, epoch, logger, scaler\n            )\n            \n            # Validate\n            val_loss, val_acc, _, val_targets, val_probs, precision, recall, f1 = validate(\n                model, val_loader, criterion, device, logger\n            )\n\n            # Compute AUC\n            try:\n                auc = roc_auc_score(val_targets, val_probs)\n            except Exception as e:\n                logger.warning(f\"Could not compute AUC: {e}\")\n                auc = 0.0\n\n            epoch_time = time.time() - epoch_start\n            \n            # Log epoch summary\n            logger.info(f\"\\nEpoch {epoch:2d}/{config.epochs} completed in {epoch_time:.1f}s\")\n            logger.info(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n            logger.info(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={auc:.4f}\")\n            logger.info(f\"         Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}\")\n\n            # Store history\n            training_history['train_loss'].append(train_loss)\n            training_history['train_acc'].append(train_acc)\n            training_history['val_loss'].append(val_loss)\n            training_history['val_acc'].append(val_acc)\n            training_history['val_precision'].append(precision)\n            training_history['val_recall'].append(recall)\n            training_history['val_f1'].append(f1)\n            training_history['val_auc'].append(auc)\n\n            # Save best model\n            is_best = (val_acc > best_val_acc) or (val_acc >= best_val_acc and f1 > best_val_f1)\n            \n            if is_best:\n                best_val_acc = val_acc\n                best_val_f1 = f1\n                no_improve = 0\n                \n                try:\n                    torch.save({\n                        'epoch': epoch,\n                        'model_state_dict': model.state_dict(),\n                        'optimizer_state_dict': optimizer.state_dict(),\n                        'scheduler_state_dict': scheduler.state_dict(),\n                        'val_acc': val_acc,\n                        'val_auc': auc,\n                        'val_f1': f1,\n                        'config': config.__dict__,\n                        'training_history': training_history\n                    }, best_model_path)\n                    logger.info(f\"  ✓ Best model saved! (Acc={val_acc:.2f}%, F1={f1:.4f})\")\n                except Exception as e:\n                    logger.error(f\"Failed to save model: {e}\")\n            else:\n                no_improve += 1\n                logger.info(f\"  No improvement ({no_improve}/{config.patience})\")\n\n            logger.info(\"-\"*80)\n\n            # Early stopping\n            if no_improve >= config.patience:\n                logger.info(f\"\\nEarly stopping triggered at epoch {epoch}\")\n                break\n\n    except KeyboardInterrupt:\n        logger.info(\"\\n\\nTraining interrupted by user\")\n    except Exception as e:\n        logger.error(f\"\\n\\nTraining failed with error: {e}\")\n        logger.debug(traceback.format_exc())\n        raise\n\n    # Training summary\n    logger.info(f\"\\n{'='*80}\")\n    logger.info(\"TRAINING COMPLETED\")\n    logger.info(f\"{'='*80}\")\n    logger.info(f\"Best Validation - Accuracy: {best_val_acc:.2f}%, F1: {best_val_f1:.4f}\")\n    logger.info(f\"Model saved to: {best_model_path}\")\n\n    # Test set evaluation\n    if test_dataset and best_model_path.exists():\n        logger.info(\"\\nLoading best model for test set evaluation...\")\n        try:\n            checkpoint = torch.load(best_model_path, weights_only=False)\n            model.load_state_dict(checkpoint['model_state_dict'])\n            \n            test_results = evaluate_test_set(\n                model, test_loader, device, logger, config.output_dir\n            )\n            \n            logger.info(f\"\\n{'='*80}\")\n            logger.info(\"FINAL TEST RESULTS\")\n            logger.info(f\"{'='*80}\")\n            logger.info(f\"  Accuracy:  {test_results['accuracy']:.2f}%\")\n            logger.info(f\"  Precision: {test_results['precision']:.4f}\")\n            logger.info(f\"  Recall:    {test_results['recall']:.4f}\")\n            logger.info(f\"  F1 Score:  {test_results['f1']:.4f}\")\n            logger.info(f\"  AUC:       {test_results['auc']:.4f}\")\n            logger.info(f\"{'='*80}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to evaluate test set: {e}\")\n            logger.debug(traceback.format_exc())\n    \n    elif not test_dataset:\n        logger.info(\"\\nNo test set available for final evaluation\")\n\n    logger.info(\"\\nTraining pipeline completed successfully!\")\n\nif __name__ == '__main__':\n    # Auto-detect environment\n    kaggle_data = '/kaggle/input/vincent2/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    \n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_output_dir = '/kaggle/working'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_output_dir = '/content'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_output_dir = '.'\n    \n    # Argument parser\n    parser = argparse.ArgumentParser(\n        description='Production-grade sleep apnea detection from ECG signals',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    \n    # Data arguments\n    parser.add_argument('--data-dir', type=str, default=default_data_dir,\n                       help='Path to apnea-ecg database')\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir,\n                       help='Directory for caching processed data')\n    parser.add_argument('--output-dir', type=str, default=default_output_dir,\n                       help='Directory for outputs (models, logs)')\n    \n    # Signal processing\n    parser.add_argument('--sampling-rate', type=int, default=100,\n                       help='ECG sampling rate in Hz')\n    parser.add_argument('--segment-duration', type=int, default=60,\n                       help='Segment duration in seconds')\n    parser.add_argument('--stride-ratio', type=float, default=0.5,\n                       help='Stride ratio for overlapping segments')\n    \n    # Model architecture\n    parser.add_argument('--d-model', type=int, default=128,\n                       help='Model dimension')\n    parser.add_argument('--n-blocks', type=int, default=8,\n                       help='Number of residual blocks')\n    parser.add_argument('--dropout', type=float, default=0.2,\n                       help='Dropout rate')\n    \n    # Training\n    parser.add_argument('--batch-size', type=int, default=48,\n                       help='Batch size')\n    parser.add_argument('--epochs', type=int, default=80,\n                       help='Number of epochs')\n    parser.add_argument('--lr', type=float, default=3e-4,\n                       help='Learning rate')\n    parser.add_argument('--weight-decay', type=float, default=1e-4,\n                       help='Weight decay')\n    parser.add_argument('--patience', type=int, default=15,\n                       help='Early stopping patience')\n    \n    # Data splits\n    parser.add_argument('--train-split', type=float, default=0.7,\n                       help='Training set ratio')\n    parser.add_argument('--val-split', type=float, default=0.15,\n                       help='Validation set ratio')\n    parser.add_argument('--test-split', type=float, default=0.15,\n                       help='Test set ratio')\n    \n    # Other\n    parser.add_argument('--seed', type=int, default=42,\n                       help='Random seed')\n    parser.add_argument('--num-workers', type=int, default=4,\n                       help='Number of dataloader workers')\n    parser.add_argument('--verbose', action='store_true',\n                       help='Enable verbose logging')\n\n    args, _ = parser.parse_known_args()\n    \n    # Validate data directory\n    if args.data_dir is None:\n        print(\"ERROR: Dataset not found. Please specify --data-dir\")\n        print(\"\\nLooking for apnea-ecg-database in:\")\n        print(f\"  - {kaggle_data}\")\n        print(f\"  - {colab_data}\")\n        sys.exit(1)\n    \n    # Create output directory\n    output_dir = Path(args.output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Setup logging\n    logger = setup_logging(str(output_dir), args.verbose)\n    \n    # Create config\n    try:\n        config = Config(**vars(args))\n    except Exception as e:\n        logger.error(f\"Invalid configuration: {e}\")\n        sys.exit(1)\n    \n    # Log configuration\n    logger.info(\"=\"*80)\n    logger.info(\"SLEEP APNEA DETECTION - PRODUCTION GRADE MODEL\")\n    logger.info(\"=\"*80)\n    logger.info(f\"\\nConfiguration:\")\n    logger.info(f\"  Data directory:    {config.data_dir}\")\n    logger.info(f\"  Cache directory:   {config.cache_dir}\")\n    logger.info(f\"  Output directory:  {config.output_dir}\")\n    logger.info(f\"\\nSignal Processing:\")\n    logger.info(f\"  Sampling rate:     {config.sampling_rate} Hz\")\n    logger.info(f\"  Segment duration:  {config.segment_duration}s ({config.segment_length} samples)\")\n    logger.info(f\"  Stride ratio:      {config.stride_ratio} ({config.stride} samples)\")\n    logger.info(f\"\\nModel Architecture:\")\n    logger.info(f\"  d_model:           {config.d_model}\")\n    logger.info(f\"  n_blocks:          {config.n_blocks}\")\n    logger.info(f\"  dropout:           {config.dropout}\")\n    logger.info(f\"\\nTraining:\")\n    logger.info(f\"  Batch size:        {config.batch_size}\")\n    logger.info(f\"  Epochs:            {config.epochs}\")\n    logger.info(f\"  Learning rate:     {config.lr}\")\n    logger.info(f\"  Weight decay:      {config.weight_decay}\")\n    logger.info(f\"  Patience:          {config.patience}\")\n    logger.info(f\"\\nData Splits:\")\n    logger.info(f\"  Train:             {config.train_split:.1%}\")\n    logger.info(f\"  Validation:        {config.val_split:.1%}\")\n    logger.info(f\"  Test:              {config.test_split:.1%}\")\n    logger.info(f\"\\nOther:\")\n    logger.info(f\"  Random seed:       {config.seed}\")\n    logger.info(f\"  Num workers:       {config.num_workers}\")\n    logger.info(\"=\"*80 + \"\\n\")\n    \n    # Run training\n    try:\n        main(config, logger)\n    except Exception as e:\n        logger.error(f\"\\nFATAL ERROR: {e}\")\n        logger.debug(traceback.format_exc())\n        sys.exit(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:22:30.934993Z","iopub.execute_input":"2025-11-20T15:22:30.935771Z","iopub.status.idle":"2025-11-20T15:22:39.206218Z","shell.execute_reply.started":"2025-11-20T15:22:30.935739Z","shell.execute_reply":"2025-11-20T15:22:39.203017Z"}},"outputs":[{"name":"stderr","text":"================================================================================\nSLEEP APNEA DETECTION - PRODUCTION GRADE MODEL\n================================================================================\n\nConfiguration:\n  Data directory:    /kaggle/input/vincent2/apnea-ecg-database-1.0.0\n  Cache directory:   /kaggle/working\n  Output directory:  /kaggle/working\n\nSignal Processing:\n  Sampling rate:     100 Hz\n  Segment duration:  60s (6000 samples)\n  Stride ratio:      0.5 (3000 samples)\n\nModel Architecture:\n  d_model:           128\n  n_blocks:          8\n  dropout:           0.2\n\nTraining:\n  Batch size:        48\n  Epochs:            80\n  Learning rate:     0.0003\n  Weight decay:      0.0001\n  Patience:          15\n\nData Splits:\n  Train:             70.0%\n  Validation:        15.0%\n  Test:              15.0%\n\nOther:\n  Random seed:       42\n  Num workers:       4\n================================================================================\n\n\nFound 86 total records\nValid records with annotations: 43\n\nRecord-level split (seed=42):\n  Train: 30 records\n  Val:   6 records\n  Test:  7 records\n  Total: 43 records\n\nCreating datasets...\nProcessing 30 records for train...\n  [1/30] Processing b02...\n  [2/30] Processing a10...\n  [3/30] Processing a04...\n  [4/30] Processing a02...\n  [5/30] Processing b03...\n  [6/30] Processing a11...\n  [7/30] Processing a08...\n  [8/30] Processing a09...\n  [9/30] Processing c01r...\n  [10/30] Processing a04r...\n  [11/30] Processing a18...\n  [12/30] Processing b01...\n  [13/30] Processing a03...\n  [14/30] Processing a14...\n  [15/30] Processing c08...\n  [16/30] Processing a02r...\n  [17/30] Processing a15...\n  [18/30] Processing c01...\n  [19/30] Processing c07...\n  [20/30] Processing c02r...\n  [21/30] Processing a17...\n  [22/30] Processing c02...\n  [23/30] Processing c05...\n  [24/30] Processing a12...\n  [25/30] Processing b01r...\n  [26/30] Processing a16...\n  [27/30] Processing c03r...\n  [28/30] Processing c04...\n  [29/30] Processing c09...\n  [30/30] Processing c10...\nSaving cache to /kaggle/working/apnea_train_6000_3000_v2.pt\nTrain: 29514 segments, Class distribution: {0: 18915, 1: 10599}\nProcessing 6 records for val...\n  [1/6] Processing a19...\n  [2/6] Processing b04...\n  [3/6] Processing a07...\n  [4/6] Processing a20...\n  [5/6] Processing a03r...\n  [6/6] Processing a13...\nSaving cache to /kaggle/working/apnea_val_6000_3000_v2.pt\nVal: 5927 segments, Class distribution: {0: 3250, 1: 2677}\nProcessing 7 records for test...\n  [1/7] Processing c03...\n  [2/7] Processing b05...\n  [3/7] Processing a06...\n  [4/7] Processing a01r...\n  [5/7] Processing a05...\n  [6/7] Processing c06...\n  [7/7] Processing a01...\nSaving cache to /kaggle/working/apnea_test_6000_3000_v2.pt\nTest: 6592 segments, Class distribution: {0: 3634, 1: 2958}\n\nDevice: cuda\nGPU: Tesla P100-PCIE-16GB\nGPU Memory: 17.06 GB\n\nModel: EfficientApneaNet\n  Total parameters:     310,818\n  Trainable parameters: 310,818\n  Model size: ~1.24 MB (fp32)\n\nClass weights: [0.7801744937896729, 1.3923012018203735]\n\n================================================================================\nSTARTING TRAINING\n================================================================================\n\n\nTraining failed with error: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 545, in __getitem__\n    seg = self.augmenter.apply(seg, augment_prob=0.5)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 187, in apply\n    signal = self._time_warp(signal)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 209, in _time_warp\n    warped = np.interp(indices, warp, signal)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py\", line 1599, in interp\n    return interp_func(x, xp, fp, left, right)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: object too deep for desired array\n\n\nFATAL ERROR: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 545, in __getitem__\n    seg = self.augmenter.apply(seg, augment_prob=0.5)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 187, in apply\n    signal = self._time_warp(signal)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 209, in _time_warp\n    warped = np.interp(indices, warp, signal)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py\", line 1599, in interp\n    return interp_func(x, xp, fp, left, right)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: object too deep for desired array\n\nERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\n","output_type":"stream"},{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_48/3253938270.py\", line 1279, in <cell line: 0>\n    main(config, logger)\n  File \"/tmp/ipykernel_48/3253938270.py\", line 1033, in main\n    train_loss, train_acc = train_epoch(\n                            ^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 597, in train_epoch\n    for batch_idx, (data, target) in enumerate(dataloader, 1):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n    data = self._next_data()\n           ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1480, in _next_data\n    return self._process_data(data)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1505, in _process_data\n    data.reraise()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_utils.py\", line 733, in reraise\n    raise exception\nValueError: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 545, in __getitem__\n    seg = self.augmenter.apply(seg, augment_prob=0.5)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 187, in apply\n    signal = self._time_warp(signal)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 209, in _time_warp\n    warped = np.interp(indices, warp, signal)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py\", line 1599, in interp\n    return interp_func(x, xp, fp, left, right)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: object too deep for desired array\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_48/3253938270.py\", line 1283, in <cell line: 0>\n    sys.exit(1)\nSystemExit: 1\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n    traceback_info = getframeinfo(tb, context)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 1671, in getframeinfo\n    lineno = frame.f_lineno\n             ^^^^^^^^^^^^^^\nAttributeError: 'tuple' object has no attribute 'f_lineno'\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/3253938270.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/3253938270.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config, logger)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             train_loss, train_acc = train_epoch(\n\u001b[0m\u001b[1;32m   1034\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/3253938270.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, scheduler, device, epoch, logger, scaler)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 545, in __getitem__\n    seg = self.augmenter.apply(seg, augment_prob=0.5)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 187, in apply\n    signal = self._time_warp(signal)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/3253938270.py\", line 209, in _time_warp\n    warped = np.interp(indices, warp, signal)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py\", line 1599, in interp\n    return interp_func(x, xp, fp, left, right)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: object too deep for desired array\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/3253938270.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mSystemExit\u001b[0m: 1","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"],"ename":"TypeError","evalue":"object of type 'NoneType' has no len()","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nEnhanced high-performance model for 90%+ apnea detection accuracy.\nImplements R-R interval extraction and advanced preprocessing from research paper.\nOptimized for Tesla P100 16GB GPU.\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy import signal as scipy_signal\nfrom scipy.interpolate import CubicSpline\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- R-Peak Detection & Preprocessing ---------------------------------\n\ndef detect_r_peaks_hamilton(ecg_signal, fs=100):\n    \"\"\"\n    Hamilton R-peak detection algorithm.\n    Based on: Hamilton, P. S. (2002). Open source ECG analysis.\n    \"\"\"\n    # Bandpass filter (5-15 Hz)\n    nyquist = fs / 2\n    low = 5 / nyquist\n    high = 15 / nyquist\n    b, a = scipy_signal.butter(2, [low, high], btype='band')\n    filtered = scipy_signal.filtfilt(b, a, ecg_signal)\n    \n    # Derivative\n    diff_signal = np.diff(filtered)\n    \n    # Squaring\n    squared = diff_signal ** 2\n    \n    # Moving window integration (150ms window)\n    window_size = int(0.15 * fs)\n    integrated = np.convolve(squared, np.ones(window_size) / window_size, mode='same')\n    \n    # Find peaks\n    threshold = 0.35 * np.max(integrated)\n    peaks = []\n    refractory = int(0.2 * fs)  # 200ms refractory period\n    \n    for i in range(1, len(integrated) - 1):\n        if integrated[i] > threshold and integrated[i] > integrated[i-1] and integrated[i] > integrated[i+1]:\n            if len(peaks) == 0 or i - peaks[-1] > refractory:\n                # Find actual R-peak in original signal around this location\n                search_start = max(0, i - int(0.05 * fs))\n                search_end = min(len(ecg_signal), i + int(0.05 * fs))\n                local_max_idx = search_start + np.argmax(np.abs(ecg_signal[search_start:search_end]))\n                peaks.append(local_max_idx)\n    \n    return np.array(peaks)\n\ndef median_filter_rr(rr_intervals, threshold=0.3):\n    \"\"\"\n    Median filter for removing physiologically uninterpretable R-R intervals.\n    Based on: Chen et al. median filtering approach.\n    \"\"\"\n    if len(rr_intervals) < 3:\n        return rr_intervals\n    \n    filtered = rr_intervals.copy()\n    median_rr = np.median(rr_intervals)\n    \n    for i in range(len(rr_intervals)):\n        if np.abs(rr_intervals[i] - median_rr) > threshold * median_rr:\n            # Replace with median of neighbors\n            if i == 0:\n                filtered[i] = rr_intervals[i+1]\n            elif i == len(rr_intervals) - 1:\n                filtered[i] = rr_intervals[i-1]\n            else:\n                filtered[i] = np.median([rr_intervals[i-1], rr_intervals[i+1]])\n    \n    return filtered\n\ndef extract_rr_features(ecg_segment, fs=100):\n    \"\"\"\n    Extract R-R intervals and R-peak amplitudes from ECG segment.\n    Apply cubic interpolation at 3 Hz as per paper.\n    \"\"\"\n    try:\n        # Detect R-peaks\n        r_peaks = detect_r_peaks_hamilton(ecg_segment, fs)\n        \n        if len(r_peaks) < 2:\n            # Return zeros if not enough peaks\n            target_length = int(60 * 3)  # 60 seconds at 3 Hz = 180 samples\n            return np.zeros(target_length), np.zeros(target_length)\n        \n        # Calculate R-R intervals (in seconds)\n        rr_intervals = np.diff(r_peaks) / fs\n        \n        # Apply median filter\n        rr_intervals = median_filter_rr(rr_intervals)\n        \n        # Extract R-peak amplitudes\n        r_amplitudes = ecg_segment[r_peaks[1:]]  # Align with RR intervals\n        \n        # Time points for interpolation\n        rr_times = r_peaks[1:] / fs  # Time of each RR interval\n        \n        # Cubic interpolation at 3 Hz\n        target_fs = 3\n        target_length = int(60 * target_fs)  # 60 seconds at 3 Hz\n        target_times = np.linspace(rr_times[0], rr_times[-1], target_length)\n        \n        # Interpolate RR intervals\n        if len(rr_times) >= 4:  # Need at least 4 points for cubic spline\n            cs_rr = CubicSpline(rr_times, rr_intervals)\n            rr_interpolated = cs_rr(target_times)\n            \n            # Interpolate R-peak amplitudes\n            cs_amp = CubicSpline(rr_times, r_amplitudes)\n            amp_interpolated = cs_amp(target_times)\n        else:\n            # Fall back to linear interpolation\n            rr_interpolated = np.interp(target_times, rr_times, rr_intervals)\n            amp_interpolated = np.interp(target_times, rr_times, r_amplitudes)\n        \n        # Normalize\n        rr_interpolated = (rr_interpolated - np.mean(rr_interpolated)) / (np.std(rr_interpolated) + 1e-8)\n        amp_interpolated = (amp_interpolated - np.mean(amp_interpolated)) / (np.std(amp_interpolated) + 1e-8)\n        \n        return rr_interpolated, amp_interpolated\n        \n    except Exception as e:\n        target_length = int(60 * 3)\n        return np.zeros(target_length), np.zeros(target_length)\n\n# ----------------------------- Enhanced Model ---------------------------\n\nclass MultiHeadSelfAttention(nn.Module):\n    \"\"\"Enhanced self-attention mechanism.\"\"\"\n    def __init__(self, d_model, num_heads=8, dropout=0.1):\n        super().__init__()\n        self.attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n        self.norm = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        # x: (B, L, d_model)\n        attn_out, _ = self.attention(x, x, x)\n        return self.norm(x + self.dropout(attn_out))\n\nclass EnhancedResBlock(nn.Module):\n    \"\"\"Enhanced residual block with depthwise separable convolutions.\"\"\"\n    def __init__(self, channels, kernel_size=7, dilation=1):\n        super().__init__()\n        padding = (kernel_size - 1) * dilation // 2\n        self.depthwise = nn.Conv1d(channels, channels, kernel_size, padding=padding, \n                                   groups=channels, dilation=dilation)\n        self.pointwise = nn.Conv1d(channels, channels, 1)\n        self.norm = nn.BatchNorm1d(channels)\n        self.dropout = nn.Dropout(0.1)\n        \n    def forward(self, x):\n        residual = x\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        x = self.norm(x)\n        x = self.dropout(x)\n        return F.gelu(residual + x)\n\nclass EnhancedApneaNet(nn.Module):\n    \"\"\"Enhanced architecture for 90%+ accuracy with multi-modal inputs.\"\"\"\n    def __init__(self, d_model=192, n_blocks=10, dropout=0.2):\n        super().__init__()\n        \n        # Separate processing for raw ECG\n        self.ecg_stem = nn.Sequential(\n            nn.Conv1d(1, d_model//2, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(d_model//2),\n            nn.GELU(),\n            nn.Conv1d(d_model//2, d_model, kernel_size=5, padding=2, stride=2),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n        )\n        \n        # Separate processing for RR intervals (180 samples at 3Hz)\n        self.rr_processor = nn.Sequential(\n            nn.Conv1d(1, d_model//2, kernel_size=5, padding=2),\n            nn.BatchNorm1d(d_model//2),\n            nn.GELU(),\n            nn.Conv1d(d_model//2, d_model, kernel_size=5, padding=2),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n        )\n        \n        # Separate processing for R-peak amplitudes\n        self.amp_processor = nn.Sequential(\n            nn.Conv1d(1, d_model//2, kernel_size=5, padding=2),\n            nn.BatchNorm1d(d_model//2),\n            nn.GELU(),\n            nn.Conv1d(d_model//2, d_model, kernel_size=5, padding=2),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n        )\n        \n        # Fusion layer\n        self.fusion = nn.Conv1d(d_model * 3, d_model, 1)\n        \n        # Enhanced residual blocks with varying receptive fields and dilations\n        self.blocks = nn.ModuleList([\n            EnhancedResBlock(d_model, kernel_size=7 if i % 3 == 0 else (11 if i % 3 == 1 else 5),\n                           dilation=1 if i < n_blocks//2 else 2)\n            for i in range(n_blocks)\n        ])\n        \n        # Multi-head self-attention layers\n        self.attention_layers = nn.ModuleList([\n            MultiHeadSelfAttention(d_model, num_heads=8, dropout=dropout)\n            for _ in range(2)\n        ])\n        \n        # Channel attention\n        self.channel_attn = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Conv1d(d_model, d_model//4, 1),\n            nn.GELU(),\n            nn.Conv1d(d_model//4, d_model, 1),\n            nn.Sigmoid()\n        )\n        \n        # Enhanced classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 4, d_model * 2),\n            nn.BatchNorm1d(d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model, 2)\n        )\n        \n    def forward(self, ecg, rr, amp):\n        # Process ECG: (B, 6000, 1) -> (B, 1, 6000)\n        ecg = ecg.transpose(1, 2)\n        ecg_feat = self.ecg_stem(ecg)  # (B, d_model, L/4)\n        \n        # Process RR intervals: (B, 180, 1) -> (B, 1, 180)\n        rr = rr.transpose(1, 2)\n        rr_feat = self.rr_processor(rr)  # (B, d_model, 180)\n        \n        # Process R-peak amplitudes: (B, 180, 1) -> (B, 1, 180)\n        amp = amp.transpose(1, 2)\n        amp_feat = self.amp_processor(amp)  # (B, d_model, 180)\n        \n        # Align temporal dimensions\n        target_length = min(ecg_feat.size(2), rr_feat.size(2), amp_feat.size(2))\n        ecg_feat = F.adaptive_avg_pool1d(ecg_feat, target_length)\n        rr_feat = F.adaptive_avg_pool1d(rr_feat, target_length)\n        amp_feat = F.adaptive_avg_pool1d(amp_feat, target_length)\n        \n        # Fuse features\n        x = torch.cat([ecg_feat, rr_feat, amp_feat], dim=1)  # (B, 3*d_model, L)\n        x = self.fusion(x)  # (B, d_model, L)\n        \n        # Residual blocks\n        for block in self.blocks:\n            x = block(x)\n        \n        # Channel attention\n        attn_weights = self.channel_attn(x)\n        x = x * attn_weights\n        \n        # Self-attention\n        x_seq = x.transpose(1, 2)  # (B, L, d_model)\n        for attn_layer in self.attention_layers:\n            x_seq = attn_layer(x_seq)\n        x = x_seq.transpose(1, 2)  # (B, d_model, L)\n        \n        # Global pooling\n        x_avg = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n        x_max = F.adaptive_max_pool1d(x, 1).squeeze(-1)\n        x_std = torch.std(x, dim=2)\n        x_last = x[:, :, -1]\n        \n        # Combine features\n        x_combined = torch.cat([x_avg, x_max, x_std, x_last], dim=1)\n        \n        # Classify\n        logits = self.classifier(x_combined)\n        return logits\n\n# --------------------------- Enhanced Dataset ---------------------------\n\nclass EnhancedApneaDataset(Dataset):\n    \"\"\"Enhanced dataset with R-R interval and R-peak amplitude extraction.\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 6000, stride: int = 3000, split='train', augment=True):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        self.augment = augment and (split == 'train')\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'enhanced_apnea_{split}_{segment_length}_{stride}_v2.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} from {cache_file}\")\n            data = torch.load(cache_file)\n            self.ecg_segments = data['ecg_segments']\n            self.rr_segments = data['rr_segments']\n            self.amp_segments = data['amp_segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb required\"\n            assert record_names is not None, \"record_names required\"\n            \n            self.ecg_segments = []\n            self.rr_segments = []\n            self.amp_segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split}...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.ecg_segments) == 0:\n                raise RuntimeError(\"No segments loaded\")\n            \n            self.ecg_segments = torch.tensor(np.stack(self.ecg_segments, axis=0), dtype=torch.float32)\n            self.rr_segments = torch.tensor(np.stack(self.rr_segments, axis=0), dtype=torch.float32)\n            self.amp_segments = torch.tensor(np.stack(self.amp_segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving cache to {cache_file}\")\n            torch.save({\n                'ecg_segments': self.ecg_segments,\n                'rr_segments': self.rr_segments,\n                'amp_segments': self.amp_segments,\n                'labels': self.labels\n            }, cache_file)\n\n        if self.ecg_segments.ndim == 2:\n            self.ecg_segments = self.ecg_segments.unsqueeze(-1)\n        if self.rr_segments.ndim == 2:\n            self.rr_segments = self.rr_segments.unsqueeze(-1)\n        if self.amp_segments.ndim == 2:\n            self.amp_segments = self.amp_segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()}: {len(self.ecg_segments)} segments, \"\n              f\"Class: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            record = wfdb.rdrecord(str(self.data_dir / record_name))\n            signal = record.p_signal[:, 0].astype(np.float32)\n    \n            if np.isnan(signal).any():\n                nans = np.isnan(signal)\n                not_nans = ~nans\n                if not_nans.sum() > 0:\n                    signal[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(not_nans), signal[not_nans])\n                else:\n                    signal = np.zeros_like(signal)\n    \n            annotation = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            \n            n_minutes = len(signal) // 6000\n            minute_labels = np.zeros(n_minutes, dtype=int)\n            \n            for i, symbol in enumerate(annotation.symbol):\n                if symbol == 'A':\n                    sample = annotation.sample[i]\n                    minute = sample // 6000\n                    if minute < n_minutes:\n                        minute_labels[minute] = 1\n    \n            n_samples = len(signal)\n            for start in range(0, n_samples - self.segment_length + 1, self.stride):\n                end = start + self.segment_length\n                ecg_seg = signal[start:end].astype(np.float32)\n    \n                # Normalize ECG\n                seg_mean = np.nanmean(ecg_seg)\n                seg_std = np.nanstd(ecg_seg)\n                if np.isnan(seg_std) or seg_std < 1e-8:\n                    ecg_seg = ecg_seg - seg_mean\n                else:\n                    ecg_seg = (ecg_seg - seg_mean) / (seg_std + 1e-8)\n                ecg_seg = np.clip(ecg_seg, -10, 10)\n                \n                # Extract R-R intervals and R-peak amplitudes\n                rr_seg, amp_seg = extract_rr_features(signal[start:end], fs=100)\n    \n                minute = start // 6000\n                if minute < len(minute_labels):\n                    label = minute_labels[minute]\n                    self.ecg_segments.append(ecg_seg)\n                    self.rr_segments.append(rr_seg)\n                    self.amp_segments.append(amp_seg)\n                    self.labels.append(int(label))\n                    \n        except Exception as e:\n            print(f\"\\nError loading {record_name}: {e}\")\n    \n    def _augment(self, ecg, rr, amp):\n        \"\"\"Enhanced augmentation for all modalities.\"\"\"\n        ecg = ecg.numpy() if torch.is_tensor(ecg) else ecg\n        rr = rr.numpy() if torch.is_tensor(rr) else rr\n        amp = amp.numpy() if torch.is_tensor(amp) else amp\n        \n        if np.random.random() < 0.3:\n            # Gaussian noise\n            ecg = ecg + np.random.normal(0, 0.02, ecg.shape).astype(np.float32)\n            rr = rr + np.random.normal(0, 0.02, rr.shape).astype(np.float32)\n            amp = amp + np.random.normal(0, 0.02, amp.shape).astype(np.float32)\n        \n        if np.random.random() < 0.2:\n            # Scale\n            scale = np.random.uniform(0.95, 1.05)\n            ecg = ecg * scale\n            amp = amp * scale\n        \n        return torch.from_numpy(ecg), torch.from_numpy(rr), torch.from_numpy(amp)\n            \n    def __len__(self):\n        return self.ecg_segments.shape[0]\n\n    def __getitem__(self, idx):\n        ecg = self.ecg_segments[idx]\n        rr = self.rr_segments[idx]\n        amp = self.amp_segments[idx]\n        label = self.labels[idx]\n        \n        if self.augment:\n            ecg, rr, amp = self._augment(ecg, rr, amp)\n        \n        # Ensure correct shapes\n        if ecg.ndim == 1:\n            ecg = ecg.unsqueeze(-1)\n        if rr.ndim == 1:\n            rr = rr.unsqueeze(-1)\n        if amp.ndim == 1:\n            amp = amp.unsqueeze(-1)\n        \n        return ecg, rr, amp, label\n\n# -------------------------- Training with Metrics ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef compute_metrics(y_true, y_pred):\n    \"\"\"Compute sensitivity, specificity, and other metrics.\"\"\"\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    \n    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # Also called recall or TPR\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # TNR\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    f1 = 2 * precision * sensitivity / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    \n    return {\n        'sensitivity': sensitivity,\n        'specificity': specificity,\n        'precision': precision,\n        'f1': f1,\n        'accuracy': accuracy\n    }\n\ndef train_epoch(model, dataloader, criterion, optimizer, scheduler, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 15)\n    start_time = time.time()\n\n    for batch_idx, (ecg, rr, amp, target) in enumerate(dataloader, 1):\n        ecg = ecg.to(device, non_blocking=True)\n        rr = rr.to(device, non_blocking=True)\n        amp = amp.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(ecg, rr, amp)\n            loss = criterion(output, target)\n        \n        if torch.isnan(loss):\n            print(f\"\\nWARNING: NaN loss, skipping batch {batch_idx}\")\n            continue\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n        \n        scheduler.step()\n\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            speed = batch_idx / (time.time() - start_time)\n            eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n            \n            print(f\"  Ep {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"({speed:.1f} b/s, ETA: {eta:.0f}s)\", end='\\r')\n\n    print()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for ecg, rr, amp, target in dataloader:\n            ecg = ecg.to(device, non_blocking=True)\n            rr = rr.to(device, non_blocking=True)\n            amp = amp.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(ecg, rr, amp)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            all_preds.extend(pred.cpu().tolist())\n            all_targets.extend(target.cpu().tolist())\n            all_probs.extend(probs.cpu().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    \n    # Compute all metrics including sensitivity and specificity\n    metrics = compute_metrics(all_targets, all_preds)\n    \n    try:\n        auc = roc_auc_score(all_targets, all_probs)\n    except:\n        auc = 0.0\n    \n    return avg_loss, metrics, np.array(all_probs), auc\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(\"No valid records found\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    import rand","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nEnhanced high-performance model for 90%+ apnea detection accuracy.\nIncludes R-R interval extraction, R-peak amplitude processing, and advanced metrics.\nOptimized for Tesla P100 16GB GPU.\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\ntry:\n    from scipy import signal as scipy_signal\n    from scipy.interpolate import interp1d\nexcept:\n    scipy_signal = None\n    interp1d = None\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n\n# ----------------------------- R-Peak Detection --------------------------\n\ndef detect_r_peaks(ecg_signal, fs=100):\n    \"\"\"\n    Detect R-peaks using a simple but effective algorithm.\n    Based on Hamilton method principles.\n    \"\"\"\n    # Bandpass filter (5-15 Hz for QRS complex)\n    if scipy_signal is None:\n        # Fallback: simple moving average\n        window = int(0.12 * fs)\n        filtered = np.convolve(ecg_signal, np.ones(window)/window, mode='same')\n    else:\n        nyquist = fs / 2\n        low = 5 / nyquist\n        high = 15 / nyquist\n        b, a = scipy_signal.butter(2, [low, high], btype='band')\n        filtered = scipy_signal.filtfilt(b, a, ecg_signal)\n    \n    # Derivative (emphasize QRS slope)\n    diff = np.diff(filtered)\n    diff = np.abs(diff)\n    \n    # Moving average\n    window = int(0.08 * fs)\n    integrated = np.convolve(diff, np.ones(window)/window, mode='same')\n    \n    # Threshold-based detection\n    threshold = np.mean(integrated) + 0.5 * np.std(integrated)\n    \n    # Find peaks\n    peaks = []\n    refractory = int(0.2 * fs)  # 200ms refractory period\n    \n    for i in range(1, len(integrated) - 1):\n        if integrated[i] > threshold and integrated[i] > integrated[i-1] and integrated[i] > integrated[i+1]:\n            if len(peaks) == 0 or i - peaks[-1] > refractory:\n                # Find actual peak in original signal around this point\n                search_window = int(0.05 * fs)\n                start = max(0, i - search_window)\n                end = min(len(ecg_signal), i + search_window)\n                actual_peak = start + np.argmax(ecg_signal[start:end])\n                peaks.append(actual_peak)\n    \n    return np.array(peaks)\n\n\ndef median_filter_rr(rr_intervals, threshold=0.3):\n    \"\"\"\n    Remove physiologically uninterpretable R-R intervals using median filter.\n    As described in Chen et al.\n    \"\"\"\n    if len(rr_intervals) < 3:\n        return rr_intervals\n    \n    filtered = []\n    for i, rr in enumerate(rr_intervals):\n        if i == 0 or i == len(rr_intervals) - 1:\n            filtered.append(rr)\n            continue\n        \n        # Get local median\n        local = rr_intervals[max(0, i-2):min(len(rr_intervals), i+3)]\n        median = np.median(local)\n        \n        # Check if current RR is within threshold of median\n        if abs(rr - median) / median < threshold:\n            filtered.append(rr)\n        else:\n            filtered.append(median)\n    \n    return np.array(filtered)\n\n\ndef extract_rr_features(ecg_signal, fs=100, target_length=180):\n    \"\"\"\n    Extract R-R intervals and R-peak amplitudes from ECG signal.\n    Apply cubic interpolation at 3 Hz as described in the paper.\n    \"\"\"\n    # Detect R-peaks\n    r_peaks = detect_r_peaks(ecg_signal, fs)\n    \n    if len(r_peaks) < 2:\n        # Return zeros if no valid peaks\n        return np.zeros(target_length), np.zeros(target_length)\n    \n    # Extract R-R intervals (in seconds)\n    rr_intervals = np.diff(r_peaks) / fs\n    \n    # Apply median filter\n    rr_intervals = median_filter_rr(rr_intervals)\n    \n    # Extract R-peak amplitudes\n    r_amplitudes = ecg_signal[r_peaks[1:]]  # Align with RR intervals\n    \n    # Create time axis for interpolation\n    time_rr = np.cumsum(rr_intervals)\n    time_rr = np.concatenate([[0], time_rr])\n    \n    # Extend arrays to match\n    rr_intervals_ext = np.concatenate([[rr_intervals[0]], rr_intervals])\n    r_amplitudes_ext = np.concatenate([[r_amplitudes[0]], r_amplitudes])\n    \n    # Target time axis at 3 Hz\n    total_time = len(ecg_signal) / fs\n    target_time = np.linspace(0, total_time, target_length)\n    \n    # Cubic interpolation\n    if interp1d is not None and len(time_rr) > 3:\n        try:\n            f_rr = interp1d(time_rr, rr_intervals_ext, kind='cubic', fill_value='extrapolate')\n            f_amp = interp1d(time_rr, r_amplitudes_ext, kind='cubic', fill_value='extrapolate')\n            \n            rr_interpolated = f_rr(target_time)\n            amp_interpolated = f_amp(target_time)\n        except:\n            # Fallback to linear\n            f_rr = interp1d(time_rr, rr_intervals_ext, kind='linear', fill_value='extrapolate')\n            f_amp = interp1d(time_rr, r_amplitudes_ext, kind='linear', fill_value='extrapolate')\n            \n            rr_interpolated = f_rr(target_time)\n            amp_interpolated = f_amp(target_time)\n    else:\n        # Simple linear interpolation fallback\n        rr_interpolated = np.interp(target_time, time_rr, rr_intervals_ext)\n        amp_interpolated = np.interp(target_time, time_rr, r_amplitudes_ext)\n    \n    # Clip outliers\n    rr_interpolated = np.clip(rr_interpolated, 0.3, 2.0)  # 30-200 bpm\n    \n    return rr_interpolated, amp_interpolated\n\n\n# ----------------------------- Enhanced Model ---------------------------\n\nclass MultiScaleConvBlock(nn.Module):\n    \"\"\"Multi-scale convolution block for capturing different temporal patterns.\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv1 = nn.Conv1d(in_channels, out_channels // 3, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(in_channels, out_channels // 3, kernel_size=5, padding=2)\n        self.conv3 = nn.Conv1d(in_channels, out_channels // 3, kernel_size=7, padding=3)\n        self.bn = nn.BatchNorm1d(out_channels)\n        \n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.conv2(x)\n        x3 = self.conv3(x)\n        x = torch.cat([x1, x2, x3], dim=1)\n        x = self.bn(x)\n        return F.gelu(x)\n\n\nclass EnhancedResBlock(nn.Module):\n    \"\"\"Enhanced residual block with squeeze-excitation attention.\"\"\"\n    def __init__(self, channels, kernel_size=7):\n        super().__init__()\n        self.conv1 = nn.Conv1d(channels, channels, kernel_size, padding=kernel_size//2, groups=channels)\n        self.conv2 = nn.Conv1d(channels, channels, 1)\n        self.bn = nn.BatchNorm1d(channels)\n        \n        # Squeeze-and-Excitation\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Conv1d(channels, channels // 4, 1),\n            nn.GELU(),\n            nn.Conv1d(channels // 4, channels, 1),\n            nn.Sigmoid()\n        )\n        self.dropout = nn.Dropout(0.15)\n        \n    def forward(self, x):\n        residual = x\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.bn(x)\n        \n        # SE attention\n        se_weight = self.se(x)\n        x = x * se_weight\n        \n        x = self.dropout(x)\n        return F.gelu(residual + x)\n\n\nclass BiLSTMBlock(nn.Module):\n    \"\"\"Bidirectional LSTM for temporal pattern learning.\"\"\"\n    def __init__(self, input_size, hidden_size, num_layers=2, dropout=0.2):\n        super().__init__()\n        self.lstm = nn.LSTM(\n            input_size, hidden_size, num_layers,\n            batch_first=True, bidirectional=True, dropout=dropout if num_layers > 1 else 0\n        )\n        self.layer_norm = nn.LayerNorm(hidden_size * 2)\n        \n    def forward(self, x):\n        # x: (B, C, L) -> (B, L, C)\n        x = x.transpose(1, 2)\n        x, _ = self.lstm(x)\n        x = self.layer_norm(x)\n        # (B, L, C) -> (B, C, L)\n        return x.transpose(1, 2)\n\n\nclass EnhancedApneaNet(nn.Module):\n    \"\"\"\n    Enhanced architecture combining:\n    - Multi-channel input (raw ECG, R-R intervals, R-peak amplitudes)\n    - Multi-scale convolutions\n    - Residual blocks with SE attention\n    - BiLSTM for temporal modeling\n    - Multi-head attention\n    \"\"\"\n    def __init__(self, d_model=160, n_blocks=8, dropout=0.2):\n        super().__init__()\n        \n        # Three-channel processing: raw ECG, RR intervals, R-peak amplitudes\n        self.ecg_stem = nn.Sequential(\n            nn.Conv1d(1, d_model // 3, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(d_model // 3),\n            nn.GELU(),\n        )\n        \n        self.rr_stem = nn.Sequential(\n            nn.Conv1d(1, d_model // 3, kernel_size=5, padding=2),\n            nn.BatchNorm1d(d_model // 3),\n            nn.GELU(),\n        )\n        \n        self.amp_stem = nn.Sequential(\n            nn.Conv1d(1, d_model // 3, kernel_size=5, padding=2),\n            nn.BatchNorm1d(d_model // 3),\n            nn.GELU(),\n        )\n        \n        # Multi-scale fusion\n        self.fusion = MultiScaleConvBlock(d_model, d_model)\n        \n        # Residual blocks\n        self.blocks = nn.ModuleList([\n            EnhancedResBlock(d_model, kernel_size=7 if i % 2 == 0 else 11)\n            for i in range(n_blocks)\n        ])\n        \n        # BiLSTM for temporal dependencies\n        self.bilstm = BiLSTMBlock(d_model, d_model // 2, num_layers=2, dropout=dropout)\n        \n        # Multi-head attention\n        self.attention = nn.MultiheadAttention(d_model, num_heads=8, dropout=dropout, batch_first=True)\n        self.attn_norm = nn.LayerNorm(d_model)\n        \n        # Global pooling\n        self.gap = nn.AdaptiveAvgPool1d(1)\n        self.gmp = nn.AdaptiveMaxPool1d(1)\n        \n        # Classification head with more capacity\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 3, d_model * 2),\n            nn.BatchNorm1d(d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model, 2)\n        )\n        \n    def forward(self, x):\n        # x: (B, L, 3) - [raw_ecg, rr_intervals, r_amplitudes]\n        \n        # Split channels\n        ecg = x[:, :, 0:1].transpose(1, 2)  # (B, 1, L)\n        rr = x[:, :, 1:2].transpose(1, 2)   # (B, 1, L')\n        amp = x[:, :, 2:3].transpose(1, 2)  # (B, 1, L')\n        \n        # Process each channel\n        ecg_feat = self.ecg_stem(ecg)  # (B, d/3, L/2)\n        \n        # Upsample RR and amp to match ECG if needed\n        if rr.shape[-1] != ecg_feat.shape[-1]:\n            rr = F.interpolate(rr, size=ecg_feat.shape[-1], mode='linear', align_corners=False)\n            amp = F.interpolate(amp, size=ecg_feat.shape[-1], mode='linear', align_corners=False)\n        \n        rr_feat = self.rr_stem(rr)    # (B, d/3, L')\n        amp_feat = self.amp_stem(amp) # (B, d/3, L')\n        \n        # Concatenate and fuse\n        x = torch.cat([ecg_feat, rr_feat, amp_feat], dim=1)  # (B, d, L')\n        x = self.fusion(x)\n        \n        # Residual blocks\n        for block in self.blocks:\n            x = block(x)\n        \n        # BiLSTM\n        x = self.bilstm(x)  # (B, d, L')\n        \n        # Attention\n        x_seq = x.transpose(1, 2)  # (B, L', d)\n        x_attn, _ = self.attention(x_seq, x_seq, x_seq)\n        x_attn = self.attn_norm(x_attn + x_seq)\n        x = x_attn.transpose(1, 2)  # (B, d, L')\n        \n        # Global pooling\n        x_avg = self.gap(x).squeeze(-1)  # (B, d)\n        x_max = self.gmp(x).squeeze(-1)  # (B, d)\n        x_attn_pool = x_attn.mean(dim=1)  # (B, d)\n        \n        # Combine\n        x_combined = torch.cat([x_avg, x_max, x_attn_pool], dim=1)  # (B, 3*d)\n        \n        # Classify\n        logits = self.classifier(x_combined)\n        return logits\n\n\n# --------------------------- Enhanced Dataset ---------------------------\n\nclass EnhancedApneaDataset(Dataset):\n    \"\"\"\n    Enhanced dataset with R-R interval and R-peak amplitude extraction.\n    \"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 6000, stride: int = 3000, split='train', augment=True):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        self.augment = augment and (split == 'train')\n        self.fs = 100  # Sampling frequency\n        self.rr_length = 180  # 60s * 3Hz\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'enhanced_apnea_{split}_{segment_length}_{stride}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} from {cache_file}\")\n            data = torch.load(cache_file)\n            self.segments = data['segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb required\"\n            assert record_names is not None, \"record_names required\"\n            \n            self.segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split} with R-R extraction...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.segments) == 0:\n                raise RuntimeError(\"No segments loaded\")\n            \n            self.segments = torch.tensor(np.stack(self.segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving cache to {cache_file}\")\n            torch.save({'segments': self.segments, 'labels': self.labels}, cache_file)\n\n        print(f\"{split.capitalize()}: {len(self.segments)} segments (3-channel), \"\n              f\"Class: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            record = wfdb.rdrecord(str(self.data_dir / record_name))\n            signal = record.p_signal[:, 0].astype(np.float32)\n    \n            # Handle NaNs\n            if np.isnan(signal).any():\n                nans = np.isnan(signal)\n                not_nans = ~nans\n                if not_nans.sum() > 0:\n                    signal[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(not_nans), signal[not_nans])\n                else:\n                    signal = np.zeros_like(signal)\n    \n            annotation = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            \n            n_minutes = len(signal) // 6000\n            minute_labels = np.zeros(n_minutes, dtype=int)\n            \n            for i, symbol in enumerate(annotation.symbol):\n                if symbol == 'A':\n                    sample = annotation.sample[i]\n                    minute = sample // 6000\n                    if minute < n_minutes:\n                        minute_labels[minute] = 1\n    \n            n_samples = len(signal)\n            for start in range(0, n_samples - self.segment_length + 1, self.stride):\n                end = start + self.segment_length\n                seg = signal[start:end].astype(np.float32)\n    \n                # Normalize raw ECG\n                seg_mean = np.nanmean(seg)\n                seg_std = np.nanstd(seg)\n                if np.isnan(seg_std) or seg_std < 1e-8:\n                    seg_norm = seg - seg_mean\n                else:\n                    seg_norm = (seg - seg_mean) / (seg_std + 1e-8)\n                seg_norm = np.clip(seg_norm, -10, 10)\n                \n                # Extract R-R intervals and R-peak amplitudes\n                rr_intervals, r_amplitudes = extract_rr_features(seg, self.fs, self.rr_length)\n                \n                # Normalize RR intervals\n                rr_mean = np.mean(rr_intervals)\n                rr_std = np.std(rr_intervals)\n                if rr_std > 1e-8:\n                    rr_intervals = (rr_intervals - rr_mean) / (rr_std + 1e-8)\n                else:\n                    rr_intervals = rr_intervals - rr_mean\n                rr_intervals = np.clip(rr_intervals, -10, 10)\n                \n                # Normalize R-peak amplitudes\n                amp_mean = np.mean(r_amplitudes)\n                amp_std = np.std(r_amplitudes)\n                if amp_std > 1e-8:\n                    r_amplitudes = (r_amplitudes - amp_mean) / (amp_std + 1e-8)\n                else:\n                    r_amplitudes = r_amplitudes - amp_mean\n                r_amplitudes = np.clip(r_amplitudes, -10, 10)\n                \n                # Interpolate RR and amplitudes to match segment length\n                if len(rr_intervals) != self.segment_length:\n                    rr_intervals = np.interp(\n                        np.linspace(0, 1, self.segment_length),\n                        np.linspace(0, 1, len(rr_intervals)),\n                        rr_intervals\n                    )\n                    r_amplitudes = np.interp(\n                        np.linspace(0, 1, self.segment_length),\n                        np.linspace(0, 1, len(r_amplitudes)),\n                        r_amplitudes\n                    )\n                \n                # Stack: [raw_ecg, rr_intervals, r_amplitudes]\n                multi_channel = np.stack([seg_norm, rr_intervals, r_amplitudes], axis=-1)\n    \n                minute = start // 6000\n                if minute < len(minute_labels):\n                    label = minute_labels[minute]\n                    self.segments.append(multi_channel)\n                    self.labels.append(int(label))\n                    \n        except Exception as e:\n            print(f\"\\nError loading {record_name}: {e}\")\n    \n    def _augment(self, seg):\n        \"\"\"Enhanced augmentation for multi-channel data.\"\"\"\n        seg = seg.numpy() if torch.is_tensor(seg) else seg\n        \n        # Random noise on raw ECG channel\n        if np.random.random() < 0.3:\n            seg[:, 0] = seg[:, 0] + np.random.normal(0, 0.03, seg.shape[0]).astype(np.float32)\n        \n        # Random scaling on all channels\n        if np.random.random() < 0.2:\n            scale = np.random.uniform(0.95, 1.05)\n            seg = seg * scale\n        \n        # Time shift\n        if np.random.random() < 0.3:\n            shift = np.random.randint(-100, 100)\n            seg = np.roll(seg, shift, axis=0)\n        \n        return torch.from_numpy(seg)\n            \n    def __len__(self):\n        return self.segments.shape[0]\n\n    def __getitem__(self, idx):\n        seg = self.segments[idx]\n        label = self.labels[idx]\n        \n        if self.augment:\n            seg = self._augment(seg)\n        \n        return seg, label\n\n\n# -------------------------- Training & Metrics ------------------------\n\ndef compute_class_weights(labels_tensor):\n    \"\"\"Compute balanced class weights with stronger emphasis on minority class.\"\"\"\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    # Use sqrt for more balanced weighting\n    weights = [np.sqrt(total / (num_classes * counts.get(i, 1))) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\n\ndef compute_metrics(y_true, y_pred, y_probs):\n    \"\"\"Compute comprehensive metrics including sensitivity and specificity.\"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Sensitivity (Recall) = TP / (TP + FN)\n    sensitivity = recall_score(y_true, y_pred, zero_division=0)\n    \n    # Specificity = TN / (TN + FP)\n    if cm.shape == (2, 2):\n        tn, fp, fn, tp = cm.ravel()\n        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    else:\n        specificity = 0\n    \n    precision = precision_score(y_true, y_pred, zero_division=0)\n    f1 = f1_score(y_true, y_pred, zero_division=0)\n    \n    try:\n        auc = roc_auc_score(y_true, y_probs)\n    except:\n        auc = 0.0\n    \n    return {\n        'sensitivity': sensitivity,\n        'specificity': specificity,\n        'precision': precision,\n        'f1': f1,\n        'auc': auc\n    }\n\n\ndef train_epoch(model, dataloader, criterion, optimizer, scheduler, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 15)\n    start_time = time.time()\n\n    for batch_idx, (data, target) in enumerate(dataloader, 1):\n        data = data.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(data)\n            loss = criterion(output, target)\n        \n        if torch.isnan(loss):\n            print(f\"\\nWARNING: NaN loss, skipping batch {batch_idx}\")\n            continue\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n        \n        scheduler.step()\n\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            speed = batch_idx / (time.time() - start_time)\n            eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n            \n            print(f\"  Ep {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"({speed:.1f} b/s, ETA: {eta:.0f}s)\", end='\\r')\n\n    print()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for data, target in dataloader:\n            data = data.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(data)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().tolist())\n            all_targets.extend(target.cpu().tolist())\n            all_probs.extend(probs.cpu().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    metrics = compute_metrics(all_targets, all_preds, all_probs)\n    \n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs), metrics\n\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T09:36:43.953413Z","iopub.execute_input":"2025-11-28T09:36:43.954112Z","iopub.status.idle":"2025-11-28T09:36:44.008952Z","shell.execute_reply.started":"2025-11-28T09:36:43.954084Z","shell.execute_reply":"2025-11-28T09:36:44.008263Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nHigh-performance apnea detection with R-R interval extraction (Target: 90%+ accuracy)\nBased on PhysioNet Apnea-ECG Database methodology\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy import signal as scipy_signal\nfrom scipy.interpolate import interp1d\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- R-Peak Detection & R-R Interval Extraction ---------------------------------\n\ndef detect_r_peaks_hamilton(ecg_signal, fs=100):\n    \"\"\"\n    Hamilton R-peak detection algorithm\n    Returns indices of R-peaks\n    \"\"\"\n    # Bandpass filter (5-15 Hz)\n    b, a = scipy_signal.butter(2, [5, 15], btype='band', fs=fs)\n    filtered = scipy_signal.filtfilt(b, a, ecg_signal)\n    \n    # Derivative\n    diff_signal = np.diff(filtered)\n    \n    # Squaring\n    squared = diff_signal ** 2\n    \n    # Moving average integration (150ms window)\n    window_size = int(0.15 * fs)\n    integrated = np.convolve(squared, np.ones(window_size)/window_size, mode='same')\n    \n    # Find peaks\n    threshold = np.mean(integrated) + 0.5 * np.std(integrated)\n    peaks = []\n    refractory = int(0.2 * fs)  # 200ms refractory period\n    \n    for i in range(1, len(integrated) - 1):\n        if integrated[i] > threshold:\n            if integrated[i] > integrated[i-1] and integrated[i] > integrated[i+1]:\n                if not peaks or (i - peaks[-1]) > refractory:\n                    peaks.append(i)\n    \n    return np.array(peaks)\n\ndef median_filter_rr(rr_intervals, window=5):\n    \"\"\"\n    Median filter for removing physiologically uninterpretable R-R intervals\n    Based on Chen et al. methodology\n    \"\"\"\n    if len(rr_intervals) < window:\n        return rr_intervals\n    \n    filtered = rr_intervals.copy()\n    median_rr = np.median(rr_intervals)\n    \n    for i in range(len(rr_intervals)):\n        # Check if RR interval is physiologically valid (300ms - 2000ms)\n        if rr_intervals[i] < 0.3 or rr_intervals[i] > 2.0:\n            filtered[i] = median_rr\n            continue\n        \n        # Median filter\n        start = max(0, i - window//2)\n        end = min(len(rr_intervals), i + window//2 + 1)\n        window_vals = rr_intervals[start:end]\n        local_median = np.median(window_vals)\n        \n        # Replace outliers (> 20% deviation from local median)\n        if abs(rr_intervals[i] - local_median) > 0.2 * local_median:\n            filtered[i] = local_median\n    \n    return filtered\n\ndef extract_rr_features(ecg_segment, fs=100):\n    \"\"\"\n    NaN-safe R-peak detection + 3 Hz interpolation.\n    Returns:\n        rr_interp  : length 180  (seconds * 3 Hz)\n        ramp_interp: length 180\n    \"\"\"\n    # ---- 1. R-peak detection -------------------------------------------------\n    r_peaks = detect_r_peaks_hamilton(ecg_segment, fs)\n    if len(r_peaks) < 3:                       # not enough peaks → dummy\n        return np.zeros(180, dtype=np.float32), np.zeros(180, dtype=np.float32)\n\n    # ---- 2. RR intervals -----------------------------------------------------\n    rr_sec = np.diff(r_peaks) / fs\n    rr_sec = median_filter_rr(rr_sec)          # outlier removal\n    rr_times = r_peaks[1:] / fs                # time stamp of each RR\n\n    # ---- 3. R-peak amplitudes ------------------------------------------------\n    ramp = ecg_segment[r_peaks[1:]]\n\n    # ---- 4. Cubic interpolation to 3 Hz -------------------------------------\n    targ_t = np.linspace(0, 60, 180)\n    kind = 'cubic' if len(rr_sec) >= 4 else 'linear'\n\n    f_rr   = interp1d(rr_times, rr_sec,   kind=kind, bounds_error=False, fill_value=(rr_sec[0], rr_sec[-1]))\n    f_amp  = interp1d(rr_times, ramp,     kind=kind, bounds_error=False, fill_value=(ramp[0],   ramp[-1]))\n\n    rr_out   = np.clip(f_rr(targ_t), 0.3, 2.0).astype(np.float32)\n    ramp_out = f_amp(targ_t).astype(np.float32)\n\n    # ---- 5. Normalise --------------------------------------------------------\n    rr_out   = (rr_out   - rr_out.mean())   / (rr_out.std()   + 1e-8)\n    ramp_out = (ramp_out - ramp_out.mean()) / (ramp_out.std() + 1e-8)\n    return rr_out, ramp_out\n\n# ----------------------------- Improved Model ---------------------------------\n\nclass FocalLoss(nn.Module):\n    \"\"\"Focal Loss for handling class imbalance\"\"\"\n    def __init__(self, alpha=0.25, gamma=2.0, weight=None):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.weight = weight\n        \n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, weight=self.weight, reduction='none')\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n        return focal_loss.mean()\n\nclass MultiScaleBlock(nn.Module):\n    \"\"\"Multi-scale feature extraction block\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        # ensure total output channels == out_channels\n        c1 = out_channels // 3\n        c2 = out_channels // 3\n        c3 = out_channels - c1 - c2  # remainder so c1 + c2 + c3 == out_channels\n\n        self.conv1 = nn.Conv1d(in_channels, c1, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(in_channels, c2, kernel_size=5, padding=2)\n        self.conv3 = nn.Conv1d(in_channels, c3, kernel_size=7, padding=3)\n        self.bn = nn.BatchNorm1d(out_channels)\n        \n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.conv2(x)\n        x3 = self.conv3(x)\n        out = torch.cat([x1, x2, x3], dim=1)\n        return F.gelu(self.bn(out))\n\n\nclass EnhancedResBlock(nn.Module):\n    \"\"\"Enhanced residual block with squeeze-excitation\"\"\"\n    def __init__(self, channels, kernel_size=7):\n        super().__init__()\n        self.conv1 = nn.Conv1d(channels, channels, kernel_size, padding=kernel_size//2, groups=channels)\n        self.conv2 = nn.Conv1d(channels, channels, 1)\n        self.norm = nn.BatchNorm1d(channels)\n        \n        # Squeeze-Excitation\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Conv1d(channels, channels//8, 1),\n            nn.GELU(),\n            nn.Conv1d(channels//8, channels, 1),\n            nn.Sigmoid()\n        )\n        self.dropout = nn.Dropout(0.15)\n        \n    def forward(self, x):\n        residual = x\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.norm(x)\n        \n        # Apply SE attention\n        se_weight = self.se(x)\n        x = x * se_weight\n        \n        x = self.dropout(x)\n        return F.gelu(residual + x)\n\nclass ImprovedApneaNet(nn.Module):\n    def __init__(self, d_model=256, n_blocks=10, dropout=0.15):\n        super().__init__()\n        # … rest of your code unchanged …\n        \n                # ====== Replace the three stem definitions with this block ======\n\n        # Ensure the three modality-channel outputs sum to d_model (avoid integer division loss)\n        c1 = d_model // 3\n        c2 = d_model // 3\n        c3 = d_model - c1 - c2  # remaining channels so c1+c2+c3 == d_model\n\n        # ECG pathway (6000 samples) -> c1 channels\n        self.ecg_stem = nn.Sequential(\n            nn.Conv1d(1, c1, kernel_size=15, padding=7, stride=4),\n            nn.BatchNorm1d(c1),\n            nn.GELU(),\n            nn.Conv1d(c1, c1, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c1),\n            nn.GELU(),\n        )\n\n        # RR interval pathway (180 samples @ 3Hz) -> c2 channels\n        self.rr_stem = nn.Sequential(\n            nn.Conv1d(1, c2, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c2),\n            nn.GELU(),\n            nn.Conv1d(c2, c2, kernel_size=5, padding=2),\n            nn.BatchNorm1d(c2),\n            nn.GELU(),\n        )\n\n        # R-amplitude pathway (180 samples @ 3Hz) -> c3 channels\n        self.ramp_stem = nn.Sequential(\n            nn.Conv1d(1, c3, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c3),\n            nn.GELU(),\n            nn.Conv1d(c3, c3, kernel_size=5, padding=2),\n            nn.BatchNorm1d(c3),\n            nn.GELU(),\n        )\n\n        # =================================================================\n\n        \n        # Multi-scale fusion\n        self.fusion = MultiScaleBlock(d_model, d_model)\n        \n        # Enhanced residual blocks\n        self.blocks = nn.ModuleList([\n            EnhancedResBlock(d_model, kernel_size=7 if i % 2 == 0 else 11)\n            for i in range(n_blocks)\n        ])\n        \n        # Temporal attention with larger context\n        self.temp_attn = nn.MultiheadAttention(d_model, num_heads=8, dropout=dropout, batch_first=True)\n        self.temp_norm = nn.LayerNorm(d_model)\n        self.temp_ffn = nn.Sequential(\n            nn.Linear(d_model, d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model)\n        )\n        \n        # Feature aggregation\n        self.global_pool = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Flatten()\n        )\n        \n        # Enhanced classifier with multiple paths\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 4, d_model * 2),\n            nn.BatchNorm1d(d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout * 0.5),\n            nn.Linear(d_model, 2)\n        )\n        \n    def forward(self, ecg, rr, ramp):\n        # Process each modality\n        # ecg: (B, 6000, 1) -> (B, 1, 6000)\n        # rr, ramp: (B, 180, 1) -> (B, 1, 180)\n        ecg = ecg.transpose(1, 2)\n        rr = rr.transpose(1, 2)\n        ramp = ramp.transpose(1, 2)\n        \n        ecg_feat = self.ecg_stem(ecg)  # (B, d//3, L1)\n        rr_feat = self.rr_stem(rr)      # (B, d//3, L2)\n        ramp_feat = self.ramp_stem(ramp)  # (B, d//3, L2)\n        \n        # Align sequence lengths and concatenate\n        target_len = min(ecg_feat.size(2), rr_feat.size(2), ramp_feat.size(2))\n        ecg_feat = F.adaptive_avg_pool1d(ecg_feat, target_len)\n        rr_feat = F.adaptive_avg_pool1d(rr_feat, target_len)\n        ramp_feat = F.adaptive_avg_pool1d(ramp_feat, target_len)\n        \n        x = torch.cat([ecg_feat, rr_feat, ramp_feat], dim=1)  # (B, d_model, L)\n        \n        # Multi-scale fusion\n        x = self.fusion(x)\n        \n        # Residual blocks\n        for block in self.blocks:\n            x = block(x)\n        \n        # Multiple pooling strategies\n        x_avg = F.adaptive_avg_pool1d(x, 1).squeeze(-1)  # (B, d_model)\n        x_max = F.adaptive_max_pool1d(x, 1).squeeze(-1)  # (B, d_model)\n        x_std = torch.std(x, dim=2)  # (B, d_model)\n        \n        # Temporal attention\n        x_seq = x.transpose(1, 2)  # (B, L, d_model)\n        x_attn, _ = self.temp_attn(x_seq, x_seq, x_seq)\n        x_attn = self.temp_norm(x_attn + x_seq)\n        x_attn = x_attn + self.temp_ffn(x_attn)\n        x_attn = x_attn.mean(dim=1)  # (B, d_model)\n        \n        # Combine all features\n        x_combined = torch.cat([x_avg, x_max, x_std, x_attn], dim=1)\n        \n        # Classify\n        logits = self.classifier(x_combined)\n        return logits\n\n# --------------------------- Enhanced Dataset ---------------------------\n\nclass EnhancedApneaDataset(Dataset):\n    \"\"\"Dataset with R-R interval and R-amplitude extraction\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 6000, stride: int = 3000, split='train', augment=True):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        self.augment = augment and (split == 'train')\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_enhanced_{split}_{segment_length}_{stride}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} from {cache_file}\")\n            data = torch.load(cache_file)\n            self.ecg_segments = data['ecg_segments']\n            self.rr_segments = data['rr_segments']\n            self.ramp_segments = data['ramp_segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb required\"\n            assert record_names is not None, \"record_names required\"\n            \n            self.ecg_segments = []\n            self.rr_segments = []\n            self.ramp_segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split} (with R-R extraction)...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.ecg_segments) == 0:\n                raise RuntimeError(\"No segments loaded\")\n            \n            self.ecg_segments = torch.tensor(np.stack(self.ecg_segments, axis=0), dtype=torch.float32)\n            self.rr_segments = torch.tensor(np.stack(self.rr_segments, axis=0), dtype=torch.float32)\n            self.ramp_segments = torch.tensor(np.stack(self.ramp_segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving cache to {cache_file}\")\n            torch.save({\n                'ecg_segments': self.ecg_segments,\n                'rr_segments': self.rr_segments,\n                'ramp_segments': self.ramp_segments,\n                'labels': self.labels\n            }, cache_file)\n\n        if self.ecg_segments.ndim == 2:\n            self.ecg_segments = self.ecg_segments.unsqueeze(-1)\n        if self.rr_segments.ndim == 2:\n            self.rr_segments = self.rr_segments.unsqueeze(-1)\n        if self.ramp_segments.ndim == 2:\n            self.ramp_segments = self.ramp_segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()}: {len(self.ecg_segments)} segments, \"\n              f\"Class: {Counter(self.labels.tolist())}\")\n\n        def _load_record(self, record_name: str):\n            try:\n                rec = wfdb.rdrecord(str(self.data_dir / record_name))\n                sig = rec.p_signal[:, 0].astype(np.float32)\n                if np.isnan(sig).any():                       # NaN interpolation\n                    nans = np.isnan(sig)\n                    sig[nans] = np.interp(np.flatnonzero(nans),np.flatnonzero(~nans), sig[~nans])\n\n                ann = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n                n_min = len(sig) // 6000\n                mins  = np.zeros(n_min, dtype=int)\n                for samp, sym in zip(ann.sample, ann.symbol):\n                    if sym == 'A':\n                        m = samp // 6000\n                        if m < n_min:\n                            mins[m] = 1\n\n                for start in range(0, len(sig) - self.segment_length + 1, self.stride):\n                    seg = sig[start:start + self.segment_length]\n                # ---- normalise ECG -------------------------------------------------\n                    seg = (seg - seg.mean()) / (seg.std() + 1e-8)\n                    seg = np.clip(seg, -10, 10)\n\n                    rr, ramp = extract_rr_features(seg, fs=100)\n\n                    minute = start // 6000\n                    if minute < len(mins):\n                        self.ecg_segments.append(seg)\n                        self.rr_segments.append(rr)\n                        self.ramp_segments.append(ramp)\n                        self.labels.append(int(mins[minute]))\n            except Exception as e:\n                print(f'\\nSkip {record_name}: {e}')\n    \n    def _augment(self, ecg, rr, ramp):\n        ecg, rr, ramp = map(lambda x: x.numpy() if torch.is_tensor(x) else x, (ecg, rr, ramp))\n\n        if np.random.rand() < 0.5:\n            ecg += np.random.normal(0, 0.02, ecg.shape).astype(np.float32)\n            rr  += np.random.normal(0, 0.01, rr.shape).astype(np.float32)\n            ramp+= np.random.normal(0, 0.01, ramp.shape).astype(np.float32)\n\n        if np.random.rand() < 0.3:\n            scale = np.random.uniform(0.9, 1.1)\n            ecg *= scale\n            ramp*= scale\n\n        if np.random.rand() < 0.2:\n            shift = np.random.randint(-150, 150)\n            ecg = np.roll(ecg, shift)\n\n        return map(torch.from_numpy, (ecg, rr, ramp))\n            \n    def __len__(self):\n        return self.ecg_segments.shape[0]\n\n    def __getitem__(self, idx):\n        ecg = self.ecg_segments[idx]\n        rr = self.rr_segments[idx]\n        ramp = self.ramp_segments[idx]\n        label = self.labels[idx]\n        \n        if self.augment:\n            ecg, rr, ramp = self._augment(ecg, rr, ramp)\n        \n        # Ensure correct shape\n        if ecg.ndim == 1:\n            ecg = ecg.unsqueeze(-1)\n        if rr.ndim == 1:\n            rr = rr.unsqueeze(-1)\n        if ramp.ndim == 1:\n            ramp = ramp.unsqueeze(-1)\n        \n        return ecg, rr, ramp, label\n\n# -------------------------- Training ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model, dataloader, criterion, optimizer, scheduler, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 15)\n    start_time = time.time()\n\n    for batch_idx, (ecg, rr, ramp, target) in enumerate(dataloader, 1):\n        ecg = ecg.to(device, non_blocking=True)\n        rr = rr.to(device, non_blocking=True)\n        ramp = ramp.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(ecg, rr, ramp)\n            loss = criterion(output, target)\n        \n        if torch.isnan(loss):\n            print(f\"\\nWARNING: NaN loss, skipping batch {batch_idx}\")\n            continue\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n        \n        scheduler.step()\n\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            speed = batch_idx / (time.time() - start_time)\n            eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n            \n            print(f\"  Ep {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"({speed:.1f} b/s, ETA: {eta:.0f}s)\", end='\\r')\n\n    print()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for ecg, rr, ramp, target in dataloader:\n            ecg = ecg.to(device, non_blocking=True)\n            rr = rr.to(device, non_blocking=True)\n            ramp = ramp.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            \n            output = model(ecg, rr, ramp)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().tolist())\n            all_targets.extend(target.cpu().tolist())\n            all_probs.extend(probs.cpu().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    precision = precision_score(all_targets, all_preds, zero_division=0)\n    recall = recall_score(all_targets, all_preds, zero_division=0)\n    f1 = f1_score(all_targets, all_preds, zero_division=0)\n    \n    # Calculate specificity and sensitivity\n    tn, fp, fn, tp = confusion_matrix(all_targets, all_preds).ravel()\n    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0  # Same as recall\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n    \n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs), precision, recall, f1, sensitivity, specificity\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(\"No valid records found\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train: {len(train_records)}, Val: {len(val_records)}\\n\")\n\n        # inside main(...) — create datasets\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), train_records, cache_dir,\n        args.segment_length, args.stride, 'train', augment=True\n    )\n    val_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), val_records, cache_dir,\n        args.segment_length, args.stride, 'val', augment=False\n    )\n\n    num_workers = 2 if str(DATA_DIR).startswith('/kaggle') else 4\n\n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Device: {device}\")\n    if device.type == 'cuda':\n        try:\n            print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        except Exception:\n            pass\n        torch.cuda.empty_cache()\n\n    model = ImprovedApneaNet(\n        d_model=args.d_model, n_blocks=args.n_blocks, dropout=args.dropout\n    ).to(device)\n\n    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n\n    # Use Focal Loss for better class imbalance handling\n        # stable, NaN-free loss with class weights\n    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n\n    optimizer = torch.optim.AdamW(\n        model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n    )\n\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, max_lr=args.lr, epochs=args.epochs,\n        steps_per_epoch=len(train_loader), pct_start=0.25\n    )\n\n    scaler = torch.amp.GradScaler() if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    best_val_f1 = 0.0\n    no_improve = 0\n\n    print(\"\\nStarting training...\")\n    print(\"=\"*100)\n\n    for epoch in range(1, args.epochs + 1):\n        epoch_start = time.time()\n\n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, scheduler, device, epoch, scaler\n        )\n\n        val_loss, val_acc, _, val_targets, val_probs, precision, recall, f1, sensitivity, specificity = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except Exception:\n            auc = 0.0\n\n        epoch_time = time.time() - epoch_start\n\n        print(f\"Epoch {epoch:2d}/{args.epochs} ({epoch_time:.1f}s)\")\n        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n        print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={auc:.4f}\")\n        print(f\"         Prec={precision:.3f}, Rec={recall:.3f}, F1={f1:.3f}\")\n        print(f\"         Sensitivity={sensitivity:.3f}, Specificity={specificity:.3f}\")\n\n        if val_acc > best_val_acc or (val_acc >= best_val_acc and f1 > best_val_f1):\n            best_val_acc = val_acc\n            best_val_f1 = f1\n            no_improve = 0\n            torch.save({\n                'epoch': epoch, 'model_state_dict': model.state_dict(),\n                'val_acc': val_acc, 'val_auc': auc, 'val_f1': f1,\n                'sensitivity': sensitivity, 'specificity': specificity\n            }, args.best_model_path)\n            print(f\"  ✓ Best! (Acc={val_acc:.2f}%, F1={f1:.3f}, Sens={sensitivity:.3f}, Spec={specificity:.3f})\")\n        else:\n            no_improve += 1\n            print(f\"  No improvement ({no_improve}/{args.patience})\")\n\n        print(\"-\"*100)\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stop at epoch {epoch}\")\n            break\n\n    print(f\"\\n{'='*100}\")\n    print(f\"BEST - Accuracy: {best_val_acc:.2f}%, F1: {best_val_f1:.3f}\")\n    print(f\"{'='*100}\")\n\n\nif __name__ == '__main__':\n    kaggle_data = '/kaggle/input/vincent2/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_model.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_model.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_model.pth'\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=6000)\n    parser.add_argument('--stride', type=int, default=2400)  # 60% overlap for more data\n    parser.add_argument('--batch-size', type=int, default=48)  # Adjusted for multi-modal\n    parser.add_argument('--epochs', type=int, default=100)\n    parser.add_argument('--lr', type=float, default=1e-3)\n    parser.add_argument('--weight-decay', type=float, default=1e-4)\n    parser.add_argument('--d-model', type=int, default=256)\n    parser.add_argument('--n-blocks', type=int, default=10)\n    parser.add_argument('--dropout', type=float, default=0.15)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--patience', type=int, default=20)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n\n    if args.data_dir is None:\n        raise SystemExit(\"ERROR: Dataset not found\")\n\n    print(\"=\"*100)\n    print(\"ENHANCED MODEL WITH R-R INTERVALS (Target: 90%+ Accuracy)\")\n    print(\"=\"*100)\n    print(f\"  Data:       {args.data_dir}\")\n    print(f\"  Segment:    {args.segment_length} samples (60s), stride={args.stride}\")\n    print(f\"  Features:   ECG + R-R Intervals + R-peak Amplitudes\")\n    print(f\"  Batch:      {args.batch_size}\")\n    print(f\"  Epochs:     {args.epochs}\")\n    print(f\"  Model:      d_model={args.d_model}, blocks={args.n_blocks}\")\n    print(f\"  Optimizer:  AdamW (lr={args.lr}, wd={args.weight_decay})\")\n    print(f\"  Loss:       Focal Loss (alpha=0.25, gamma=2.0)\")\n    print(\"=\"*100 + \"\\n\")\n\n    main(args)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T09:58:29.167336Z","iopub.execute_input":"2025-11-28T09:58:29.168158Z","iopub.status.idle":"2025-11-28T10:00:01.522130Z","shell.execute_reply.started":"2025-11-28T09:58:29.168127Z","shell.execute_reply":"2025-11-28T10:00:01.521001Z"}},"outputs":[{"name":"stdout","text":"====================================================================================================\nENHANCED MODEL WITH R-R INTERVALS (Target: 90%+ Accuracy)\n====================================================================================================\n  Data:       /kaggle/input/vincent2/apnea-ecg-database-1.0.0\n  Segment:    6000 samples (60s), stride=2400\n  Features:   ECG + R-R Intervals + R-peak Amplitudes\n  Batch:      48\n  Epochs:     100\n  Model:      d_model=256, blocks=10\n  Optimizer:  AdamW (lr=0.001, wd=0.0001)\n  Loss:       Focal Loss (alpha=0.25, gamma=2.0)\n====================================================================================================\n\nFound 43 valid records\nTrain: 34, Val: 9\n\nLoading cached train from /kaggle/working/apnea_enhanced_train_6000_2400.pt\nTrain: 41751 segments, Class: Counter({0: 26395, 1: 15356})\nLoading cached val from /kaggle/working/apnea_enhanced_val_6000_2400.pt\nVal: 10777 segments, Class: Counter({0: 5862, 1: 4915})\nDevice: cuda\nGPU: Tesla P100-PCIE-16GB\nParameters: 2,496,778\n\nClass weights: tensor([0.7909, 1.3594], device='cuda:0')\n\nStarting training...\n====================================================================================================\n\nWARNING: NaN loss, skipping batch 48\n\nWARNING: NaN loss, skipping batch 53\n\nWARNING: NaN loss, skipping batch 57\n  Ep 1 [  58/870] Loss: 0.6449 Acc: 66.10% (21.4 b/s, ETA: 38s)\nWARNING: NaN loss, skipping batch 59\n\nWARNING: NaN loss, skipping batch 79\n\nWARNING: NaN loss, skipping batch 108\n  Ep 1 [ 116/870] Loss: 0.6121 Acc: 68.31% (22.7 b/s, ETA: 33s)\nWARNING: NaN loss, skipping batch 118\n\nWARNING: NaN loss, skipping batch 154\n\nWARNING: NaN loss, skipping batch 155\n\nWARNING: NaN loss, skipping batch 167\n  Ep 1 [ 174/870] Loss: 0.5864 Acc: 69.14% (23.2 b/s, ETA: 30s)\nWARNING: NaN loss, skipping batch 212\n\nWARNING: NaN loss, skipping batch 221\n  Ep 1 [ 232/870] Loss: 0.5665 Acc: 70.88% (22.9 b/s, ETA: 28s)\nWARNING: NaN loss, skipping batch 245\n\nWARNING: NaN loss, skipping batch 247\n\nWARNING: NaN loss, skipping batch 251\n\nWARNING: NaN loss, skipping batch 261\n\nWARNING: NaN loss, skipping batch 268\n\nWARNING: NaN loss, skipping batch 275\n  Ep 1 [ 290/870] Loss: 0.5416 Acc: 72.15% (22.9 b/s, ETA: 25s)\nWARNING: NaN loss, skipping batch 292\n\nWARNING: NaN loss, skipping batch 313\n\nWARNING: NaN loss, skipping batch 325\n  Ep 1 [ 348/870] Loss: 0.5256 Acc: 73.24% (23.1 b/s, ETA: 23s)\nWARNING: NaN loss, skipping batch 358\n\nWARNING: NaN loss, skipping batch 380\n\nWARNING: NaN loss, skipping batch 381\n  Ep 1 [ 406/870] Loss: 0.5085 Acc: 74.63% (23.0 b/s, ETA: 20s)\nWARNING: NaN loss, skipping batch 412\n\nWARNING: NaN loss, skipping batch 424\n\nWARNING: NaN loss, skipping batch 426\n\nWARNING: NaN loss, skipping batch 446\n\nWARNING: NaN loss, skipping batch 452\n\nWARNING: NaN loss, skipping batch 453\n\nWARNING: NaN loss, skipping batch 457\n  Ep 1 [ 464/870] Loss: 0.4908 Acc: 75.61% (23.0 b/s, ETA: 18s)\nWARNING: NaN loss, skipping batch 476\n\nWARNING: NaN loss, skipping batch 493\n\nWARNING: NaN loss, skipping batch 518\n  Ep 1 [ 522/870] Loss: 0.4794 Acc: 76.47% (23.0 b/s, ETA: 15s)\nWARNING: NaN loss, skipping batch 524\n\nWARNING: NaN loss, skipping batch 525\n\nWARNING: NaN loss, skipping batch 531\n\nWARNING: NaN loss, skipping batch 543\n\nWARNING: NaN loss, skipping batch 550\n  Ep 1 [ 580/870] Loss: 0.4682 Acc: 77.30% (23.2 b/s, ETA: 13s)\nWARNING: NaN loss, skipping batch 586\n\nWARNING: NaN loss, skipping batch 588\n\nWARNING: NaN loss, skipping batch 589\n\nWARNING: NaN loss, skipping batch 590\n\nWARNING: NaN loss, skipping batch 592\n\nWARNING: NaN loss, skipping batch 603\n\nWARNING: NaN loss, skipping batch 606\n\nWARNING: NaN loss, skipping batch 619\n\nWARNING: NaN loss, skipping batch 624\n\nWARNING: NaN loss, skipping batch 630\n\nWARNING: NaN loss, skipping batch 632\n  Ep 1 [ 638/870] Loss: 0.4538 Acc: 77.98% (23.4 b/s, ETA: 10s)\nWARNING: NaN loss, skipping batch 650\n\nWARNING: NaN loss, skipping batch 654\n\nWARNING: NaN loss, skipping batch 659\n\nWARNING: NaN loss, skipping batch 663\n\nWARNING: NaN loss, skipping batch 674\n\nWARNING: NaN loss, skipping batch 676\n\nWARNING: NaN loss, skipping batch 692\n  Ep 1 [ 696/870] Loss: 0.4444 Acc: 78.60% (23.5 b/s, ETA: 7s)\nWARNING: NaN loss, skipping batch 728\n\nWARNING: NaN loss, skipping batch 744\n  Ep 1 [ 754/870] Loss: 0.4394 Acc: 79.17% (23.4 b/s, ETA: 5s)\nWARNING: NaN loss, skipping batch 755\n\nWARNING: NaN loss, skipping batch 779\n\nWARNING: NaN loss, skipping batch 781\n\nWARNING: NaN loss, skipping batch 788\n\nWARNING: NaN loss, skipping batch 795\n\nWARNING: NaN loss, skipping batch 796\n\nWARNING: NaN loss, skipping batch 801\n\nWARNING: NaN loss, skipping batch 803\n\nWARNING: NaN loss, skipping batch 808\n  Ep 1 [ 812/870] Loss: 0.4305 Acc: 79.64% (23.5 b/s, ETA: 2s)\nWARNING: NaN loss, skipping batch 814\n\nWARNING: NaN loss, skipping batch 847\n\nWARNING: NaN loss, skipping batch 859\n\nWARNING: NaN loss, skipping batch 861\n\nWARNING: NaN loss, skipping batch 866\n  Ep 1 [ 870/870] Loss: 0.4238 Acc: 80.13% (23.6 b/s, ETA: 0s)\nEpoch  1/100 (39.6s)\n  Train: Loss=0.4238, Acc=80.13%\n  Val:   Loss=nan, Acc=54.39%, AUC=0.0000\n         Prec=0.000, Rec=0.000, F1=0.000\n         Sensitivity=0.000, Specificity=1.000\n  ✓ Best! (Acc=54.39%, F1=0.000, Sens=0.000, Spec=1.000)\n----------------------------------------------------------------------------------------------------\n\nWARNING: NaN loss, skipping batch 1\n\nWARNING: NaN loss, skipping batch 27\n\nWARNING: NaN loss, skipping batch 39\n  Ep 2 [  58/870] Loss: 0.3554 Acc: 84.92% (21.6 b/s, ETA: 38s)\nWARNING: NaN loss, skipping batch 92\n\nWARNING: NaN loss, skipping batch 105\n\nWARNING: NaN loss, skipping batch 109\n\nWARNING: NaN loss, skipping batch 116\n\nWARNING: NaN loss, skipping batch 142\n\nWARNING: NaN loss, skipping batch 144\n\nWARNING: NaN loss, skipping batch 150\n\nWARNING: NaN loss, skipping batch 158\n\nWARNING: NaN loss, skipping batch 160\n\nWARNING: NaN loss, skipping batch 168\n\nWARNING: NaN loss, skipping batch 170\n  Ep 2 [ 174/870] Loss: 0.3294 Acc: 87.14% (23.6 b/s, ETA: 30s)\nWARNING: NaN loss, skipping batch 190\n\nWARNING: NaN loss, skipping batch 193\n\nWARNING: NaN loss, skipping batch 223\n  Ep 2 [ 232/870] Loss: 0.3323 Acc: 87.17% (23.7 b/s, ETA: 27s)\nWARNING: NaN loss, skipping batch 239\n\nWARNING: NaN loss, skipping batch 245\n\nWARNING: NaN loss, skipping batch 262\n\nWARNING: NaN loss, skipping batch 278\n\nWARNING: NaN loss, skipping batch 281\n\nWARNING: NaN loss, skipping batch 282\n\nWARNING: NaN loss, skipping batch 285\n\nWARNING: NaN loss, skipping batch 288\n  Ep 2 [ 290/870] Loss: 0.3280 Acc: 87.17% (23.9 b/s, ETA: 24s)\nWARNING: NaN loss, skipping batch 298\n\nWARNING: NaN loss, skipping batch 299\n\nWARNING: NaN loss, skipping batch 318\n\nWARNING: NaN loss, skipping batch 328\n\nWARNING: NaN loss, skipping batch 331\n  Ep 2 [ 348/870] Loss: 0.3274 Acc: 87.21% (24.0 b/s, ETA: 22s)\nWARNING: NaN loss, skipping batch 352\n\nWARNING: NaN loss, skipping batch 381\n\nWARNING: NaN loss, skipping batch 390\n\nWARNING: NaN loss, skipping batch 393\n  Ep 2 [ 406/870] Loss: 0.3264 Acc: 87.29% (24.0 b/s, ETA: 19s)\nWARNING: NaN loss, skipping batch 411\n\nWARNING: NaN loss, skipping batch 438\n\nWARNING: NaN loss, skipping batch 441\n\nWARNING: NaN loss, skipping batch 454\n\nWARNING: NaN loss, skipping batch 457\n  Ep 2 [ 464/870] Loss: 0.3241 Acc: 87.41% (24.0 b/s, ETA: 17s)\nWARNING: NaN loss, skipping batch 478\n\nWARNING: NaN loss, skipping batch 486\n\nWARNING: NaN loss, skipping batch 495\n\nWARNING: NaN loss, skipping batch 511\n  Ep 2 [ 522/870] Loss: 0.3236 Acc: 87.47% (23.9 b/s, ETA: 15s)\nWARNING: NaN loss, skipping batch 524\n\nWARNING: NaN loss, skipping batch 550\n\nWARNING: NaN loss, skipping batch 552\n\nWARNING: NaN loss, skipping batch 564\n\nWARNING: NaN loss, skipping batch 572\n  Ep 2 [ 580/870] Loss: 0.3225 Acc: 87.57% (24.0 b/s, ETA: 12s)\nWARNING: NaN loss, skipping batch 591\n\nWARNING: NaN loss, skipping batch 592\n\nWARNING: NaN loss, skipping batch 600\n\nWARNING: NaN loss, skipping batch 606\n\nWARNING: NaN loss, skipping batch 607\n\nWARNING: NaN loss, skipping batch 620\n  Ep 2 [ 638/870] Loss: 0.3213 Acc: 87.68% (24.1 b/s, ETA: 10s)\nWARNING: NaN loss, skipping batch 664\n\nWARNING: NaN loss, skipping batch 665\n  Ep 2 [ 696/870] Loss: 0.3238 Acc: 87.64% (23.9 b/s, ETA: 7s)\nWARNING: NaN loss, skipping batch 713\n\nWARNING: NaN loss, skipping batch 719\n\nWARNING: NaN loss, skipping batch 721\n\nWARNING: NaN loss, skipping batch 727\n  Ep 2 [ 754/870] Loss: 0.3244 Acc: 87.65% (23.8 b/s, ETA: 5s)\nWARNING: NaN loss, skipping batch 764\n\nWARNING: NaN loss, skipping batch 767\n\nWARNING: NaN loss, skipping batch 774\n\nWARNING: NaN loss, skipping batch 775\n\nWARNING: NaN loss, skipping batch 779\n\nWARNING: NaN loss, skipping batch 792\n\nWARNING: NaN loss, skipping batch 807\n  Ep 2 [ 812/870] Loss: 0.3224 Acc: 87.72% (23.9 b/s, ETA: 2s)\nWARNING: NaN loss, skipping batch 837\n\nWARNING: NaN loss, skipping batch 846\n\nWARNING: NaN loss, skipping batch 867\n  Ep 2 [ 870/870] Loss: 0.3228 Acc: 87.72% (23.8 b/s, ETA: 0s)\nEpoch  2/100 (39.1s)\n  Train: Loss=0.3228, Acc=87.72%\n  Val:   Loss=nan, Acc=54.39%, AUC=0.0000\n         Prec=0.000, Rec=0.000, F1=0.000\n         Sensitivity=0.000, Specificity=1.000\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n\nWARNING: NaN loss, skipping batch 9\n\nWARNING: NaN loss, skipping batch 13\n\nWARNING: NaN loss, skipping batch 19\n\nWARNING: NaN loss, skipping batch 33\n\nWARNING: NaN loss, skipping batch 43\n\nWARNING: NaN loss, skipping batch 51\n\nWARNING: NaN loss, skipping batch 57\n  Ep 3 [  58/870] Loss: 0.2882 Acc: 88.40% (23.3 b/s, ETA: 35s)\nWARNING: NaN loss, skipping batch 61\n\nWARNING: NaN loss, skipping batch 78\n\nWARNING: NaN loss, skipping batch 86\n\nWARNING: NaN loss, skipping batch 91\n\nWARNING: NaN loss, skipping batch 102\n\nWARNING: NaN loss, skipping batch 104\n  Ep 3 [ 116/870] Loss: 0.2978 Acc: 88.51% (23.4 b/s, ETA: 32s)\nWARNING: NaN loss, skipping batch 134\n\nWARNING: NaN loss, skipping batch 148\n\nWARNING: NaN loss, skipping batch 151\n\nWARNING: NaN loss, skipping batch 153\n\nWARNING: NaN loss, skipping batch 158\n  Ep 3 [ 174/870] Loss: 0.3047 Acc: 88.30% (23.5 b/s, ETA: 30s)\nWARNING: NaN loss, skipping batch 193\n\nWARNING: NaN loss, skipping batch 198\n\nWARNING: NaN loss, skipping batch 208\n\nWARNING: NaN loss, skipping batch 211\n  Ep 3 [ 232/870] Loss: 0.3077 Acc: 88.19% (23.7 b/s, ETA: 27s)\nWARNING: NaN loss, skipping batch 253\n\nWARNING: NaN loss, skipping batch 280\n\nWARNING: NaN loss, skipping batch 283\n\nWARNING: NaN loss, skipping batch 285\n\nWARNING: NaN loss, skipping batch 286\n  Ep 3 [ 290/870] Loss: 0.3049 Acc: 88.51% (23.9 b/s, ETA: 24s)\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/3901991631.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/3901991631.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         train_loss, train_acc = train_epoch(\n\u001b[0m\u001b[1;32m    678\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         )\n","\u001b[0;32m/tmp/ipykernel_47/3901991631.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, scheduler, device, epoch, scaler)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nHigh-performance apnea detection with R-R interval extraction (Target: 90%+ accuracy)\nBased on PhysioNet Apnea-ECG Database methodology\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy import signal as scipy_signal\nfrom scipy.interpolate import interp1d\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- R-Peak Detection & R-R Interval Extraction ---------------------------------\n\ndef detect_r_peaks_hamilton(ecg_signal, fs=100):\n    \"\"\"\n    Hamilton R-peak detection algorithm\n    Returns indices of R-peaks\n    \"\"\"\n    # Bandpass filter (5-15 Hz)\n    b, a = scipy_signal.butter(2, [5, 15], btype='band', fs=fs)\n    filtered = scipy_signal.filtfilt(b, a, ecg_signal)\n    \n    # Derivative\n    diff_signal = np.diff(filtered)\n    \n    # Squaring\n    squared = diff_signal ** 2\n    \n    # Moving average integration (150ms window)\n    window_size = int(0.15 * fs)\n    integrated = np.convolve(squared, np.ones(window_size)/window_size, mode='same')\n    \n    # Find peaks\n    threshold = np.mean(integrated) + 0.5 * np.std(integrated)\n    peaks = []\n    refractory = int(0.2 * fs)  # 200ms refractory period\n    \n    for i in range(1, len(integrated) - 1):\n        if integrated[i] > threshold:\n            if integrated[i] > integrated[i-1] and integrated[i] > integrated[i+1]:\n                if not peaks or (i - peaks[-1]) > refractory:\n                    peaks.append(i)\n    \n    return np.array(peaks)\n\ndef median_filter_rr(rr_intervals, window=5):\n    \"\"\"\n    Median filter for removing physiologically uninterpretable R-R intervals\n    Based on Chen et al. methodology\n    \"\"\"\n    if len(rr_intervals) < window:\n        return rr_intervals\n    \n    filtered = rr_intervals.copy()\n    median_rr = np.median(rr_intervals)\n    \n    for i in range(len(rr_intervals)):\n        # Check if RR interval is physiologically valid (300ms - 2000ms)\n        if rr_intervals[i] < 0.3 or rr_intervals[i] > 2.0:\n            filtered[i] = median_rr\n            continue\n        \n        # Median filter\n        start = max(0, i - window//2)\n        end = min(len(rr_intervals), i + window//2 + 1)\n        window_vals = rr_intervals[start:end]\n        local_median = np.median(window_vals)\n        \n        # Replace outliers (> 20% deviation from local median)\n        if abs(rr_intervals[i] - local_median) > 0.2 * local_median:\n            filtered[i] = local_median\n    \n    return filtered\n\ndef extract_rr_features(ecg_segment, fs=100):\n    \"\"\"\n    NaN-safe R-peak detection + 3 Hz interpolation.\n    Returns:\n        rr_interp  : length 180  (seconds * 3 Hz)\n        ramp_interp: length 180\n    \"\"\"\n    # ---- 1. R-peak detection -------------------------------------------------\n    r_peaks = detect_r_peaks_hamilton(ecg_segment, fs)\n    if len(r_peaks) < 3:                       # not enough peaks → dummy\n        return np.zeros(180, dtype=np.float32), np.zeros(180, dtype=np.float32)\n\n    # ---- 2. RR intervals -----------------------------------------------------\n    rr_sec = np.diff(r_peaks) / fs\n    rr_sec = median_filter_rr(rr_sec)          # outlier removal\n    rr_times = r_peaks[1:] / fs                # time stamp of each RR\n\n    # ---- 3. R-peak amplitudes ------------------------------------------------\n    ramp = ecg_segment[r_peaks[1:]]\n\n    # ---- 4. Cubic interpolation to 3 Hz -------------------------------------\n    targ_t = np.linspace(0, 60, 180)\n    kind = 'cubic' if len(rr_sec) >= 4 else 'linear'\n\n    f_rr   = interp1d(rr_times, rr_sec,   kind=kind, bounds_error=False, fill_value=(rr_sec[0], rr_sec[-1]))\n    f_amp  = interp1d(rr_times, ramp,     kind=kind, bounds_error=False, fill_value=(ramp[0],   ramp[-1]))\n\n    rr_out   = np.clip(f_rr(targ_t), 0.3, 2.0).astype(np.float32)\n    ramp_out = f_amp(targ_t).astype(np.float32)\n\n    # ---- 5. Normalise with safety checks -------------------------------------\n    rr_std = rr_out.std()\n    ramp_std = ramp_out.std()\n    \n    if rr_std > 1e-6:\n        rr_out = (rr_out - rr_out.mean()) / rr_std\n    else:\n        rr_out = rr_out - rr_out.mean()\n    \n    if ramp_std > 1e-6:\n        ramp_out = (ramp_out - ramp_out.mean()) / ramp_std\n    else:\n        ramp_out = ramp_out - ramp_out.mean()\n    \n    # Clip to prevent extreme values\n    rr_out = np.clip(rr_out, -10, 10)\n    ramp_out = np.clip(ramp_out, -10, 10)\n    \n    return rr_out, ramp_out\n\n# ----------------------------- Improved Model ---------------------------------\n\nclass MultiScaleBlock(nn.Module):\n    \"\"\"Multi-scale feature extraction block\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        # ensure total output channels == out_channels\n        c1 = out_channels // 3\n        c2 = out_channels // 3\n        c3 = out_channels - c1 - c2  # remainder so c1 + c2 + c3 == out_channels\n\n        self.conv1 = nn.Conv1d(in_channels, c1, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(in_channels, c2, kernel_size=5, padding=2)\n        self.conv3 = nn.Conv1d(in_channels, c3, kernel_size=7, padding=3)\n        self.bn = nn.BatchNorm1d(out_channels)\n        \n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.conv2(x)\n        x3 = self.conv3(x)\n        out = torch.cat([x1, x2, x3], dim=1)\n        return F.gelu(self.bn(out))\n\n\nclass EnhancedResBlock(nn.Module):\n    \"\"\"Enhanced residual block with squeeze-excitation\"\"\"\n    def __init__(self, channels, kernel_size=7):\n        super().__init__()\n        self.conv1 = nn.Conv1d(channels, channels, kernel_size, padding=kernel_size//2, groups=channels)\n        self.conv2 = nn.Conv1d(channels, channels, 1)\n        self.norm = nn.BatchNorm1d(channels)\n        \n        # Squeeze-Excitation with stability improvements\n        se_channels = max(8, channels // 8)  # Ensure at least 8 channels\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Conv1d(channels, se_channels, 1),\n            nn.GELU(),\n            nn.Conv1d(se_channels, channels, 1),\n            nn.Sigmoid()\n        )\n        self.dropout = nn.Dropout(0.15)\n        \n    def forward(self, x):\n        residual = x\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.norm(x)\n        \n        # Apply SE attention with safety check\n        se_weight = self.se(x)\n        # Clamp to prevent extreme values\n        se_weight = torch.clamp(se_weight, 0.0, 1.0)\n        x = x * se_weight\n        \n        x = self.dropout(x)\n        return F.gelu(residual + x)\n\nclass ImprovedApneaNet(nn.Module):\n    def __init__(self, d_model=256, n_blocks=10, dropout=0.15):\n        super().__init__()\n        \n        # Ensure the three modality-channel outputs sum to d_model\n        c1 = d_model // 3\n        c2 = d_model // 3\n        c3 = d_model - c1 - c2\n\n        # ECG pathway (6000 samples) -> c1 channels\n        self.ecg_stem = nn.Sequential(\n            nn.Conv1d(1, c1, kernel_size=15, padding=7, stride=4),\n            nn.BatchNorm1d(c1),\n            nn.GELU(),\n            nn.Conv1d(c1, c1, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c1),\n            nn.GELU(),\n        )\n\n        # RR interval pathway (180 samples @ 3Hz) -> c2 channels\n        self.rr_stem = nn.Sequential(\n            nn.Conv1d(1, c2, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c2),\n            nn.GELU(),\n            nn.Conv1d(c2, c2, kernel_size=5, padding=2),\n            nn.BatchNorm1d(c2),\n            nn.GELU(),\n        )\n\n        # R-amplitude pathway (180 samples @ 3Hz) -> c3 channels\n        self.ramp_stem = nn.Sequential(\n            nn.Conv1d(1, c3, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c3),\n            nn.GELU(),\n            nn.Conv1d(c3, c3, kernel_size=5, padding=2),\n            nn.BatchNorm1d(c3),\n            nn.GELU(),\n        )\n        \n        # Multi-scale fusion\n        self.fusion = MultiScaleBlock(d_model, d_model)\n        \n        # Enhanced residual blocks\n        self.blocks = nn.ModuleList([\n            EnhancedResBlock(d_model, kernel_size=7 if i % 2 == 0 else 11)\n            for i in range(n_blocks)\n        ])\n        \n        # Temporal attention with larger context\n        self.temp_attn = nn.MultiheadAttention(d_model, num_heads=8, dropout=dropout, batch_first=True)\n        self.temp_norm = nn.LayerNorm(d_model)\n        self.temp_ffn = nn.Sequential(\n            nn.Linear(d_model, d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model)\n        )\n        \n        # Feature aggregation\n        self.global_pool = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Flatten()\n        )\n        \n        # Enhanced classifier with multiple paths\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 4, d_model * 2),\n            nn.BatchNorm1d(d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout * 0.5),\n            nn.Linear(d_model, 2)\n        )\n        \n        # Initialize weights\n        self._initialize_weights()\n        \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv1d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n        \n    def forward(self, ecg, rr, ramp):\n        # Validate inputs\n        if torch.isnan(ecg).any() or torch.isinf(ecg).any():\n            ecg = torch.nan_to_num(ecg, nan=0.0, posinf=10.0, neginf=-10.0)\n        if torch.isnan(rr).any() or torch.isinf(rr).any():\n            rr = torch.nan_to_num(rr, nan=0.0, posinf=10.0, neginf=-10.0)\n        if torch.isnan(ramp).any() or torch.isinf(ramp).any():\n            ramp = torch.nan_to_num(ramp, nan=0.0, posinf=10.0, neginf=-10.0)\n        \n        # Process each modality\n        ecg = ecg.transpose(1, 2)\n        rr = rr.transpose(1, 2)\n        ramp = ramp.transpose(1, 2)\n        \n        ecg_feat = self.ecg_stem(ecg)\n        rr_feat = self.rr_stem(rr)\n        ramp_feat = self.ramp_stem(ramp)\n        \n        # Align sequence lengths and concatenate\n        target_len = min(ecg_feat.size(2), rr_feat.size(2), ramp_feat.size(2))\n        ecg_feat = F.adaptive_avg_pool1d(ecg_feat, target_len)\n        rr_feat = F.adaptive_avg_pool1d(rr_feat, target_len)\n        ramp_feat = F.adaptive_avg_pool1d(ramp_feat, target_len)\n        \n        x = torch.cat([ecg_feat, rr_feat, ramp_feat], dim=1)\n        \n        # Multi-scale fusion\n        x = self.fusion(x)\n        \n        # Residual blocks\n        for block in self.blocks:\n            x = block(x)\n        \n        # Multiple pooling strategies with safety\n        x_avg = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n        x_max = F.adaptive_max_pool1d(x, 1).squeeze(-1)\n        x_std = torch.std(x, dim=2) + 1e-8  # Add epsilon for stability\n        \n        # Temporal attention\n        x_seq = x.transpose(1, 2)\n        x_attn, _ = self.temp_attn(x_seq, x_seq, x_seq)\n        x_attn = self.temp_norm(x_attn + x_seq)\n        x_attn = x_attn + self.temp_ffn(x_attn)\n        x_attn = x_attn.mean(dim=1)\n        \n        # Combine all features\n        x_combined = torch.cat([x_avg, x_max, x_std, x_attn], dim=1)\n        \n        # Final NaN check before classifier\n        if torch.isnan(x_combined).any() or torch.isinf(x_combined).any():\n            x_combined = torch.nan_to_num(x_combined, nan=0.0, posinf=10.0, neginf=-10.0)\n        \n        # Classify\n        logits = self.classifier(x_combined)\n        return logits\n\n# --------------------------- Enhanced Dataset ---------------------------\n\nclass EnhancedApneaDataset(Dataset):\n    \"\"\"Dataset with R-R interval and R-amplitude extraction\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 6000, stride: int = 3000, split='train', augment=True):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        self.augment = augment and (split == 'train')\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_enhanced_{split}_{segment_length}_{stride}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} from {cache_file}\")\n            data = torch.load(cache_file)\n            self.ecg_segments = data['ecg_segments']\n            self.rr_segments = data['rr_segments']\n            self.ramp_segments = data['ramp_segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb required\"\n            assert record_names is not None, \"record_names required\"\n            \n            self.ecg_segments = []\n            self.rr_segments = []\n            self.ramp_segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split} (with R-R extraction)...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.ecg_segments) == 0:\n                raise RuntimeError(\"No segments loaded\")\n            \n            self.ecg_segments = torch.tensor(np.stack(self.ecg_segments, axis=0), dtype=torch.float32)\n            self.rr_segments = torch.tensor(np.stack(self.rr_segments, axis=0), dtype=torch.float32)\n            self.ramp_segments = torch.tensor(np.stack(self.ramp_segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving cache to {cache_file}\")\n            torch.save({\n                'ecg_segments': self.ecg_segments,\n                'rr_segments': self.rr_segments,\n                'ramp_segments': self.ramp_segments,\n                'labels': self.labels\n            }, cache_file)\n\n        if self.ecg_segments.ndim == 2:\n            self.ecg_segments = self.ecg_segments.unsqueeze(-1)\n        if self.rr_segments.ndim == 2:\n            self.rr_segments = self.rr_segments.unsqueeze(-1)\n        if self.ramp_segments.ndim == 2:\n            self.ramp_segments = self.ramp_segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()}: {len(self.ecg_segments)} segments, \"\n              f\"Class: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            rec = wfdb.rdrecord(str(self.data_dir / record_name))\n            sig = rec.p_signal[:, 0].astype(np.float32)\n            if np.isnan(sig).any():\n                nans = np.isnan(sig)\n                sig[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(~nans), sig[~nans])\n\n            ann = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            n_min = len(sig) // 6000\n            mins = np.zeros(n_min, dtype=int)\n            for samp, sym in zip(ann.sample, ann.symbol):\n                if sym == 'A':\n                    m = samp // 6000\n                    if m < n_min:\n                        mins[m] = 1\n\n            for start in range(0, len(sig) - self.segment_length + 1, self.stride):\n                seg = sig[start:start + self.segment_length]\n                \n                # Normalise ECG with safety\n                seg_std = seg.std()\n                if seg_std > 1e-6:\n                    seg = (seg - seg.mean()) / seg_std\n                else:\n                    seg = seg - seg.mean()\n                seg = np.clip(seg, -10, 10)\n\n                rr, ramp = extract_rr_features(seg, fs=100)\n\n                minute = start // 6000\n                if minute < len(mins):\n                    self.ecg_segments.append(seg)\n                    self.rr_segments.append(rr)\n                    self.ramp_segments.append(ramp)\n                    self.labels.append(int(mins[minute]))\n        except Exception as e:\n            print(f'\\nSkip {record_name}: {e}')\n    \n    def _augment(self, ecg, rr, ramp):\n        ecg, rr, ramp = map(lambda x: x.numpy() if torch.is_tensor(x) else x, (ecg, rr, ramp))\n\n        if np.random.rand() < 0.5:\n            ecg += np.random.normal(0, 0.02, ecg.shape).astype(np.float32)\n            rr += np.random.normal(0, 0.01, rr.shape).astype(np.float32)\n            ramp += np.random.normal(0, 0.01, ramp.shape).astype(np.float32)\n\n        if np.random.rand() < 0.3:\n            scale = np.random.uniform(0.9, 1.1)\n            ecg *= scale\n            ramp *= scale\n\n        if np.random.rand() < 0.2:\n            shift = np.random.randint(-150, 150)\n            ecg = np.roll(ecg, shift)\n\n        # Clip after augmentation\n        ecg = np.clip(ecg, -10, 10)\n        rr = np.clip(rr, -10, 10)\n        ramp = np.clip(ramp, -10, 10)\n\n        return tuple(map(torch.from_numpy, (ecg, rr, ramp)))\n            \n    def __len__(self):\n        return self.ecg_segments.shape[0]\n\n    def __getitem__(self, idx):\n        ecg = self.ecg_segments[idx]\n        rr = self.rr_segments[idx]\n        ramp = self.ramp_segments[idx]\n        label = self.labels[idx]\n        \n        if self.augment:\n            ecg, rr, ramp = self._augment(ecg, rr, ramp)\n        \n        # Ensure correct shape\n        if ecg.ndim == 1:\n            ecg = ecg.unsqueeze(-1)\n        if rr.ndim == 1:\n            rr = rr.unsqueeze(-1)\n        if ramp.ndim == 1:\n            ramp = ramp.unsqueeze(-1)\n        \n        return ecg, rr, ramp, label\n\n# -------------------------- Training ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model, dataloader, criterion, optimizer, scheduler, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 15)\n    start_time = time.time()\n\n    for batch_idx, (ecg, rr, ramp, target) in enumerate(dataloader, 1):\n        ecg = ecg.to(device, non_blocking=True)\n        rr = rr.to(device, non_blocking=True)\n        ramp = ramp.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(ecg, rr, ramp)\n            loss = criterion(output, target)\n        \n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"\\nWARNING: NaN/Inf loss, skipping batch {batch_idx}\")\n            continue\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n        \n        scheduler.step()\n\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            speed = batch_idx / (time.time() - start_time)\n            eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n            \n            print(f\"  Ep {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"({speed:.1f} b/s, ETA: {eta:.0f}s)\", end='\\r')\n\n    print()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for ecg, rr, ramp, target in dataloader:\n            ecg = ecg.to(device, non_blocking=True)\n            rr = rr.to(device, non_blocking=True)\n            ramp = ramp.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            \n            output = model(ecg, rr, ramp)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().tolist())\n            all_targets.extend(target.cpu().tolist())\n            all_probs.extend(probs.cpu().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    precision = precision_score(all_targets, all_preds, zero_division=0)\n    recall = recall_score(all_targets, all_preds, zero_division=0)\n    f1 = f1_score(all_targets, all_preds, zero_division=0)\n    \n    # Calculate specificity and sensitivity\n    tn, fp, fn, tp = confusion_matrix(all_targets, all_preds).ravel()\n    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n    \n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs), precision, recall, f1, sensitivity, specificity\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(\"No valid records found\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train: {len(train_records)}, Val: {len(val_records)}\\n\")\n\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), train_records, cache_dir,\n        args.segment_length, args.stride, 'train', augment=True\n    )\n    val_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), val_records, cache_dir,\n        args.segment_length, args.stride, 'val', augment=False\n    )\n\n    num_workers = 2 if str(DATA_DIR).startswith('/kaggle') else 4\n\n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Device: {device}\")\n    if device.type == 'cuda':\n        try:\n            print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        except Exception:\n            pass\n        torch.cuda.empty_cache()\n\n    model = ImprovedApneaNet(\n        d_model=args.d_model, n_blocks=args.n_blocks, dropout=args.dropout\n    ).to(device)\n\n    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n\n    # Use Focal Loss for better class imbalance handling\n        # stable, NaN-free loss with class weights\n    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n\n    optimizer = torch.optim.AdamW(\n        model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n    )\n\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, max_lr=args.lr, epochs=args.epochs,\n        steps_per_epoch=len(train_loader), pct_start=0.25\n    )\n\n    scaler = torch.amp.GradScaler() if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    best_val_f1 = 0.0\n    no_improve = 0\n\n    print(\"\\nStarting training...\")\n    print(\"=\"*100)\n\n    for epoch in range(1, args.epochs + 1):\n        epoch_start = time.time()\n\n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, scheduler, device, epoch, scaler\n        )\n\n        val_loss, val_acc, _, val_targets, val_probs, precision, recall, f1, sensitivity, specificity = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except Exception:\n            auc = 0.0\n\n        epoch_time = time.time() - epoch_start\n\n        print(f\"Epoch {epoch:2d}/{args.epochs} ({epoch_time:.1f}s)\")\n        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n        print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={auc:.4f}\")\n        print(f\"         Prec={precision:.3f}, Rec={recall:.3f}, F1={f1:.3f}\")\n        print(f\"         Sensitivity={sensitivity:.3f}, Specificity={specificity:.3f}\")\n\n        if val_acc > best_val_acc or (val_acc >= best_val_acc and f1 > best_val_f1):\n            best_val_acc = val_acc\n            best_val_f1 = f1\n            no_improve = 0\n            torch.save({\n                'epoch': epoch, 'model_state_dict': model.state_dict(),\n                'val_acc': val_acc, 'val_auc': auc, 'val_f1': f1,\n                'sensitivity': sensitivity, 'specificity': specificity\n            }, args.best_model_path)\n            print(f\"  ✓ Best! (Acc={val_acc:.2f}%, F1={f1:.3f}, Sens={sensitivity:.3f}, Spec={specificity:.3f})\")\n        else:\n            no_improve += 1\n            print(f\"  No improvement ({no_improve}/{args.patience})\")\n\n        print(\"-\"*100)\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stop at epoch {epoch}\")\n            break\n\n    print(f\"\\n{'='*100}\")\n    print(f\"BEST - Accuracy: {best_val_acc:.2f}%, F1: {best_val_f1:.3f}\")\n    print(f\"{'='*100}\")\n\n\nif __name__ == '__main__':\n    kaggle_data = '/kaggle/input/vincent2/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_model.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_model.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_model.pth'\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=6000)\n    parser.add_argument('--stride', type=int, default=2400)  # 60% overlap for more data\n    parser.add_argument('--batch-size', type=int, default=48)  # Adjusted for multi-modal\n    parser.add_argument('--epochs', type=int, default=100)\n    parser.add_argument('--lr', type=float, default=1e-3)\n    parser.add_argument('--weight-decay', type=float, default=1e-4)\n    parser.add_argument('--d-model', type=int, default=256)\n    parser.add_argument('--n-blocks', type=int, default=10)\n    parser.add_argument('--dropout', type=float, default=0.15)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--patience', type=int, default=20)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n\n    if args.data_dir is None:\n        raise SystemExit(\"ERROR: Dataset not found\")\n\n    print(\"=\"*100)\n    print(\"ENHANCED MODEL WITH R-R INTERVALS (Target: 90%+ Accuracy)\")\n    print(\"=\"*100)\n    print(f\"  Data:       {args.data_dir}\")\n    print(f\"  Segment:    {args.segment_length} samples (60s), stride={args.stride}\")\n    print(f\"  Features:   ECG + R-R Intervals + R-peak Amplitudes\")\n    print(f\"  Batch:      {args.batch_size}\")\n    print(f\"  Epochs:     {args.epochs}\")\n    print(f\"  Model:      d_model={args.d_model}, blocks={args.n_blocks}\")\n    print(f\"  Optimizer:  AdamW (lr={args.lr}, wd={args.weight_decay})\")\n    print(f\"  Loss:       Focal Loss (alpha=0.25, gamma=2.0)\")\n    print(\"=\"*100 + \"\\n\")\n\n    main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T10:07:12.848626Z","iopub.execute_input":"2025-11-28T10:07:12.849209Z","iopub.status.idle":"2025-11-28T10:27:23.590778Z","shell.execute_reply.started":"2025-11-28T10:07:12.849177Z","shell.execute_reply":"2025-11-28T10:27:23.589940Z"}},"outputs":[{"name":"stdout","text":"====================================================================================================\nENHANCED MODEL WITH R-R INTERVALS (Target: 90%+ Accuracy)\n====================================================================================================\n  Data:       /kaggle/input/vincent2/apnea-ecg-database-1.0.0\n  Segment:    6000 samples (60s), stride=2400\n  Features:   ECG + R-R Intervals + R-peak Amplitudes\n  Batch:      48\n  Epochs:     100\n  Model:      d_model=256, blocks=10\n  Optimizer:  AdamW (lr=0.001, wd=0.0001)\n  Loss:       Focal Loss (alpha=0.25, gamma=2.0)\n====================================================================================================\n\nFound 43 valid records\nTrain: 34, Val: 9\n\nLoading cached train from /kaggle/working/apnea_enhanced_train_6000_2400.pt\nTrain: 41751 segments, Class: Counter({0: 26395, 1: 15356})\nLoading cached val from /kaggle/working/apnea_enhanced_val_6000_2400.pt\nVal: 10777 segments, Class: Counter({0: 5862, 1: 4915})\nDevice: cuda\nGPU: Tesla P100-PCIE-16GB\nParameters: 2,496,778\n\nClass weights: tensor([0.7909, 1.3594], device='cuda:0')\n\nStarting training...\n====================================================================================================\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Ep 1 [ 870/870] Loss: 0.5580 Acc: 74.69% (21.3 b/s, ETA: 0s))\nEpoch  1/100 (43.8s)\n  Train: Loss=0.5580, Acc=74.69%\n  Val:   Loss=0.5033, Acc=78.05%, AUC=0.8956\n         Prec=0.694, Rec=0.928, F1=0.794\n         Sensitivity=0.928, Specificity=0.657\n  ✓ Best! (Acc=78.05%, F1=0.794, Sens=0.928, Spec=0.657)\n----------------------------------------------------------------------------------------------------\n  Ep 2 [ 870/870] Loss: 0.3917 Acc: 85.49% (22.1 b/s, ETA: 0s))\nEpoch  2/100 (42.3s)\n  Train: Loss=0.3917, Acc=85.49%\n  Val:   Loss=0.5056, Acc=80.02%, AUC=0.8718\n         Prec=0.753, Rec=0.837, F1=0.793\n         Sensitivity=0.837, Specificity=0.769\n  ✓ Best! (Acc=80.02%, F1=0.793, Sens=0.837, Spec=0.769)\n----------------------------------------------------------------------------------------------------\n  Ep 3 [ 870/870] Loss: 0.3555 Acc: 87.77% (22.3 b/s, ETA: 0s))\nEpoch  3/100 (42.2s)\n  Train: Loss=0.3555, Acc=87.77%\n  Val:   Loss=0.4170, Acc=83.59%, AUC=0.9167\n         Prec=0.799, Rec=0.856, F1=0.826\n         Sensitivity=0.856, Specificity=0.819\n  ✓ Best! (Acc=83.59%, F1=0.826, Sens=0.856, Spec=0.819)\n----------------------------------------------------------------------------------------------------\n  Ep 4 [ 870/870] Loss: 0.3350 Acc: 88.86% (21.7 b/s, ETA: 0s))\nEpoch  4/100 (43.0s)\n  Train: Loss=0.3350, Acc=88.86%\n  Val:   Loss=0.4219, Acc=83.39%, AUC=0.9116\n         Prec=0.786, Rec=0.874, F1=0.828\n         Sensitivity=0.874, Specificity=0.800\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 5 [ 870/870] Loss: 0.3209 Acc: 89.71% (21.8 b/s, ETA: 0s))\nEpoch  5/100 (43.0s)\n  Train: Loss=0.3209, Acc=89.71%\n  Val:   Loss=0.3879, Acc=85.09%, AUC=0.9325\n         Prec=0.797, Rec=0.903, F1=0.847\n         Sensitivity=0.903, Specificity=0.807\n  ✓ Best! (Acc=85.09%, F1=0.847, Sens=0.903, Spec=0.807)\n----------------------------------------------------------------------------------------------------\n  Ep 6 [ 870/870] Loss: 0.3114 Acc: 90.49% (22.1 b/s, ETA: 0s))\nEpoch  6/100 (42.3s)\n  Train: Loss=0.3114, Acc=90.49%\n  Val:   Loss=0.4184, Acc=83.96%, AUC=0.9205\n         Prec=0.812, Rec=0.843, F1=0.827\n         Sensitivity=0.843, Specificity=0.837\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 7 [ 870/870] Loss: 0.3038 Acc: 90.73% (22.0 b/s, ETA: 0s))\nEpoch  7/100 (42.6s)\n  Train: Loss=0.3038, Acc=90.73%\n  Val:   Loss=0.4607, Acc=81.22%, AUC=0.9011\n         Prec=0.781, Rec=0.818, F1=0.799\n         Sensitivity=0.818, Specificity=0.807\n  No improvement (2/20)\n----------------------------------------------------------------------------------------------------\n  Ep 8 [ 870/870] Loss: 0.2965 Acc: 91.21% (21.9 b/s, ETA: 0s))\nEpoch  8/100 (42.6s)\n  Train: Loss=0.2965, Acc=91.21%\n  Val:   Loss=0.3604, Acc=86.94%, AUC=0.9440\n         Prec=0.826, Rec=0.904, F1=0.863\n         Sensitivity=0.904, Specificity=0.841\n  ✓ Best! (Acc=86.94%, F1=0.863, Sens=0.904, Spec=0.841)\n----------------------------------------------------------------------------------------------------\n  Ep 9 [ 870/870] Loss: 0.2872 Acc: 91.61% (21.8 b/s, ETA: 0s))\nEpoch  9/100 (42.7s)\n  Train: Loss=0.2872, Acc=91.61%\n  Val:   Loss=0.3871, Acc=86.75%, AUC=0.9326\n         Prec=0.845, Rec=0.869, F1=0.857\n         Sensitivity=0.869, Specificity=0.866\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 10 [ 870/870] Loss: 0.2852 Acc: 91.87% (22.1 b/s, ETA: 0s))\nEpoch 10/100 (42.3s)\n  Train: Loss=0.2852, Acc=91.87%\n  Val:   Loss=0.4440, Acc=83.19%, AUC=0.9135\n         Prec=0.831, Rec=0.793, F1=0.811\n         Sensitivity=0.793, Specificity=0.864\n  No improvement (2/20)\n----------------------------------------------------------------------------------------------------\n  Ep 11 [ 870/870] Loss: 0.2773 Acc: 92.25% (21.4 b/s, ETA: 0s))\nEpoch 11/100 (43.6s)\n  Train: Loss=0.2773, Acc=92.25%\n  Val:   Loss=0.5034, Acc=81.28%, AUC=0.8787\n         Prec=0.845, Rec=0.722, F1=0.779\n         Sensitivity=0.722, Specificity=0.889\n  No improvement (3/20)\n----------------------------------------------------------------------------------------------------\n  Ep 12 [ 870/870] Loss: 0.2724 Acc: 92.63% (21.2 b/s, ETA: 0s))\nEpoch 12/100 (43.9s)\n  Train: Loss=0.2724, Acc=92.63%\n  Val:   Loss=0.4040, Acc=85.39%, AUC=0.9310\n         Prec=0.869, Rec=0.801, F1=0.833\n         Sensitivity=0.801, Specificity=0.898\n  No improvement (4/20)\n----------------------------------------------------------------------------------------------------\n  Ep 13 [ 870/870] Loss: 0.2695 Acc: 92.76% (21.9 b/s, ETA: 0s))\nEpoch 13/100 (42.7s)\n  Train: Loss=0.2695, Acc=92.76%\n  Val:   Loss=0.4608, Acc=82.69%, AUC=0.9186\n         Prec=0.859, Rec=0.742, F1=0.796\n         Sensitivity=0.742, Specificity=0.898\n  No improvement (5/20)\n----------------------------------------------------------------------------------------------------\n  Ep 14 [ 870/870] Loss: 0.2622 Acc: 93.17% (21.7 b/s, ETA: 0s))\nEpoch 14/100 (43.1s)\n  Train: Loss=0.2622, Acc=93.17%\n  Val:   Loss=0.4505, Acc=82.87%, AUC=0.9284\n         Prec=0.885, Rec=0.717, F1=0.793\n         Sensitivity=0.717, Specificity=0.922\n  No improvement (6/20)\n----------------------------------------------------------------------------------------------------\n  Ep 15 [ 870/870] Loss: 0.2550 Acc: 93.48% (21.9 b/s, ETA: 0s))\nEpoch 15/100 (42.7s)\n  Train: Loss=0.2550, Acc=93.48%\n  Val:   Loss=0.4135, Acc=85.26%, AUC=0.9266\n         Prec=0.869, Rec=0.797, F1=0.832\n         Sensitivity=0.797, Specificity=0.899\n  No improvement (7/20)\n----------------------------------------------------------------------------------------------------\n  Ep 16 [ 870/870] Loss: 0.2504 Acc: 93.67% (21.5 b/s, ETA: 0s))\nEpoch 16/100 (43.6s)\n  Train: Loss=0.2504, Acc=93.67%\n  Val:   Loss=0.4228, Acc=84.67%, AUC=0.9260\n         Prec=0.864, Rec=0.788, F1=0.824\n         Sensitivity=0.788, Specificity=0.896\n  No improvement (8/20)\n----------------------------------------------------------------------------------------------------\n  Ep 17 [ 870/870] Loss: 0.2409 Acc: 94.44% (21.9 b/s, ETA: 0s))\nEpoch 17/100 (42.8s)\n  Train: Loss=0.2409, Acc=94.44%\n  Val:   Loss=0.4362, Acc=85.26%, AUC=0.9205\n         Prec=0.854, Rec=0.816, F1=0.835\n         Sensitivity=0.816, Specificity=0.883\n  No improvement (9/20)\n----------------------------------------------------------------------------------------------------\n  Ep 18 [ 870/870] Loss: 0.2350 Acc: 94.56% (22.0 b/s, ETA: 0s))\nEpoch 18/100 (42.5s)\n  Train: Loss=0.2350, Acc=94.56%\n  Val:   Loss=0.4245, Acc=85.09%, AUC=0.9210\n         Prec=0.872, Rec=0.789, F1=0.828\n         Sensitivity=0.789, Specificity=0.903\n  No improvement (10/20)\n----------------------------------------------------------------------------------------------------\n  Ep 19 [ 870/870] Loss: 0.2288 Acc: 94.96% (21.7 b/s, ETA: 0s))\nEpoch 19/100 (43.1s)\n  Train: Loss=0.2288, Acc=94.96%\n  Val:   Loss=0.3894, Acc=86.69%, AUC=0.9395\n         Prec=0.886, Rec=0.813, F1=0.848\n         Sensitivity=0.813, Specificity=0.912\n  No improvement (11/20)\n----------------------------------------------------------------------------------------------------\n  Ep 20 [ 870/870] Loss: 0.2200 Acc: 95.42% (21.8 b/s, ETA: 0s))\nEpoch 20/100 (42.8s)\n  Train: Loss=0.2200, Acc=95.42%\n  Val:   Loss=0.4140, Acc=85.86%, AUC=0.9322\n         Prec=0.868, Rec=0.813, F1=0.840\n         Sensitivity=0.813, Specificity=0.897\n  No improvement (12/20)\n----------------------------------------------------------------------------------------------------\n  Ep 21 [ 870/870] Loss: 0.2123 Acc: 95.89% (21.8 b/s, ETA: 0s))\nEpoch 21/100 (42.9s)\n  Train: Loss=0.2123, Acc=95.89%\n  Val:   Loss=0.5461, Acc=80.67%, AUC=0.8939\n         Prec=0.831, Rec=0.723, F1=0.773\n         Sensitivity=0.723, Specificity=0.877\n  No improvement (13/20)\n----------------------------------------------------------------------------------------------------\n  Ep 22 [ 870/870] Loss: 0.2085 Acc: 96.12% (20.9 b/s, ETA: 0s))\nEpoch 22/100 (44.9s)\n  Train: Loss=0.2085, Acc=96.12%\n  Val:   Loss=0.4058, Acc=86.38%, AUC=0.9334\n         Prec=0.874, Rec=0.820, F1=0.846\n         Sensitivity=0.820, Specificity=0.901\n  No improvement (14/20)\n----------------------------------------------------------------------------------------------------\n  Ep 23 [ 870/870] Loss: 0.2000 Acc: 96.50% (21.2 b/s, ETA: 0s))\nEpoch 23/100 (44.1s)\n  Train: Loss=0.2000, Acc=96.50%\n  Val:   Loss=0.4646, Acc=84.43%, AUC=0.9176\n         Prec=0.850, Rec=0.800, F1=0.824\n         Sensitivity=0.800, Specificity=0.882\n  No improvement (15/20)\n----------------------------------------------------------------------------------------------------\n  Ep 24 [ 870/870] Loss: 0.1956 Acc: 96.72% (21.5 b/s, ETA: 0s))\nEpoch 24/100 (43.5s)\n  Train: Loss=0.1956, Acc=96.72%\n  Val:   Loss=0.4541, Acc=84.94%, AUC=0.9253\n         Prec=0.840, Rec=0.828, F1=0.834\n         Sensitivity=0.828, Specificity=0.867\n  No improvement (16/20)\n----------------------------------------------------------------------------------------------------\n  Ep 25 [ 870/870] Loss: 0.1907 Acc: 97.03% (21.1 b/s, ETA: 0s))\nEpoch 25/100 (44.1s)\n  Train: Loss=0.1907, Acc=97.03%\n  Val:   Loss=0.5060, Acc=82.55%, AUC=0.9007\n         Prec=0.864, Rec=0.733, F1=0.793\n         Sensitivity=0.733, Specificity=0.903\n  No improvement (17/20)\n----------------------------------------------------------------------------------------------------\n  Ep 26 [ 870/870] Loss: 0.1817 Acc: 97.41% (21.1 b/s, ETA: 0s))\nEpoch 26/100 (44.2s)\n  Train: Loss=0.1817, Acc=97.41%\n  Val:   Loss=0.4707, Acc=84.47%, AUC=0.9142\n         Prec=0.883, Rec=0.760, F1=0.817\n         Sensitivity=0.760, Specificity=0.916\n  No improvement (18/20)\n----------------------------------------------------------------------------------------------------\n  Ep 27 [ 870/870] Loss: 0.1785 Acc: 97.61% (21.2 b/s, ETA: 0s))\nEpoch 27/100 (43.9s)\n  Train: Loss=0.1785, Acc=97.61%\n  Val:   Loss=0.5314, Acc=81.44%, AUC=0.8959\n         Prec=0.866, Rec=0.702, F1=0.775\n         Sensitivity=0.702, Specificity=0.909\n  No improvement (19/20)\n----------------------------------------------------------------------------------------------------\n  Ep 28 [ 870/870] Loss: 0.1744 Acc: 97.89% (21.0 b/s, ETA: 0s))\nEpoch 28/100 (44.5s)\n  Train: Loss=0.1744, Acc=97.89%\n  Val:   Loss=0.5002, Acc=83.90%, AUC=0.9175\n         Prec=0.868, Rec=0.763, F1=0.812\n         Sensitivity=0.763, Specificity=0.903\n  No improvement (20/20)\n----------------------------------------------------------------------------------------------------\n\nEarly stop at epoch 28\n\n====================================================================================================\nBEST - Accuracy: 86.94%, F1: 0.863\n====================================================================================================\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nHigh-performance apnea detection with R-R interval extraction (Target: 90%+ accuracy)\nBased on PhysioNet Apnea-ECG Database methodology\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy import signal as scipy_signal\nfrom scipy.interpolate import interp1d\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- R-Peak Detection & R-R Interval Extraction ---------------------------------\n\ndef detect_r_peaks_hamilton(ecg_signal, fs=100):\n    \"\"\"\n    Hamilton R-peak detection algorithm\n    Returns indices of R-peaks\n    \"\"\"\n    # Bandpass filter (5-15 Hz)\n    b, a = scipy_signal.butter(2, [5, 15], btype='band', fs=fs)\n    filtered = scipy_signal.filtfilt(b, a, ecg_signal)\n    \n    # Derivative\n    diff_signal = np.diff(filtered)\n    \n    # Squaring\n    squared = diff_signal ** 2\n    \n    # Moving average integration (150ms window)\n    window_size = int(0.15 * fs)\n    integrated = np.convolve(squared, np.ones(window_size)/window_size, mode='same')\n    \n    # Find peaks\n    threshold = np.mean(integrated) + 0.5 * np.std(integrated)\n    peaks = []\n    refractory = int(0.2 * fs)  # 200ms refractory period\n    \n    for i in range(1, len(integrated) - 1):\n        if integrated[i] > threshold:\n            if integrated[i] > integrated[i-1] and integrated[i] > integrated[i+1]:\n                if not peaks or (i - peaks[-1]) > refractory:\n                    peaks.append(i)\n    \n    return np.array(peaks)\n\ndef median_filter_rr(rr_intervals, window=5):\n    \"\"\"\n    Median filter for removing physiologically uninterpretable R-R intervals\n    Based on Chen et al. methodology\n    \"\"\"\n    if len(rr_intervals) < window:\n        return rr_intervals\n    \n    filtered = rr_intervals.copy()\n    median_rr = np.median(rr_intervals)\n    \n    for i in range(len(rr_intervals)):\n        # Check if RR interval is physiologically valid (300ms - 2000ms)\n        if rr_intervals[i] < 0.3 or rr_intervals[i] > 2.0:\n            filtered[i] = median_rr\n            continue\n        \n        # Median filter\n        start = max(0, i - window//2)\n        end = min(len(rr_intervals), i + window//2 + 1)\n        window_vals = rr_intervals[start:end]\n        local_median = np.median(window_vals)\n        \n        # Replace outliers (> 20% deviation from local median)\n        if abs(rr_intervals[i] - local_median) > 0.2 * local_median:\n            filtered[i] = local_median\n    \n    return filtered\n\ndef extract_rr_features(ecg_segment, fs=100):\n    \"\"\"\n    NaN-safe R-peak detection + 3 Hz interpolation.\n    Returns:\n        rr_interp  : length 180  (seconds * 3 Hz)\n        ramp_interp: length 180\n    \"\"\"\n    # ---- 1. R-peak detection -------------------------------------------------\n    r_peaks = detect_r_peaks_hamilton(ecg_segment, fs)\n    if len(r_peaks) < 3:                       # not enough peaks → dummy\n        return np.zeros(180, dtype=np.float32), np.zeros(180, dtype=np.float32)\n\n    # ---- 2. RR intervals -----------------------------------------------------\n    rr_sec = np.diff(r_peaks) / fs\n    rr_sec = median_filter_rr(rr_sec)          # outlier removal\n    rr_times = r_peaks[1:] / fs                # time stamp of each RR\n\n    # ---- 3. R-peak amplitudes ------------------------------------------------\n    ramp = ecg_segment[r_peaks[1:]]\n\n    # ---- 4. Cubic interpolation to 3 Hz -------------------------------------\n    targ_t = np.linspace(0, 60, 180)\n    kind = 'cubic' if len(rr_sec) >= 4 else 'linear'\n\n    f_rr   = interp1d(rr_times, rr_sec,   kind=kind, bounds_error=False, fill_value=(rr_sec[0], rr_sec[-1]))\n    f_amp  = interp1d(rr_times, ramp,     kind=kind, bounds_error=False, fill_value=(ramp[0],   ramp[-1]))\n\n    rr_out   = np.clip(f_rr(targ_t), 0.3, 2.0).astype(np.float32)\n    ramp_out = f_amp(targ_t).astype(np.float32)\n\n    # ---- 5. Normalise with safety checks -------------------------------------\n    rr_std = rr_out.std()\n    ramp_std = ramp_out.std()\n    \n    if rr_std > 1e-6:\n        rr_out = (rr_out - rr_out.mean()) / rr_std\n    else:\n        rr_out = rr_out - rr_out.mean()\n    \n    if ramp_std > 1e-6:\n        ramp_out = (ramp_out - ramp_out.mean()) / ramp_std\n    else:\n        ramp_out = ramp_out - ramp_out.mean()\n    \n    # Clip to prevent extreme values\n    rr_out = np.clip(rr_out, -10, 10)\n    ramp_out = np.clip(ramp_out, -10, 10)\n    \n    return rr_out, ramp_out\n\n# ----------------------------- Improved Model ---------------------------------\n\nclass MultiScaleBlock(nn.Module):\n    \"\"\"Multi-scale feature extraction block\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        # ensure total output channels == out_channels\n        c1 = out_channels // 3\n        c2 = out_channels // 3\n        c3 = out_channels - c1 - c2  # remainder so c1 + c2 + c3 == out_channels\n\n        self.conv1 = nn.Conv1d(in_channels, c1, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(in_channels, c2, kernel_size=5, padding=2)\n        self.conv3 = nn.Conv1d(in_channels, c3, kernel_size=7, padding=3)\n        self.bn = nn.BatchNorm1d(out_channels)\n        \n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.conv2(x)\n        x3 = self.conv3(x)\n        out = torch.cat([x1, x2, x3], dim=1)\n        return F.gelu(self.bn(out))\n\n\nclass EnhancedResBlock(nn.Module):\n    \"\"\"Enhanced residual block with squeeze-excitation\"\"\"\n    def __init__(self, channels, kernel_size=7):\n        super().__init__()\n        self.conv1 = nn.Conv1d(channels, channels, kernel_size, padding=kernel_size//2, groups=channels)\n        self.conv2 = nn.Conv1d(channels, channels, 1)\n        self.norm = nn.BatchNorm1d(channels)\n        \n        # Squeeze-Excitation with stability improvements\n        se_channels = max(8, channels // 8)  # Ensure at least 8 channels\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Conv1d(channels, se_channels, 1),\n            nn.GELU(),\n            nn.Conv1d(se_channels, channels, 1),\n            nn.Sigmoid()\n        )\n        self.dropout = nn.Dropout(0.15)\n        \n    def forward(self, x):\n        residual = x\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.norm(x)\n        \n        # Apply SE attention with safety check\n        se_weight = self.se(x)\n        # Clamp to prevent extreme values\n        se_weight = torch.clamp(se_weight, 0.0, 1.0)\n        x = x * se_weight\n        \n        x = self.dropout(x)\n        return F.gelu(residual + x)\n\nclass ImprovedApneaNet(nn.Module):\n    def __init__(self, d_model=256, n_blocks=10, dropout=0.15):\n        super().__init__()\n        \n        # Ensure the three modality-channel outputs sum to d_model\n        c1 = d_model // 3\n        c2 = d_model // 3\n        c3 = d_model - c1 - c2\n\n        # ECG pathway (6000 samples) -> c1 channels\n        self.ecg_stem = nn.Sequential(\n            nn.Conv1d(1, c1, kernel_size=15, padding=7, stride=4),\n            nn.BatchNorm1d(c1),\n            nn.GELU(),\n            nn.Conv1d(c1, c1, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c1),\n            nn.GELU(),\n        )\n\n        # RR interval pathway (180 samples @ 3Hz) -> c2 channels\n        self.rr_stem = nn.Sequential(\n            nn.Conv1d(1, c2, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c2),\n            nn.GELU(),\n            nn.Conv1d(c2, c2, kernel_size=5, padding=2),\n            nn.BatchNorm1d(c2),\n            nn.GELU(),\n        )\n\n        # R-amplitude pathway (180 samples @ 3Hz) -> c3 channels\n        self.ramp_stem = nn.Sequential(\n            nn.Conv1d(1, c3, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c3),\n            nn.GELU(),\n            nn.Conv1d(c3, c3, kernel_size=5, padding=2),\n            nn.BatchNorm1d(c3),\n            nn.GELU(),\n        )\n        \n        # Multi-scale fusion\n        self.fusion = MultiScaleBlock(d_model, d_model)\n        \n        # Enhanced residual blocks\n        self.blocks = nn.ModuleList([\n            EnhancedResBlock(d_model, kernel_size=7 if i % 2 == 0 else 11)\n            for i in range(n_blocks)\n        ])\n        \n        # Temporal attention with larger context\n        self.temp_attn = nn.MultiheadAttention(d_model, num_heads=8, dropout=dropout, batch_first=True)\n        self.temp_norm = nn.LayerNorm(d_model)\n        self.temp_ffn = nn.Sequential(\n            nn.Linear(d_model, d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model)\n        )\n        \n        # Feature aggregation\n        self.global_pool = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Flatten()\n        )\n        \n        # Enhanced classifier with multiple paths\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 4, d_model * 2),\n            nn.BatchNorm1d(d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout * 0.5),\n            nn.Linear(d_model, 2)\n        )\n        \n        # Initialize weights\n        self._initialize_weights()\n        \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv1d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n        \n    def forward(self, ecg, rr, ramp):\n        # Validate inputs\n        if torch.isnan(ecg).any() or torch.isinf(ecg).any():\n            ecg = torch.nan_to_num(ecg, nan=0.0, posinf=10.0, neginf=-10.0)\n        if torch.isnan(rr).any() or torch.isinf(rr).any():\n            rr = torch.nan_to_num(rr, nan=0.0, posinf=10.0, neginf=-10.0)\n        if torch.isnan(ramp).any() or torch.isinf(ramp).any():\n            ramp = torch.nan_to_num(ramp, nan=0.0, posinf=10.0, neginf=-10.0)\n        \n        # Process each modality\n        ecg = ecg.transpose(1, 2)\n        rr = rr.transpose(1, 2)\n        ramp = ramp.transpose(1, 2)\n        \n        ecg_feat = self.ecg_stem(ecg)\n        rr_feat = self.rr_stem(rr)\n        ramp_feat = self.ramp_stem(ramp)\n        \n        # Align sequence lengths and concatenate\n        target_len = min(ecg_feat.size(2), rr_feat.size(2), ramp_feat.size(2))\n        ecg_feat = F.adaptive_avg_pool1d(ecg_feat, target_len)\n        rr_feat = F.adaptive_avg_pool1d(rr_feat, target_len)\n        ramp_feat = F.adaptive_avg_pool1d(ramp_feat, target_len)\n        \n        x = torch.cat([ecg_feat, rr_feat, ramp_feat], dim=1)\n        \n        # Multi-scale fusion\n        x = self.fusion(x)\n        \n        # Residual blocks\n        for block in self.blocks:\n            x = block(x)\n        \n        # Multiple pooling strategies with safety\n        x_avg = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n        x_max = F.adaptive_max_pool1d(x, 1).squeeze(-1)\n        x_std = torch.std(x, dim=2) + 1e-8  # Add epsilon for stability\n        \n        # Temporal attention\n        x_seq = x.transpose(1, 2)\n        x_attn, _ = self.temp_attn(x_seq, x_seq, x_seq)\n        x_attn = self.temp_norm(x_attn + x_seq)\n        x_attn = x_attn + self.temp_ffn(x_attn)\n        x_attn = x_attn.mean(dim=1)\n        \n        # Combine all features\n        x_combined = torch.cat([x_avg, x_max, x_std, x_attn], dim=1)\n        \n        # Final NaN check before classifier\n        if torch.isnan(x_combined).any() or torch.isinf(x_combined).any():\n            x_combined = torch.nan_to_num(x_combined, nan=0.0, posinf=10.0, neginf=-10.0)\n        \n        # Classify\n        logits = self.classifier(x_combined)\n        return logits\n\n# --------------------------- Enhanced Dataset ---------------------------\n\nclass EnhancedApneaDataset(Dataset):\n    \"\"\"Dataset with R-R interval and R-amplitude extraction\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 6000, stride: int = 3000, split='train', augment=True):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        self.augment = augment and (split == 'train')\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_enhanced_{split}_{segment_length}_{stride}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} from {cache_file}\")\n            data = torch.load(cache_file)\n            self.ecg_segments = data['ecg_segments']\n            self.rr_segments = data['rr_segments']\n            self.ramp_segments = data['ramp_segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb required\"\n            assert record_names is not None, \"record_names required\"\n            \n            self.ecg_segments = []\n            self.rr_segments = []\n            self.ramp_segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split} (with R-R extraction)...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.ecg_segments) == 0:\n                raise RuntimeError(\"No segments loaded\")\n            \n            self.ecg_segments = torch.tensor(np.stack(self.ecg_segments, axis=0), dtype=torch.float32)\n            self.rr_segments = torch.tensor(np.stack(self.rr_segments, axis=0), dtype=torch.float32)\n            self.ramp_segments = torch.tensor(np.stack(self.ramp_segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving cache to {cache_file}\")\n            torch.save({\n                'ecg_segments': self.ecg_segments,\n                'rr_segments': self.rr_segments,\n                'ramp_segments': self.ramp_segments,\n                'labels': self.labels\n            }, cache_file)\n\n        if self.ecg_segments.ndim == 2:\n            self.ecg_segments = self.ecg_segments.unsqueeze(-1)\n        if self.rr_segments.ndim == 2:\n            self.rr_segments = self.rr_segments.unsqueeze(-1)\n        if self.ramp_segments.ndim == 2:\n            self.ramp_segments = self.ramp_segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()}: {len(self.ecg_segments)} segments, \"\n              f\"Class: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            rec = wfdb.rdrecord(str(self.data_dir / record_name))\n            sig = rec.p_signal[:, 0].astype(np.float32)\n            if np.isnan(sig).any():\n                nans = np.isnan(sig)\n                sig[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(~nans), sig[~nans])\n\n            ann = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            n_min = len(sig) // 6000\n            mins = np.zeros(n_min, dtype=int)\n            for samp, sym in zip(ann.sample, ann.symbol):\n                if sym == 'A':\n                    m = samp // 6000\n                    if m < n_min:\n                        mins[m] = 1\n\n            for start in range(0, len(sig) - self.segment_length + 1, self.stride):\n                seg = sig[start:start + self.segment_length]\n                \n                # Normalise ECG with safety\n                seg_std = seg.std()\n                if seg_std > 1e-6:\n                    seg = (seg - seg.mean()) / seg_std\n                else:\n                    seg = seg - seg.mean()\n                seg = np.clip(seg, -10, 10)\n\n                rr, ramp = extract_rr_features(seg, fs=100)\n\n                minute = start // 6000\n                if minute < len(mins):\n                    self.ecg_segments.append(seg)\n                    self.rr_segments.append(rr)\n                    self.ramp_segments.append(ramp)\n                    self.labels.append(int(mins[minute]))\n        except Exception as e:\n            print(f'\\nSkip {record_name}: {e}')\n    \n    def _augment(self, ecg, rr, ramp):\n        ecg, rr, ramp = map(lambda x: x.numpy() if torch.is_tensor(x) else x, (ecg, rr, ramp))\n\n        if np.random.rand() < 0.5:\n            ecg += np.random.normal(0, 0.02, ecg.shape).astype(np.float32)\n            rr += np.random.normal(0, 0.01, rr.shape).astype(np.float32)\n            ramp += np.random.normal(0, 0.01, ramp.shape).astype(np.float32)\n\n        if np.random.rand() < 0.3:\n            scale = np.random.uniform(0.9, 1.1)\n            ecg *= scale\n            ramp *= scale\n\n        if np.random.rand() < 0.2:\n            shift = np.random.randint(-150, 150)\n            ecg = np.roll(ecg, shift)\n\n        # Clip after augmentation\n        ecg = np.clip(ecg, -10, 10)\n        rr = np.clip(rr, -10, 10)\n        ramp = np.clip(ramp, -10, 10)\n\n        return tuple(map(torch.from_numpy, (ecg, rr, ramp)))\n            \n    def __len__(self):\n        return self.ecg_segments.shape[0]\n\n    def __getitem__(self, idx):\n        ecg = self.ecg_segments[idx]\n        rr = self.rr_segments[idx]\n        ramp = self.ramp_segments[idx]\n        label = self.labels[idx]\n        \n        if self.augment:\n            ecg, rr, ramp = self._augment(ecg, rr, ramp)\n        \n        # Ensure correct shape\n        if ecg.ndim == 1:\n            ecg = ecg.unsqueeze(-1)\n        if rr.ndim == 1:\n            rr = rr.unsqueeze(-1)\n        if ramp.ndim == 1:\n            ramp = ramp.unsqueeze(-1)\n        \n        return ecg, rr, ramp, label\n\n# -------------------------- Training ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\ndef train_epoch(model, dataloader, criterion, optimizer, scheduler, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 15)\n    start_time = time.time()\n\n    for batch_idx, (ecg, rr, ramp, target) in enumerate(dataloader, 1):\n        ecg = ecg.to(device, non_blocking=True)\n        rr = rr.to(device, non_blocking=True)\n        ramp = ramp.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(ecg, rr, ramp)\n            loss = criterion(output, target)\n        \n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"\\nWARNING: NaN/Inf loss, skipping batch {batch_idx}\")\n            continue\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n        \n        scheduler.step()\n\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            speed = batch_idx / (time.time() - start_time)\n            eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n            \n            print(f\"  Ep {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"({speed:.1f} b/s, ETA: {eta:.0f}s)\", end='\\r')\n\n    print()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for ecg, rr, ramp, target in dataloader:\n            ecg = ecg.to(device, non_blocking=True)\n            rr = rr.to(device, non_blocking=True)\n            ramp = ramp.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            \n            output = model(ecg, rr, ramp)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().tolist())\n            all_targets.extend(target.cpu().tolist())\n            all_probs.extend(probs.cpu().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    precision = precision_score(all_targets, all_preds, zero_division=0)\n    recall = recall_score(all_targets, all_preds, zero_division=0)\n    f1 = f1_score(all_targets, all_preds, zero_division=0)\n    \n    # Calculate specificity and sensitivity\n    tn, fp, fn, tp = confusion_matrix(all_targets, all_preds).ravel()\n    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n    \n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs), precision, recall, f1, sensitivity, specificity\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(\"No valid records found\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train: {len(train_records)}, Val: {len(val_records)}\\n\")\n\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), train_records, cache_dir,\n        args.segment_length, args.stride, 'train', augment=True\n    )\n    val_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), val_records, cache_dir,\n        args.segment_length, args.stride, 'val', augment=False\n    )\n\n    num_workers = 2 if str(DATA_DIR).startswith('/kaggle') else 4\n\n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Device: {device}\")\n    if device.type == 'cuda':\n        try:\n            print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        except Exception:\n            pass\n        torch.cuda.empty_cache()\n\n    model = ImprovedApneaNet(\n        d_model=args.d_model, n_blocks=args.n_blocks, dropout=args.dropout\n    ).to(device)\n\n    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n\n    # Use Focal Loss for better class imbalance handling\n        # stable, NaN-free loss with class weights\n    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n\n    optimizer = torch.optim.AdamW(\n        model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n    )\n\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, max_lr=args.lr, epochs=args.epochs,\n        steps_per_epoch=len(train_loader), pct_start=0.2\n    )\n\n    scaler = torch.amp.GradScaler() if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    best_val_f1 = 0.0\n    no_improve = 0\n\n    print(\"\\nStarting training...\")\n    print(\"=\"*100)\n\n    for epoch in range(1, args.epochs + 1):\n        epoch_start = time.time()\n\n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, scheduler, device, epoch, scaler\n        )\n\n        val_loss, val_acc, _, val_targets, val_probs, precision, recall, f1, sensitivity, specificity = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except Exception:\n            auc = 0.0\n\n        epoch_time = time.time() - epoch_start\n\n        print(f\"Epoch {epoch:2d}/{args.epochs} ({epoch_time:.1f}s)\")\n        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n        print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={auc:.4f}\")\n        print(f\"         Prec={precision:.3f}, Rec={recall:.3f}, F1={f1:.3f}\")\n        print(f\"         Sensitivity={sensitivity:.3f}, Specificity={specificity:.3f}\")\n\n        if val_acc > best_val_acc or (val_acc >= best_val_acc and f1 > best_val_f1):\n            best_val_acc = val_acc\n            best_val_f1 = f1\n            no_improve = 0\n            torch.save({\n                'epoch': epoch, 'model_state_dict': model.state_dict(),\n                'val_acc': val_acc, 'val_auc': auc, 'val_f1': f1,\n                'sensitivity': sensitivity, 'specificity': specificity\n            }, args.best_model_path)\n            print(f\"  ✓ Best! (Acc={val_acc:.2f}%, F1={f1:.3f}, Sens={sensitivity:.3f}, Spec={specificity:.3f})\")\n        else:\n            no_improve += 1\n            print(f\"  No improvement ({no_improve}/{args.patience})\")\n\n        print(\"-\"*100)\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stop at epoch {epoch}\")\n            break\n\n    print(f\"\\n{'='*100}\")\n    print(f\"BEST - Accuracy: {best_val_acc:.2f}%, F1: {best_val_f1:.3f}\")\n    print(f\"{'='*100}\")\n\n\nif __name__ == '__main__':\n    kaggle_data = '/kaggle/input/vincent2/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_model.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_model.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_model.pth'\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=6000)\n    parser.add_argument('--stride', type=int, default=2400)  # 60% overlap for more data\n    parser.add_argument('--batch-size', type=int, default=32)  # Adjusted for multi-modal\n    parser.add_argument('--epochs', type=int, default=100)\n    parser.add_argument('--lr', type=float, default=1e-4)\n    parser.add_argument('--weight-decay', type=float, default=0)\n    parser.add_argument('--d-model', type=int, default=256)\n    parser.add_argument('--n-blocks', type=int, default=10)\n    parser.add_argument('--dropout', type=float, default=0.15)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--patience', type=int, default=20)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n\n    if args.data_dir is None:\n        raise SystemExit(\"ERROR: Dataset not found\")\n\n    print(\"=\"*100)\n    print(\"ENHANCED MODEL WITH R-R INTERVALS (Target: 90%+ Accuracy)\")\n    print(\"=\"*100)\n    print(f\"  Data:       {args.data_dir}\")\n    print(f\"  Segment:    {args.segment_length} samples (60s), stride={args.stride}\")\n    print(f\"  Features:   ECG + R-R Intervals + R-peak Amplitudes\")\n    print(f\"  Batch:      {args.batch_size}\")\n    print(f\"  Epochs:     {args.epochs}\")\n    print(f\"  Model:      d_model={args.d_model}, blocks={args.n_blocks}\")\n    print(f\"  Optimizer:  AdamW (lr={args.lr}, wd={args.weight_decay})\")\n    print(f\"  Loss:       Focal Loss (alpha=0.25, gamma=2.0)\")\n    print(\"=\"*100 + \"\\n\")\n\n    main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T06:24:54.037581Z","iopub.execute_input":"2025-11-29T06:24:54.038293Z","iopub.status.idle":"2025-11-29T07:05:53.451303Z","shell.execute_reply.started":"2025-11-29T06:24:54.038263Z","shell.execute_reply":"2025-11-29T07:05:53.450280Z"}},"outputs":[{"name":"stdout","text":"====================================================================================================\nENHANCED MODEL WITH R-R INTERVALS (Target: 90%+ Accuracy)\n====================================================================================================\n  Data:       /kaggle/input/vincent2/apnea-ecg-database-1.0.0\n  Segment:    6000 samples (60s), stride=2400\n  Features:   ECG + R-R Intervals + R-peak Amplitudes\n  Batch:      32\n  Epochs:     100\n  Model:      d_model=256, blocks=10\n  Optimizer:  AdamW (lr=0.0001, wd=0)\n  Loss:       Focal Loss (alpha=0.25, gamma=2.0)\n====================================================================================================\n\nFound 43 valid records\nTrain: 34, Val: 9\n\nProcessing 34 records for train (with R-R extraction)...\n  [34/34] a20....\nSaving cache to /kaggle/working/apnea_enhanced_train_6000_2400.pt\nTrain: 41751 segments, Class: Counter({0: 26395, 1: 15356})\nProcessing 9 records for val (with R-R extraction)...\n  [9/9] a01....\nSaving cache to /kaggle/working/apnea_enhanced_val_6000_2400.pt\nVal: 10777 segments, Class: Counter({0: 5862, 1: 4915})\nDevice: cuda\nGPU: Tesla P100-PCIE-16GB\nParameters: 2,496,778\n\nClass weights: tensor([0.7909, 1.3594], device='cuda:0')\n\nStarting training...\n====================================================================================================\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Ep 1 [1305/1305] Loss: 0.6828 Acc: 69.07% (24.3 b/s, ETA: 0s))\nEpoch  1/100 (58.0s)\n  Train: Loss=0.6828, Acc=69.07%\n  Val:   Loss=0.5591, Acc=73.87%, AUC=0.8367\n         Prec=0.666, Rec=0.855, F1=0.749\n         Sensitivity=0.855, Specificity=0.641\n  ✓ Best! (Acc=73.87%, F1=0.749, Sens=0.855, Spec=0.641)\n----------------------------------------------------------------------------------------------------\n  Ep 2 [1305/1305] Loss: 0.5557 Acc: 75.20% (25.4 b/s, ETA: 0s))\nEpoch  2/100 (55.5s)\n  Train: Loss=0.5557, Acc=75.20%\n  Val:   Loss=0.4985, Acc=78.19%, AUC=0.8756\n         Prec=0.716, Rec=0.865, F1=0.783\n         Sensitivity=0.865, Specificity=0.712\n  ✓ Best! (Acc=78.19%, F1=0.783, Sens=0.865, Spec=0.712)\n----------------------------------------------------------------------------------------------------\n  Ep 3 [1305/1305] Loss: 0.5022 Acc: 78.56% (25.3 b/s, ETA: 0s))\nEpoch  3/100 (55.6s)\n  Train: Loss=0.5022, Acc=78.56%\n  Val:   Loss=0.5167, Acc=77.36%, AUC=0.8655\n         Prec=0.711, Rec=0.847, F1=0.773\n         Sensitivity=0.847, Specificity=0.712\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 4 [1305/1305] Loss: 0.4499 Acc: 82.03% (25.2 b/s, ETA: 0s))\nEpoch  4/100 (56.0s)\n  Train: Loss=0.4499, Acc=82.03%\n  Val:   Loss=0.5239, Acc=77.65%, AUC=0.8679\n         Prec=0.714, Rec=0.851, F1=0.776\n         Sensitivity=0.851, Specificity=0.714\n  No improvement (2/20)\n----------------------------------------------------------------------------------------------------\n  Ep 5 [1305/1305] Loss: 0.4059 Acc: 84.97% (25.2 b/s, ETA: 0s))\nEpoch  5/100 (55.9s)\n  Train: Loss=0.4059, Acc=84.97%\n  Val:   Loss=0.4807, Acc=80.95%, AUC=0.8950\n         Prec=0.772, Rec=0.827, F1=0.798\n         Sensitivity=0.827, Specificity=0.795\n  ✓ Best! (Acc=80.95%, F1=0.798, Sens=0.827, Spec=0.795)\n----------------------------------------------------------------------------------------------------\n  Ep 6 [1305/1305] Loss: 0.3738 Acc: 86.82% (25.0 b/s, ETA: 0s))\nEpoch  6/100 (56.1s)\n  Train: Loss=0.3738, Acc=86.82%\n  Val:   Loss=0.4948, Acc=80.44%, AUC=0.8890\n         Prec=0.754, Rec=0.847, F1=0.798\n         Sensitivity=0.847, Specificity=0.768\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 7 [1305/1305] Loss: 0.3541 Acc: 87.99% (25.2 b/s, ETA: 0s))\nEpoch  7/100 (55.8s)\n  Train: Loss=0.3541, Acc=87.99%\n  Val:   Loss=0.5081, Acc=80.16%, AUC=0.8896\n         Prec=0.762, Rec=0.822, F1=0.791\n         Sensitivity=0.822, Specificity=0.784\n  No improvement (2/20)\n----------------------------------------------------------------------------------------------------\n  Ep 8 [1305/1305] Loss: 0.3354 Acc: 89.18% (25.5 b/s, ETA: 0s))\nEpoch  8/100 (55.1s)\n  Train: Loss=0.3354, Acc=89.18%\n  Val:   Loss=0.4409, Acc=82.97%, AUC=0.9085\n         Prec=0.777, Rec=0.880, F1=0.825\n         Sensitivity=0.880, Specificity=0.788\n  ✓ Best! (Acc=82.97%, F1=0.825, Sens=0.880, Spec=0.788)\n----------------------------------------------------------------------------------------------------\n  Ep 9 [1305/1305] Loss: 0.3221 Acc: 89.98% (25.0 b/s, ETA: 0s))\nEpoch  9/100 (56.4s)\n  Train: Loss=0.3221, Acc=89.98%\n  Val:   Loss=0.4390, Acc=83.67%, AUC=0.9163\n         Prec=0.814, Rec=0.832, F1=0.823\n         Sensitivity=0.832, Specificity=0.840\n  ✓ Best! (Acc=83.67%, F1=0.823, Sens=0.832, Spec=0.840)\n----------------------------------------------------------------------------------------------------\n  Ep 10 [1305/1305] Loss: 0.3114 Acc: 90.53% (25.2 b/s, ETA: 0s))\nEpoch 10/100 (55.8s)\n  Train: Loss=0.3114, Acc=90.53%\n  Val:   Loss=0.4469, Acc=82.95%, AUC=0.9137\n         Prec=0.800, Rec=0.835, F1=0.817\n         Sensitivity=0.835, Specificity=0.825\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 11 [1305/1305] Loss: 0.3004 Acc: 91.06% (25.3 b/s, ETA: 0s))\nEpoch 11/100 (55.6s)\n  Train: Loss=0.3004, Acc=91.06%\n  Val:   Loss=0.5199, Acc=79.69%, AUC=0.8875\n         Prec=0.748, Rec=0.837, F1=0.790\n         Sensitivity=0.837, Specificity=0.763\n  No improvement (2/20)\n----------------------------------------------------------------------------------------------------\n  Ep 12 [1305/1305] Loss: 0.2886 Acc: 91.88% (24.8 b/s, ETA: 0s))\nEpoch 12/100 (56.6s)\n  Train: Loss=0.2886, Acc=91.88%\n  Val:   Loss=0.5406, Acc=78.35%, AUC=0.8746\n         Prec=0.756, Rec=0.775, F1=0.766\n         Sensitivity=0.775, Specificity=0.791\n  No improvement (3/20)\n----------------------------------------------------------------------------------------------------\n  Ep 13 [1305/1305] Loss: 0.2803 Acc: 92.36% (25.3 b/s, ETA: 0s))\nEpoch 13/100 (55.7s)\n  Train: Loss=0.2803, Acc=92.36%\n  Val:   Loss=0.4745, Acc=83.26%, AUC=0.9110\n         Prec=0.843, Rec=0.778, F1=0.809\n         Sensitivity=0.778, Specificity=0.878\n  No improvement (4/20)\n----------------------------------------------------------------------------------------------------\n  Ep 14 [1305/1305] Loss: 0.2720 Acc: 92.78% (25.4 b/s, ETA: 0s))\nEpoch 14/100 (55.6s)\n  Train: Loss=0.2720, Acc=92.78%\n  Val:   Loss=0.4568, Acc=82.56%, AUC=0.9046\n         Prec=0.794, Rec=0.835, F1=0.814\n         Sensitivity=0.835, Specificity=0.818\n  No improvement (5/20)\n----------------------------------------------------------------------------------------------------\n  Ep 15 [1305/1305] Loss: 0.2627 Acc: 93.24% (25.1 b/s, ETA: 0s))\nEpoch 15/100 (56.1s)\n  Train: Loss=0.2627, Acc=93.24%\n  Val:   Loss=0.5010, Acc=81.59%, AUC=0.8957\n         Prec=0.761, Rec=0.869, F1=0.812\n         Sensitivity=0.869, Specificity=0.771\n  No improvement (6/20)\n----------------------------------------------------------------------------------------------------\n  Ep 16 [1305/1305] Loss: 0.2543 Acc: 93.79% (24.8 b/s, ETA: 0s))\nEpoch 16/100 (56.8s)\n  Train: Loss=0.2543, Acc=93.79%\n  Val:   Loss=0.5251, Acc=80.68%, AUC=0.8754\n         Prec=0.795, Rec=0.777, F1=0.786\n         Sensitivity=0.777, Specificity=0.831\n  No improvement (7/20)\n----------------------------------------------------------------------------------------------------\n  Ep 17 [1305/1305] Loss: 0.2453 Acc: 94.29% (25.2 b/s, ETA: 0s))\nEpoch 17/100 (56.0s)\n  Train: Loss=0.2453, Acc=94.29%\n  Val:   Loss=0.5091, Acc=81.75%, AUC=0.8991\n         Prec=0.793, Rec=0.811, F1=0.802\n         Sensitivity=0.811, Specificity=0.823\n  No improvement (8/20)\n----------------------------------------------------------------------------------------------------\n  Ep 18 [1305/1305] Loss: 0.2402 Acc: 94.54% (25.2 b/s, ETA: 0s))\nEpoch 18/100 (56.0s)\n  Train: Loss=0.2402, Acc=94.54%\n  Val:   Loss=0.5243, Acc=80.99%, AUC=0.8923\n         Prec=0.752, Rec=0.869, F1=0.807\n         Sensitivity=0.869, Specificity=0.760\n  No improvement (9/20)\n----------------------------------------------------------------------------------------------------\n  Ep 19 [1305/1305] Loss: 0.2299 Acc: 95.13% (25.2 b/s, ETA: 0s))\nEpoch 19/100 (55.7s)\n  Train: Loss=0.2299, Acc=95.13%\n  Val:   Loss=0.4989, Acc=82.71%, AUC=0.8996\n         Prec=0.792, Rec=0.841, F1=0.816\n         Sensitivity=0.841, Specificity=0.815\n  No improvement (10/20)\n----------------------------------------------------------------------------------------------------\n  Ep 20 [1305/1305] Loss: 0.2249 Acc: 95.42% (25.5 b/s, ETA: 0s))\nEpoch 20/100 (55.4s)\n  Train: Loss=0.2249, Acc=95.42%\n  Val:   Loss=0.4279, Acc=85.36%, AUC=0.9289\n         Prec=0.846, Rec=0.830, F1=0.838\n         Sensitivity=0.830, Specificity=0.874\n  ✓ Best! (Acc=85.36%, F1=0.838, Sens=0.830, Spec=0.874)\n----------------------------------------------------------------------------------------------------\n  Ep 21 [1305/1305] Loss: 0.2140 Acc: 96.00% (25.5 b/s, ETA: 0s))\nEpoch 21/100 (55.3s)\n  Train: Loss=0.2140, Acc=96.00%\n  Val:   Loss=0.5833, Acc=79.68%, AUC=0.8732\n         Prec=0.755, Rec=0.820, F1=0.786\n         Sensitivity=0.820, Specificity=0.778\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 22 [1305/1305] Loss: 0.2123 Acc: 96.14% (25.3 b/s, ETA: 0s))\nEpoch 22/100 (55.7s)\n  Train: Loss=0.2123, Acc=96.14%\n  Val:   Loss=0.5013, Acc=81.63%, AUC=0.8965\n         Prec=0.790, Rec=0.813, F1=0.801\n         Sensitivity=0.813, Specificity=0.819\n  No improvement (2/20)\n----------------------------------------------------------------------------------------------------\n  Ep 23 [1305/1305] Loss: 0.2045 Acc: 96.44% (25.3 b/s, ETA: 0s))\nEpoch 23/100 (55.6s)\n  Train: Loss=0.2045, Acc=96.44%\n  Val:   Loss=0.5380, Acc=81.14%, AUC=0.8847\n         Prec=0.818, Rec=0.754, F1=0.785\n         Sensitivity=0.754, Specificity=0.859\n  No improvement (3/20)\n----------------------------------------------------------------------------------------------------\n  Ep 24 [1305/1305] Loss: 0.2007 Acc: 96.72% (25.1 b/s, ETA: 0s))\nEpoch 24/100 (56.2s)\n  Train: Loss=0.2007, Acc=96.72%\n  Val:   Loss=0.4779, Acc=84.06%, AUC=0.9145\n         Prec=0.802, Rec=0.864, F1=0.832\n         Sensitivity=0.864, Specificity=0.821\n  No improvement (4/20)\n----------------------------------------------------------------------------------------------------\n  Ep 25 [1305/1305] Loss: 0.1941 Acc: 96.93% (25.5 b/s, ETA: 0s))\nEpoch 25/100 (55.3s)\n  Train: Loss=0.1941, Acc=96.93%\n  Val:   Loss=0.6256, Acc=77.86%, AUC=0.8474\n         Prec=0.787, Rec=0.706, F1=0.744\n         Sensitivity=0.706, Specificity=0.839\n  No improvement (5/20)\n----------------------------------------------------------------------------------------------------\n  Ep 26 [1305/1305] Loss: 0.1896 Acc: 97.18% (25.4 b/s, ETA: 0s))\nEpoch 26/100 (55.4s)\n  Train: Loss=0.1896, Acc=97.18%\n  Val:   Loss=0.5854, Acc=79.74%, AUC=0.8806\n         Prec=0.763, Rec=0.806, F1=0.784\n         Sensitivity=0.806, Specificity=0.791\n  No improvement (6/20)\n----------------------------------------------------------------------------------------------------\n  Ep 27 [1305/1305] Loss: 0.1876 Acc: 97.37% (25.6 b/s, ETA: 0s))\nEpoch 27/100 (54.8s)\n  Train: Loss=0.1876, Acc=97.37%\n  Val:   Loss=0.5848, Acc=79.51%, AUC=0.8636\n         Prec=0.796, Rec=0.740, F1=0.767\n         Sensitivity=0.740, Specificity=0.842\n  No improvement (7/20)\n----------------------------------------------------------------------------------------------------\n  Ep 28 [1305/1305] Loss: 0.1807 Acc: 97.63% (25.2 b/s, ETA: 0s))\nEpoch 28/100 (56.0s)\n  Train: Loss=0.1807, Acc=97.63%\n  Val:   Loss=0.4725, Acc=84.78%, AUC=0.9238\n         Prec=0.830, Rec=0.837, F1=0.834\n         Sensitivity=0.837, Specificity=0.857\n  No improvement (8/20)\n----------------------------------------------------------------------------------------------------\n  Ep 29 [1305/1305] Loss: 0.1791 Acc: 97.78% (25.4 b/s, ETA: 0s))\nEpoch 29/100 (55.7s)\n  Train: Loss=0.1791, Acc=97.78%\n  Val:   Loss=0.5152, Acc=83.02%, AUC=0.9048\n         Prec=0.831, Rec=0.788, F1=0.809\n         Sensitivity=0.788, Specificity=0.865\n  No improvement (9/20)\n----------------------------------------------------------------------------------------------------\n  Ep 30 [1305/1305] Loss: 0.1775 Acc: 97.79% (25.2 b/s, ETA: 0s))\nEpoch 30/100 (56.2s)\n  Train: Loss=0.1775, Acc=97.79%\n  Val:   Loss=0.5525, Acc=81.53%, AUC=0.8909\n         Prec=0.781, Rec=0.827, F1=0.803\n         Sensitivity=0.827, Specificity=0.805\n  No improvement (10/20)\n----------------------------------------------------------------------------------------------------\n  Ep 31 [1305/1305] Loss: 0.1726 Acc: 98.08% (25.3 b/s, ETA: 0s))\nEpoch 31/100 (55.5s)\n  Train: Loss=0.1726, Acc=98.08%\n  Val:   Loss=0.5355, Acc=82.74%, AUC=0.9007\n         Prec=0.777, Rec=0.871, F1=0.822\n         Sensitivity=0.871, Specificity=0.791\n  No improvement (11/20)\n----------------------------------------------------------------------------------------------------\n  Ep 32 [1305/1305] Loss: 0.1706 Acc: 98.18% (25.1 b/s, ETA: 0s))\nEpoch 32/100 (56.0s)\n  Train: Loss=0.1706, Acc=98.18%\n  Val:   Loss=0.5637, Acc=81.59%, AUC=0.8852\n         Prec=0.796, Rec=0.801, F1=0.799\n         Sensitivity=0.801, Specificity=0.828\n  No improvement (12/20)\n----------------------------------------------------------------------------------------------------\n  Ep 33 [1305/1305] Loss: 0.1682 Acc: 98.26% (25.5 b/s, ETA: 0s))\nEpoch 33/100 (55.2s)\n  Train: Loss=0.1682, Acc=98.26%\n  Val:   Loss=0.5396, Acc=81.87%, AUC=0.8929\n         Prec=0.790, Rec=0.821, F1=0.805\n         Sensitivity=0.821, Specificity=0.817\n  No improvement (13/20)\n----------------------------------------------------------------------------------------------------\n  Ep 34 [1305/1305] Loss: 0.1669 Acc: 98.32% (25.4 b/s, ETA: 0s))\nEpoch 34/100 (55.3s)\n  Train: Loss=0.1669, Acc=98.32%\n  Val:   Loss=0.5480, Acc=82.79%, AUC=0.8918\n         Prec=0.788, Rec=0.851, F1=0.819\n         Sensitivity=0.851, Specificity=0.808\n  No improvement (14/20)\n----------------------------------------------------------------------------------------------------\n  Ep 35 [1305/1305] Loss: 0.1648 Acc: 98.40% (25.3 b/s, ETA: 0s))\nEpoch 35/100 (55.6s)\n  Train: Loss=0.1648, Acc=98.40%\n  Val:   Loss=0.5272, Acc=83.43%, AUC=0.9021\n         Prec=0.805, Rec=0.840, F1=0.822\n         Sensitivity=0.840, Specificity=0.829\n  No improvement (15/20)\n----------------------------------------------------------------------------------------------------\n  Ep 36 [1305/1305] Loss: 0.1609 Acc: 98.59% (25.3 b/s, ETA: 0s))\nEpoch 36/100 (55.5s)\n  Train: Loss=0.1609, Acc=98.59%\n  Val:   Loss=0.5238, Acc=83.47%, AUC=0.8928\n         Prec=0.833, Rec=0.798, F1=0.815\n         Sensitivity=0.798, Specificity=0.866\n  No improvement (16/20)\n----------------------------------------------------------------------------------------------------\n  Ep 37 [1305/1305] Loss: 0.1580 Acc: 98.68% (25.1 b/s, ETA: 0s))\nEpoch 37/100 (56.1s)\n  Train: Loss=0.1580, Acc=98.68%\n  Val:   Loss=0.5932, Acc=81.71%, AUC=0.8993\n         Prec=0.765, Rec=0.865, F1=0.812\n         Sensitivity=0.865, Specificity=0.777\n  No improvement (17/20)\n----------------------------------------------------------------------------------------------------\n  Ep 38 [1305/1305] Loss: 0.1569 Acc: 98.78% (25.4 b/s, ETA: 0s))\nEpoch 38/100 (55.2s)\n  Train: Loss=0.1569, Acc=98.78%\n  Val:   Loss=0.6011, Acc=81.36%, AUC=0.8934\n         Prec=0.781, Rec=0.822, F1=0.801\n         Sensitivity=0.822, Specificity=0.807\n  No improvement (18/20)\n----------------------------------------------------------------------------------------------------\n  Ep 39 [1305/1305] Loss: 0.1573 Acc: 98.74% (24.7 b/s, ETA: 0s))\nEpoch 39/100 (56.8s)\n  Train: Loss=0.1573, Acc=98.74%\n  Val:   Loss=0.6272, Acc=80.11%, AUC=0.8680\n         Prec=0.783, Rec=0.779, F1=0.781\n         Sensitivity=0.779, Specificity=0.819\n  No improvement (19/20)\n----------------------------------------------------------------------------------------------------\n  Ep 40 [1305/1305] Loss: 0.1526 Acc: 98.95% (25.6 b/s, ETA: 0s))\nEpoch 40/100 (55.3s)\n  Train: Loss=0.1526, Acc=98.95%\n  Val:   Loss=0.5405, Acc=83.83%, AUC=0.9080\n         Prec=0.825, Rec=0.820, F1=0.822\n         Sensitivity=0.820, Specificity=0.854\n  No improvement (20/20)\n----------------------------------------------------------------------------------------------------\n\nEarly stop at epoch 40\n\n====================================================================================================\nBEST - Accuracy: 85.36%, F1: 0.838\n====================================================================================================\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nHigh-performance apnea detection with R-R interval extraction (Target: 90%+ accuracy)\nBased on PhysioNet Apnea-ECG Database methodology\n\"\"\"\n\nimport argparse\nimport os\nimport time\nfrom pathlib import Path\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy import signal as scipy_signal\nfrom scipy.interpolate import interp1d\n\ntry:\n    import wfdb\nexcept Exception:\n    wfdb = None\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n\n# ----------------------------- Utilities ---------------------------------\n\ndef set_seed(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# ----------------------------- R-Peak Detection & R-R Interval Extraction ---------------------------------\n\ndef detect_r_peaks_hamilton(ecg_signal, fs=100):\n    \"\"\"\n    Enhanced Hamilton R-peak detection with better noise handling\n    \"\"\"\n    # Remove baseline wander (0.5 Hz high-pass)\n    b_high, a_high = scipy_signal.butter(2, 0.5, btype='high', fs=fs)\n    ecg_signal = scipy_signal.filtfilt(b_high, a_high, ecg_signal)\n    \n    # Bandpass filter (5-15 Hz) - tighter for QRS\n    b, a = scipy_signal.butter(3, [5, 15], btype='band', fs=fs)\n    filtered = scipy_signal.filtfilt(b, a, ecg_signal)\n    \n    # Derivative with normalization\n    diff_signal = np.diff(filtered)\n    diff_signal = diff_signal / (np.std(diff_signal) + 1e-8)\n    \n    # Squaring\n    squared = diff_signal ** 2\n    \n    # Moving average integration (150ms window)\n    window_size = int(0.15 * fs)\n    integrated = np.convolve(squared, np.ones(window_size)/window_size, mode='same')\n    \n    # Adaptive thresholding with percentile\n    threshold = np.percentile(integrated, 75) + 0.3 * np.std(integrated)\n    \n    # Find peaks with minimum distance constraint\n    from scipy.signal import find_peaks\n    peaks, properties = find_peaks(integrated, \n                                   height=threshold,\n                                   distance=int(0.2 * fs))  # 200ms minimum\n    \n    # Validate peaks are actual R-peaks by checking original signal\n    valid_peaks = []\n    for peak in peaks:\n        # Check window around peak in original signal\n        win_start = max(0, peak - int(0.05 * fs))\n        win_end = min(len(ecg_signal), peak + int(0.05 * fs))\n        if win_end > win_start:\n            local_max = np.argmax(np.abs(ecg_signal[win_start:win_end])) + win_start\n            valid_peaks.append(local_max)\n    \n    return np.array(valid_peaks)\n\ndef median_filter_rr(rr_intervals, window=5):\n    \"\"\"\n    Median filter for removing physiologically uninterpretable R-R intervals\n    Based on Chen et al. methodology\n    \"\"\"\n    if len(rr_intervals) < window:\n        return rr_intervals\n    \n    filtered = rr_intervals.copy()\n    median_rr = np.median(rr_intervals)\n    \n    for i in range(len(rr_intervals)):\n        # Check if RR interval is physiologically valid (300ms - 2000ms)\n        if rr_intervals[i] < 0.3 or rr_intervals[i] > 2.0:\n            filtered[i] = median_rr\n            continue\n        \n        # Median filter\n        start = max(0, i - window//2)\n        end = min(len(rr_intervals), i + window//2 + 1)\n        window_vals = rr_intervals[start:end]\n        local_median = np.median(window_vals)\n        \n        # Replace outliers (> 20% deviation from local median)\n        if abs(rr_intervals[i] - local_median) > 0.2 * local_median:\n            filtered[i] = local_median\n    \n    return filtered\n\ndef extract_rr_features(ecg_segment, fs=100):\n    \"\"\"\n    Enhanced RR extraction with additional HRV features\n    Returns 360 features: [rr_interp(180), ramp_interp(180)]\n    \"\"\"\n    r_peaks = detect_r_peaks_hamilton(ecg_segment, fs)\n    if len(r_peaks) < 5:\n        return np.zeros(180, dtype=np.float32), np.zeros(180, dtype=np.float32)\n\n    # RR intervals\n    rr_sec = np.diff(r_peaks) / fs\n    rr_sec = median_filter_rr(rr_sec)\n    rr_times = r_peaks[1:] / fs\n    \n    # R-peak amplitudes\n    ramp = ecg_segment[r_peaks[1:]]\n    \n    # Interpolate to 3 Hz (180 samples for 60s)\n    targ_t = np.linspace(0, 60, 180)\n    \n    # Use better interpolation\n    if len(rr_sec) >= 10:\n        kind = 'cubic'\n    elif len(rr_sec) >= 4:\n        kind = 'quadratic'\n    else:\n        kind = 'linear'\n    \n    f_rr = interp1d(rr_times, rr_sec, kind=kind, bounds_error=False, \n                    fill_value='extrapolate')\n    f_amp = interp1d(rr_times, ramp, kind=kind, bounds_error=False, \n                     fill_value='extrapolate')\n    \n    rr_out = f_rr(targ_t)\n    ramp_out = f_amp(targ_t)\n    \n    # Clip to physiological range\n    rr_out = np.clip(rr_out, 0.3, 2.0)\n    \n    # Robust normalization (using IQR instead of std)\n    def robust_normalize(x):\n        q1, q3 = np.percentile(x, [25, 75])\n        iqr = q3 - q1\n        if iqr > 1e-6:\n            return np.clip((x - np.median(x)) / iqr, -5, 5)\n        else:\n            return x - np.median(x)\n    \n    rr_out = robust_normalize(rr_out).astype(np.float32)\n    ramp_out = robust_normalize(ramp_out).astype(np.float32)\n    \n    return rr_out, ramp_out\n\n# ----------------------------- Improved Model ---------------------------------\n\nclass MultiScaleBlock(nn.Module):\n    \"\"\"Multi-scale feature extraction block\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        # ensure total output channels == out_channels\n        c1 = out_channels // 3\n        c2 = out_channels // 3\n        c3 = out_channels - c1 - c2  # remainder so c1 + c2 + c3 == out_channels\n\n        self.conv1 = nn.Conv1d(in_channels, c1, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(in_channels, c2, kernel_size=5, padding=2)\n        self.conv3 = nn.Conv1d(in_channels, c3, kernel_size=7, padding=3)\n        self.bn = nn.BatchNorm1d(out_channels)\n        \n    def forward(self, x):\n        x1 = self.conv1(x)\n        x2 = self.conv2(x)\n        x3 = self.conv3(x)\n        out = torch.cat([x1, x2, x3], dim=1)\n        return F.gelu(self.bn(out))\n\n\nclass EnhancedResBlock(nn.Module):\n    \"\"\"Enhanced residual block with squeeze-excitation\"\"\"\n    def __init__(self, channels, kernel_size=7):\n        super().__init__()\n        self.conv1 = nn.Conv1d(channels, channels, kernel_size, padding=kernel_size//2, groups=channels)\n        self.conv2 = nn.Conv1d(channels, channels, 1)\n        self.norm = nn.BatchNorm1d(channels)\n        \n        # Squeeze-Excitation with stability improvements\n        se_channels = max(8, channels // 8)  # Ensure at least 8 channels\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Conv1d(channels, se_channels, 1),\n            nn.GELU(),\n            nn.Conv1d(se_channels, channels, 1),\n            nn.Sigmoid()\n        )\n        self.dropout = nn.Dropout(0.15)\n        \n    def forward(self, x):\n        residual = x\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.norm(x)\n        \n        # Apply SE attention with safety check\n        se_weight = self.se(x)\n        # Clamp to prevent extreme values\n        se_weight = torch.clamp(se_weight, 0.0, 1.0)\n        x = x * se_weight\n        \n        x = self.dropout(x)\n        return F.gelu(residual + x)\n\nclass ImprovedApneaNet(nn.Module):\n    def __init__(self, d_model=256, n_blocks=10, dropout=0.15):\n        super().__init__()\n        \n        # Ensure the three modality-channel outputs sum to d_model\n        c1 = d_model // 3\n        c2 = d_model // 3\n        c3 = d_model - c1 - c2\n\n        # ECG pathway (6000 samples) -> c1 channels\n        self.ecg_stem = nn.Sequential(\n            nn.Conv1d(1, c1, kernel_size=15, padding=7, stride=4),\n            nn.BatchNorm1d(c1),\n            nn.GELU(),\n            nn.Conv1d(c1, c1, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c1),\n            nn.GELU(),\n        )\n\n        # RR interval pathway (180 samples @ 3Hz) -> c2 channels\n        self.rr_stem = nn.Sequential(\n            nn.Conv1d(1, c2, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c2),\n            nn.GELU(),\n            nn.Conv1d(c2, c2, kernel_size=5, padding=2),\n            nn.BatchNorm1d(c2),\n            nn.GELU(),\n        )\n\n        # R-amplitude pathway (180 samples @ 3Hz) -> c3 channels\n        self.ramp_stem = nn.Sequential(\n            nn.Conv1d(1, c3, kernel_size=7, padding=3, stride=2),\n            nn.BatchNorm1d(c3),\n            nn.GELU(),\n            nn.Conv1d(c3, c3, kernel_size=5, padding=2),\n            nn.BatchNorm1d(c3),\n            nn.GELU(),\n        )\n        \n        # Multi-scale fusion\n        self.fusion = MultiScaleBlock(d_model, d_model)\n        \n        # Enhanced residual blocks\n        self.blocks = nn.ModuleList([\n            EnhancedResBlock(d_model, kernel_size=7 if i % 2 == 0 else 11)\n            for i in range(n_blocks)\n        ])\n        \n        # Temporal attention with larger context\n        self.temp_attn = nn.MultiheadAttention(d_model, num_heads=8, dropout=dropout, batch_first=True)\n        self.temp_norm = nn.LayerNorm(d_model)\n        self.temp_ffn = nn.Sequential(\n            nn.Linear(d_model, d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 2, d_model)\n        )\n        \n        # Feature aggregation\n        self.global_pool = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Flatten()\n        )\n        \n        # Enhanced classifier with multiple paths\n        # Attention-based pooling\n        self.attention_pool = nn.Sequential(\n            nn.Conv1d(d_model, d_model // 4, 1),\n            nn.GELU(),\n            nn.Conv1d(d_model // 4, 1, 1),\n            nn.Softmax(dim=2)\n        )\n        \n        # Enhanced classifier with deeper network\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model * 4, d_model * 3),\n            nn.BatchNorm1d(d_model * 3),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model * 3, d_model * 2),\n            nn.BatchNorm1d(d_model * 2),\n            nn.GELU(),\n            nn.Dropout(dropout * 0.7),\n            nn.Linear(d_model * 2, d_model),\n            nn.BatchNorm1d(d_model),\n            nn.GELU(),\n            nn.Dropout(dropout * 0.5),\n            nn.Linear(d_model, 2)\n        )\n        \n        # Initialize weights\n        self._initialize_weights()\n        \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv1d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n        \n    def forward(self, ecg, rr, ramp):\n        # Validate inputs\n        if torch.isnan(ecg).any() or torch.isinf(ecg).any():\n            ecg = torch.nan_to_num(ecg, nan=0.0, posinf=10.0, neginf=-10.0)\n        if torch.isnan(rr).any() or torch.isinf(rr).any():\n            rr = torch.nan_to_num(rr, nan=0.0, posinf=10.0, neginf=-10.0)\n        if torch.isnan(ramp).any() or torch.isinf(ramp).any():\n            ramp = torch.nan_to_num(ramp, nan=0.0, posinf=10.0, neginf=-10.0)\n        \n        # Process each modality\n        ecg = ecg.transpose(1, 2)\n        rr = rr.transpose(1, 2)\n        ramp = ramp.transpose(1, 2)\n        \n        ecg_feat = self.ecg_stem(ecg)\n        rr_feat = self.rr_stem(rr)\n        ramp_feat = self.ramp_stem(ramp)\n        \n        # Align sequence lengths and concatenate\n        target_len = min(ecg_feat.size(2), rr_feat.size(2), ramp_feat.size(2))\n        ecg_feat = F.adaptive_avg_pool1d(ecg_feat, target_len)\n        rr_feat = F.adaptive_avg_pool1d(rr_feat, target_len)\n        ramp_feat = F.adaptive_avg_pool1d(ramp_feat, target_len)\n        \n        x = torch.cat([ecg_feat, rr_feat, ramp_feat], dim=1)\n        \n        # Multi-scale fusion\n        x = self.fusion(x)\n        \n        # Residual blocks\n        for block in self.blocks:\n            x = block(x)\n        \n        # Multiple pooling strategies with safety\n        # Attention-weighted pooling\n        attn_weights = self.attention_pool(x)\n        x_attn_pool = (x * attn_weights).sum(dim=2)\n        \n        # Multiple pooling strategies\n        x_avg = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n        x_max = F.adaptive_max_pool1d(x, 1).squeeze(-1)\n        x_std = torch.std(x, dim=2) + 1e-8\n        \n        # Temporal attention\n        x_seq = x.transpose(1, 2)\n        x_attn, _ = self.temp_attn(x_seq, x_seq, x_seq)\n        x_attn = self.temp_norm(x_attn + x_seq)\n        x_attn = x_attn + self.temp_ffn(x_attn)\n        x_attn = x_attn.mean(dim=1)\n        \n        # Combine all features\n        x_combined = torch.cat([x_avg, x_max, x_std, x_attn], dim=1)\n        \n        # Final NaN check before classifier\n        if torch.isnan(x_combined).any() or torch.isinf(x_combined).any():\n            x_combined = torch.nan_to_num(x_combined, nan=0.0, posinf=10.0, neginf=-10.0)\n        \n        # Classify\n        logits = self.classifier(x_combined)\n        return logits\n\n# --------------------------- Enhanced Dataset ---------------------------\n\nclass EnhancedApneaDataset(Dataset):\n    \"\"\"Dataset with R-R interval and R-amplitude extraction\"\"\"\n\n    def __init__(self, data_dir: str, record_names: list = None, cache_dir: str = None,\n                 segment_length: int = 6000, stride: int = 3000, split='train', augment=True):\n        super().__init__()\n        self.segment_length = int(segment_length)\n        self.stride = int(stride)\n        self.split = split\n        self.augment = augment and (split == 'train')\n        \n        cache_dir = Path(cache_dir) if cache_dir else Path(data_dir)\n        cache_file = cache_dir / f'apnea_enhanced_{split}_{segment_length}_{stride}.pt'\n\n        if cache_file.exists():\n            print(f\"Loading cached {split} from {cache_file}\")\n            data = torch.load(cache_file)\n            self.ecg_segments = data['ecg_segments']\n            self.rr_segments = data['rr_segments']\n            self.ramp_segments = data['ramp_segments']\n            self.labels = data['labels']\n        else:\n            assert wfdb is not None, \"wfdb required\"\n            assert record_names is not None, \"record_names required\"\n            \n            self.ecg_segments = []\n            self.rr_segments = []\n            self.ramp_segments = []\n            self.labels = []\n            self.data_dir = Path(data_dir)\n            \n            print(f\"Processing {len(record_names)} records for {split} (with R-R extraction)...\")\n            for i, rec in enumerate(record_names):\n                print(f\"  [{i+1}/{len(record_names)}] {rec}...\", end='\\r')\n                self._load_record(rec)\n            \n            if len(self.ecg_segments) == 0:\n                raise RuntimeError(\"No segments loaded\")\n            \n            self.ecg_segments = torch.tensor(np.stack(self.ecg_segments, axis=0), dtype=torch.float32)\n            self.rr_segments = torch.tensor(np.stack(self.rr_segments, axis=0), dtype=torch.float32)\n            self.ramp_segments = torch.tensor(np.stack(self.ramp_segments, axis=0), dtype=torch.float32)\n            self.labels = torch.tensor(self.labels, dtype=torch.long)\n            \n            print(f\"\\nSaving cache to {cache_file}\")\n            torch.save({\n                'ecg_segments': self.ecg_segments,\n                'rr_segments': self.rr_segments,\n                'ramp_segments': self.ramp_segments,\n                'labels': self.labels\n            }, cache_file)\n\n        if self.ecg_segments.ndim == 2:\n            self.ecg_segments = self.ecg_segments.unsqueeze(-1)\n        if self.rr_segments.ndim == 2:\n            self.rr_segments = self.rr_segments.unsqueeze(-1)\n        if self.ramp_segments.ndim == 2:\n            self.ramp_segments = self.ramp_segments.unsqueeze(-1)\n\n        print(f\"{split.capitalize()}: {len(self.ecg_segments)} segments, \"\n              f\"Class: {Counter(self.labels.tolist())}\")\n\n    def _load_record(self, record_name: str):\n        try:\n            rec = wfdb.rdrecord(str(self.data_dir / record_name))\n            sig = rec.p_signal[:, 0].astype(np.float32)\n            if np.isnan(sig).any():\n                nans = np.isnan(sig)\n                sig[nans] = np.interp(np.flatnonzero(nans), np.flatnonzero(~nans), sig[~nans])\n\n            ann = wfdb.rdann(str(self.data_dir / record_name), 'apn')\n            n_min = len(sig) // 6000\n            mins = np.zeros(n_min, dtype=int)\n            for samp, sym in zip(ann.sample, ann.symbol):\n                if sym == 'A':\n                    m = samp // 6000\n                    if m < n_min:\n                        mins[m] = 1\n\n            for start in range(0, len(sig) - self.segment_length + 1, self.stride):\n                seg = sig[start:start + self.segment_length]\n                \n                # Normalise ECG with safety\n                seg_std = seg.std()\n                if seg_std > 1e-6:\n                    seg = (seg - seg.mean()) / seg_std\n                else:\n                    seg = seg - seg.mean()\n                seg = np.clip(seg, -10, 10)\n\n                rr, ramp = extract_rr_features(seg, fs=100)\n\n                minute = start // 6000\n                if minute < len(mins):\n                    self.ecg_segments.append(seg)\n                    self.rr_segments.append(rr)\n                    self.ramp_segments.append(ramp)\n                    self.labels.append(int(mins[minute]))\n        except Exception as e:\n            print(f'\\nSkip {record_name}: {e}')\n    \n    def _augment(self, ecg, rr, ramp):\n        ecg, rr, ramp = map(lambda x: x.numpy() if torch.is_tensor(x) else x, (ecg, rr, ramp))\n\n    # Flatten to 1D for augmentation, will reshape back at the end\n        ecg = ecg.squeeze()\n        rr = rr.squeeze()\n        ramp = ramp.squeeze()\n\n    # Time shift (more aggressive)\n        if np.random.rand() < 0.4:\n            shift = np.random.randint(-300, 300)\n            ecg = np.roll(ecg, shift)\n\n    # Gaussian noise (adjusted per signal type)\n        if np.random.rand() < 0.6:\n            ecg += np.random.normal(0, 0.03, ecg.shape).astype(np.float32)\n            rr += np.random.normal(0, 0.02, rr.shape).astype(np.float32)\n            ramp += np.random.normal(0, 0.02, ramp.shape).astype(np.float32)\n\n    # Amplitude scaling\n        if np.random.rand() < 0.4:\n            ecg_scale = np.random.uniform(0.85, 1.15)\n            ramp_scale = np.random.uniform(0.9, 1.1)\n            ecg *= ecg_scale\n            ramp *= ramp_scale\n\n    # Baseline wander simulation for ECG\n        if np.random.rand() < 0.3:\n            baseline = np.sin(np.linspace(0, 2*np.pi, len(ecg))) * np.random.uniform(0.05, 0.15)\n            ecg += baseline\n\n    # RR interval perturbation (simulating heart rate variability changes)\n        if np.random.rand() < 0.3:\n            rr_noise = scipy_signal.savgol_filter(np.random.randn(len(rr)), 15, 3) * 0.05\n            rr += rr_noise\n\n    # Clip after augmentation\n        ecg = np.clip(ecg, -10, 10)\n        rr = np.clip(rr, -10, 10)\n        ramp = np.clip(ramp, -10, 10)\n\n    # Convert back to torch tensors\n        return tuple(map(torch.from_numpy, (ecg, rr, ramp)))\n            \n    def __len__(self):\n        return self.ecg_segments.shape[0]\n\n    def __getitem__(self, idx):\n        ecg = self.ecg_segments[idx]\n        rr = self.rr_segments[idx]\n        ramp = self.ramp_segments[idx]\n        label = self.labels[idx]\n        \n        if self.augment:\n            ecg, rr, ramp = self._augment(ecg, rr, ramp)\n        \n        # Ensure correct shape\n        if ecg.ndim == 1:\n            ecg = ecg.unsqueeze(-1)\n        if rr.ndim == 1:\n            rr = rr.unsqueeze(-1)\n        if ramp.ndim == 1:\n            ramp = ramp.unsqueeze(-1)\n        \n        return ecg, rr, ramp, label\n\n# -------------------------- Training ------------------------\n\ndef compute_class_weights(labels_tensor):\n    counts = Counter(labels_tensor.tolist())\n    total = sum(counts.values())\n    num_classes = len(counts)\n    weights = [total / (num_classes * counts.get(i, 1)) for i in range(num_classes)]\n    return torch.tensor(weights, dtype=torch.float32)\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0, weight=None):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.weight = weight\n        \n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.weight)\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n        return focal_loss.mean()\n\ndef train_epoch(model, dataloader, criterion, optimizer, scheduler, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    \n    num_batches = len(dataloader)\n    print_freq = max(1, num_batches // 15)\n    start_time = time.time()\n\n    for batch_idx, (ecg, rr, ramp, target) in enumerate(dataloader, 1):\n        ecg = ecg.to(device, non_blocking=True)\n        rr = rr.to(device, non_blocking=True)\n        ramp = ramp.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            output = model(ecg, rr, ramp)\n            loss = criterion(output, target)\n        \n        if torch.isnan(loss) or torch.isinf(loss):\n            print(f\"\\nWARNING: NaN/Inf loss, skipping batch {batch_idx}\")\n            continue\n\n        if scaler is not None:\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n        \n        scheduler.step()\n\n        total_loss += loss.item()\n        pred = output.argmax(dim=1)\n        correct += pred.eq(target).sum().item()\n        total += target.size(0)\n        \n        if batch_idx % print_freq == 0 or batch_idx == num_batches:\n            curr_acc = 100.0 * correct / total\n            curr_loss = total_loss / batch_idx\n            speed = batch_idx / (time.time() - start_time)\n            eta = (num_batches - batch_idx) / speed if speed > 0 else 0\n            \n            print(f\"  Ep {epoch} [{batch_idx:4d}/{num_batches}] \"\n                  f\"Loss: {curr_loss:.4f} Acc: {curr_acc:.2f}% \"\n                  f\"({speed:.1f} b/s, ETA: {eta:.0f}s)\", end='\\r')\n\n    print()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    return avg_loss, accuracy\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for ecg, rr, ramp, target in dataloader:\n            ecg = ecg.to(device, non_blocking=True)\n            rr = rr.to(device, non_blocking=True)\n            ramp = ramp.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            \n            output = model(ecg, rr, ramp)\n            loss = criterion(output, target)\n\n            total_loss += loss.item()\n            probs = F.softmax(output, dim=1)[:, 1]\n            pred = output.argmax(dim=1)\n\n            correct += pred.eq(target).sum().item()\n            total += target.size(0)\n\n            all_preds.extend(pred.cpu().tolist())\n            all_targets.extend(target.cpu().tolist())\n            all_probs.extend(probs.cpu().tolist())\n\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100.0 * correct / total if total > 0 else 0.0\n    \n    precision = precision_score(all_targets, all_preds, zero_division=0)\n    recall = recall_score(all_targets, all_preds, zero_division=0)\n    f1 = f1_score(all_targets, all_preds, zero_division=0)\n    \n    # Calculate specificity and sensitivity\n    tn, fp, fn, tp = confusion_matrix(all_targets, all_preds).ravel()\n    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n    \n    return avg_loss, accuracy, np.array(all_preds), np.array(all_targets), np.array(all_probs), precision, recall, f1, sensitivity, specificity\n\n# ------------------------------ Main ------------------------------------\n\ndef main(args):\n    set_seed(args.seed)\n\n    DATA_DIR = Path(args.data_dir)\n    if not DATA_DIR.exists():\n        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n\n    record_files = list(DATA_DIR.glob('*.hea'))\n    all_records = [f.stem for f in record_files]\n    valid_records = [rec for rec in all_records \n                    if (DATA_DIR / (rec + '.apn')).exists() and not rec.endswith('er')]\n    \n    if len(valid_records) == 0:\n        raise RuntimeError(\"No valid records found\")\n\n    print(f\"Found {len(valid_records)} valid records\")\n\n    import random\n    valid_records_shuffled = valid_records.copy()\n    random.Random(args.seed).shuffle(valid_records_shuffled)\n    split_idx = int(len(valid_records_shuffled) * args.train_split)\n    train_records = valid_records_shuffled[:split_idx]\n    val_records = valid_records_shuffled[split_idx:]\n    print(f\"Train: {len(train_records)}, Val: {len(val_records)}\\n\")\n\n    cache_dir = args.cache_dir if args.cache_dir else str(DATA_DIR)\n    train_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), train_records, cache_dir,\n        args.segment_length, args.stride, 'train', augment=True\n    )\n    val_dataset = EnhancedApneaDataset(\n        str(DATA_DIR), val_records, cache_dir,\n        args.segment_length, args.stride, 'val', augment=False\n    )\n\n    num_workers = 2 if str(DATA_DIR).startswith('/kaggle') else 4\n\n    train_loader = DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=num_workers, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=num_workers, pin_memory=True\n    )\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Device: {device}\")\n    if device.type == 'cuda':\n        try:\n            print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        except Exception:\n            pass\n        torch.cuda.empty_cache()\n\n    model = ImprovedApneaNet(\n        d_model=args.d_model, n_blocks=args.n_blocks, dropout=args.dropout\n    ).to(device)\n\n    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n\n    class_weights = compute_class_weights(train_dataset.labels).to(device)\n    print(f\"Class weights: {class_weights}\")\n\n    # Use Focal Loss for better class imbalance handling\n        # stable, NaN-free loss with class weights\n    criterion = FocalLoss(alpha=0.25, gamma=2.0, weight=class_weights)\n\n    optimizer = torch.optim.AdamW(\n        model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n    )\n\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer, max_lr=args.lr, epochs=args.epochs,\n        steps_per_epoch=len(train_loader), pct_start=0.2\n    )\n\n    scaler = torch.amp.GradScaler() if device.type == 'cuda' else None\n\n    best_val_acc = 0.0\n    best_val_f1 = 0.0\n    no_improve = 0\n\n    print(\"\\nStarting training...\")\n    print(\"=\"*100)\n\n    # class FocalLoss(nn.Module):\n    #     def __init__(self, alpha=0.25, gamma=2.0, weight=None):\n    #         super().__init__()\n    #         self.alpha = alpha\n    #         self.gamma = gamma\n    #         self.weight = weight\n        \n    #     def forward(self, inputs, targets):\n    #         ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.weight)\n    #         pt = torch.exp(-ce_loss)\n    #         focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n    #         return focal_loss.mean()\n\n    for epoch in range(1, args.epochs + 1):\n        epoch_start = time.time()\n\n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, scheduler, device, epoch, scaler\n        )\n\n        val_loss, val_acc, _, val_targets, val_probs, precision, recall, f1, sensitivity, specificity = validate(\n            model, val_loader, criterion, device\n        )\n\n        try:\n            auc = roc_auc_score(val_targets, val_probs)\n        except Exception:\n            auc = 0.0\n\n        epoch_time = time.time() - epoch_start\n\n        print(f\"Epoch {epoch:2d}/{args.epochs} ({epoch_time:.1f}s)\")\n        print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n        print(f\"  Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%, AUC={auc:.4f}\")\n        print(f\"         Prec={precision:.3f}, Rec={recall:.3f}, F1={f1:.3f}\")\n        print(f\"         Sensitivity={sensitivity:.3f}, Specificity={specificity:.3f}\")\n\n        if val_acc > best_val_acc or (val_acc >= best_val_acc and f1 > best_val_f1):\n            best_val_acc = val_acc\n            best_val_f1 = f1\n            no_improve = 0\n            torch.save({\n                'epoch': epoch, 'model_state_dict': model.state_dict(),\n                'val_acc': val_acc, 'val_auc': auc, 'val_f1': f1,\n                'sensitivity': sensitivity, 'specificity': specificity\n            }, args.best_model_path)\n            print(f\"  ✓ Best! (Acc={val_acc:.2f}%, F1={f1:.3f}, Sens={sensitivity:.3f}, Spec={specificity:.3f})\")\n        else:\n            no_improve += 1\n            print(f\"  No improvement ({no_improve}/{args.patience})\")\n\n        print(\"-\"*100)\n\n        if no_improve >= args.patience:\n            print(f\"\\nEarly stop at epoch {epoch}\")\n            break\n\n    print(f\"\\n{'='*100}\")\n    print(f\"BEST - Accuracy: {best_val_acc:.2f}%, F1: {best_val_f1:.3f}\")\n    print(f\"{'='*100}\")\n\n\nif __name__ == '__main__':\n    kaggle_data = '/kaggle/input/vincent2/apnea-ecg-database-1.0.0'\n    colab_data = '/content/apnea-ecg/1.0.0'\n    if Path(kaggle_data).exists():\n        default_data_dir = kaggle_data\n        default_cache_dir = '/kaggle/working'\n        default_model_path = '/kaggle/working/best_model.pth'\n    elif Path(colab_data).exists():\n        default_data_dir = colab_data\n        default_cache_dir = '/content'\n        default_model_path = '/content/best_model.pth'\n    else:\n        default_data_dir = None\n        default_cache_dir = None\n        default_model_path = 'best_model.pth'\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data-dir', type=str, default=default_data_dir)\n    parser.add_argument('--cache-dir', type=str, default=default_cache_dir)\n    parser.add_argument('--segment-length', type=int, default=6000)\n    parser.add_argument('--stride', type=int, default=2000)  # 67% overlap - more training data\n    parser.add_argument('--batch-size', type=int, default=24)  # Smaller batch for better gradients\n    parser.add_argument('--epochs', type=int, default=100)\n    parser.add_argument('--lr', type=float, default=8e-5)\n    parser.add_argument('--weight-decay', type=float, default=0.01)\n    parser.add_argument('--d-model', type=int, default=256)\n    parser.add_argument('--n-blocks', type=int, default=10)\n    parser.add_argument('--dropout', type=float, default=0.2)\n    parser.add_argument('--train-split', type=float, default=0.8)\n    parser.add_argument('--patience', type=int, default=20)\n    parser.add_argument('--best-model-path', type=str, default=default_model_path)\n    parser.add_argument('--seed', type=int, default=42)\n\n    args, _ = parser.parse_known_args()\n\n    if args.data_dir is None:\n        raise SystemExit(\"ERROR: Dataset not found\")\n\n    print(\"=\"*100)\n    print(\"ENHANCED MODEL WITH R-R INTERVALS (Target: 90%+ Accuracy)\")\n    print(\"=\"*100)\n    print(f\"  Data:       {args.data_dir}\")\n    print(f\"  Segment:    {args.segment_length} samples (60s), stride={args.stride}\")\n    print(f\"  Features:   ECG + R-R Intervals + R-peak Amplitudes\")\n    print(f\"  Batch:      {args.batch_size}\")\n    print(f\"  Epochs:     {args.epochs}\")\n    print(f\"  Model:      d_model={args.d_model}, blocks={args.n_blocks}\")\n    print(f\"  Optimizer:  AdamW (lr={args.lr}, wd={args.weight_decay})\")\n    print(f\"  Loss:       Focal Loss (alpha=0.25, gamma=2.0)\")\n    print(\"=\"*100 + \"\\n\")\n\n    main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T08:25:54.458635Z","iopub.execute_input":"2025-11-29T08:25:54.459515Z","iopub.status.idle":"2025-11-29T09:54:23.671913Z","shell.execute_reply.started":"2025-11-29T08:25:54.459468Z","shell.execute_reply":"2025-11-29T09:54:23.670930Z"}},"outputs":[{"name":"stdout","text":"====================================================================================================\nENHANCED MODEL WITH R-R INTERVALS (Target: 90%+ Accuracy)\n====================================================================================================\n  Data:       /kaggle/input/vincent2/apnea-ecg-database-1.0.0\n  Segment:    6000 samples (60s), stride=2000\n  Features:   ECG + R-R Intervals + R-peak Amplitudes\n  Batch:      24\n  Epochs:     100\n  Model:      d_model=256, blocks=10\n  Optimizer:  AdamW (lr=8e-05, wd=0.01)\n  Loss:       Focal Loss (alpha=0.25, gamma=2.0)\n====================================================================================================\n\nFound 43 valid records\nTrain: 34, Val: 9\n\nProcessing 34 records for train (with R-R extraction)...\n  [34/34] a20....\nSaving cache to /kaggle/working/apnea_enhanced_train_6000_2000.pt\nTrain: 50104 segments, Class: Counter({0: 31658, 1: 18446})\nProcessing 9 records for val (with R-R extraction)...\n  [9/9] a01....\nSaving cache to /kaggle/working/apnea_enhanced_val_6000_2000.pt\nVal: 12933 segments, Class: Counter({0: 7032, 1: 5901})\nDevice: cuda\nGPU: Tesla P100-PCIE-16GB\nParameters: 3,170,955\n\nClass weights: tensor([0.7913, 1.3581], device='cuda:0')\n\nStarting training...\n====================================================================================================\n  Ep 1 [2088/2088] Loss: 0.1182 Acc: 45.10% (25.3 b/s, ETA: 0s)))\nEpoch  1/100 (89.0s)\n  Train: Loss=0.1182, Acc=45.10%\n  Val:   Loss=0.0480, Acc=58.99%, AUC=0.7757\n         Prec=0.529, Rec=0.922, F1=0.672\n         Sensitivity=0.922, Specificity=0.311\n  ✓ Best! (Acc=58.99%, F1=0.672, Sens=0.922, Spec=0.311)\n----------------------------------------------------------------------------------------------------\n  Ep 2 [2088/2088] Loss: 0.0652 Acc: 58.19% (26.1 b/s, ETA: 0s))\nEpoch  2/100 (86.6s)\n  Train: Loss=0.0652, Acc=58.19%\n  Val:   Loss=0.0403, Acc=69.52%, AUC=0.8208\n         Prec=0.615, Rec=0.885, F1=0.726\n         Sensitivity=0.885, Specificity=0.536\n  ✓ Best! (Acc=69.52%, F1=0.726, Sens=0.885, Spec=0.536)\n----------------------------------------------------------------------------------------------------\n  Ep 3 [2088/2088] Loss: 0.0509 Acc: 67.95% (26.0 b/s, ETA: 0s))\nEpoch  3/100 (87.0s)\n  Train: Loss=0.0509, Acc=67.95%\n  Val:   Loss=0.0366, Acc=74.99%, AUC=0.8522\n         Prec=0.678, Rec=0.860, F1=0.758\n         Sensitivity=0.860, Specificity=0.658\n  ✓ Best! (Acc=74.99%, F1=0.758, Sens=0.860, Spec=0.658)\n----------------------------------------------------------------------------------------------------\n  Ep 4 [2088/2088] Loss: 0.0409 Acc: 75.02% (25.5 b/s, ETA: 0s))\nEpoch  4/100 (88.3s)\n  Train: Loss=0.0409, Acc=75.02%\n  Val:   Loss=0.0333, Acc=75.86%, AUC=0.8777\n         Prec=0.676, Rec=0.903, F1=0.773\n         Sensitivity=0.903, Specificity=0.638\n  ✓ Best! (Acc=75.86%, F1=0.773, Sens=0.903, Spec=0.638)\n----------------------------------------------------------------------------------------------------\n  Ep 5 [2088/2088] Loss: 0.0330 Acc: 79.68% (26.1 b/s, ETA: 0s))\nEpoch  5/100 (86.3s)\n  Train: Loss=0.0330, Acc=79.68%\n  Val:   Loss=0.0348, Acc=77.80%, AUC=0.8776\n         Prec=0.719, Rec=0.843, F1=0.776\n         Sensitivity=0.843, Specificity=0.723\n  ✓ Best! (Acc=77.80%, F1=0.776, Sens=0.843, Spec=0.723)\n----------------------------------------------------------------------------------------------------\n  Ep 6 [2088/2088] Loss: 0.0274 Acc: 82.64% (26.3 b/s, ETA: 0s))\nEpoch  6/100 (86.0s)\n  Train: Loss=0.0274, Acc=82.64%\n  Val:   Loss=0.0395, Acc=74.62%, AUC=0.8516\n         Prec=0.682, Rec=0.832, F1=0.750\n         Sensitivity=0.832, Specificity=0.674\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 7 [2088/2088] Loss: 0.0239 Acc: 84.61% (26.3 b/s, ETA: 0s))\nEpoch  7/100 (85.8s)\n  Train: Loss=0.0239, Acc=84.61%\n  Val:   Loss=0.0419, Acc=78.22%, AUC=0.8669\n         Prec=0.761, Rec=0.762, F1=0.761\n         Sensitivity=0.762, Specificity=0.799\n  ✓ Best! (Acc=78.22%, F1=0.761, Sens=0.762, Spec=0.799)\n----------------------------------------------------------------------------------------------------\n  Ep 8 [2088/2088] Loss: 0.0212 Acc: 85.81% (25.8 b/s, ETA: 0s))\nEpoch  8/100 (87.2s)\n  Train: Loss=0.0212, Acc=85.81%\n  Val:   Loss=0.0361, Acc=79.31%, AUC=0.8836\n         Prec=0.747, Rec=0.826, F1=0.785\n         Sensitivity=0.826, Specificity=0.766\n  ✓ Best! (Acc=79.31%, F1=0.785, Sens=0.826, Spec=0.766)\n----------------------------------------------------------------------------------------------------\n  Ep 9 [2088/2088] Loss: 0.0194 Acc: 86.71% (25.4 b/s, ETA: 0s))\nEpoch  9/100 (88.7s)\n  Train: Loss=0.0194, Acc=86.71%\n  Val:   Loss=0.0311, Acc=81.38%, AUC=0.9031\n         Prec=0.770, Rec=0.844, F1=0.805\n         Sensitivity=0.844, Specificity=0.788\n  ✓ Best! (Acc=81.38%, F1=0.805, Sens=0.844, Spec=0.788)\n----------------------------------------------------------------------------------------------------\n  Ep 10 [2088/2088] Loss: 0.0179 Acc: 87.56% (25.7 b/s, ETA: 0s))\nEpoch 10/100 (87.7s)\n  Train: Loss=0.0179, Acc=87.56%\n  Val:   Loss=0.0287, Acc=78.43%, AUC=0.8973\n         Prec=0.702, Rec=0.915, F1=0.795\n         Sensitivity=0.915, Specificity=0.674\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 11 [2088/2088] Loss: 0.0165 Acc: 88.35% (25.8 b/s, ETA: 0s))\nEpoch 11/100 (87.3s)\n  Train: Loss=0.0165, Acc=88.35%\n  Val:   Loss=0.0335, Acc=80.59%, AUC=0.8921\n         Prec=0.768, Rec=0.823, F1=0.795\n         Sensitivity=0.823, Specificity=0.792\n  No improvement (2/20)\n----------------------------------------------------------------------------------------------------\n  Ep 12 [2088/2088] Loss: 0.0159 Acc: 89.08% (25.8 b/s, ETA: 0s))\nEpoch 12/100 (87.4s)\n  Train: Loss=0.0159, Acc=89.08%\n  Val:   Loss=0.0284, Acc=79.53%, AUC=0.9039\n         Prec=0.721, Rec=0.899, F1=0.800\n         Sensitivity=0.899, Specificity=0.708\n  No improvement (3/20)\n----------------------------------------------------------------------------------------------------\n  Ep 13 [2088/2088] Loss: 0.0150 Acc: 89.49% (25.9 b/s, ETA: 0s))\nEpoch 13/100 (87.1s)\n  Train: Loss=0.0150, Acc=89.49%\n  Val:   Loss=0.0510, Acc=77.14%, AUC=0.8502\n         Prec=0.739, Rec=0.773, F1=0.755\n         Sensitivity=0.773, Specificity=0.770\n  No improvement (4/20)\n----------------------------------------------------------------------------------------------------\n  Ep 14 [2088/2088] Loss: 0.0137 Acc: 90.39% (25.5 b/s, ETA: 0s))\nEpoch 14/100 (88.4s)\n  Train: Loss=0.0137, Acc=90.39%\n  Val:   Loss=0.0331, Acc=78.61%, AUC=0.8843\n         Prec=0.722, Rec=0.865, F1=0.787\n         Sensitivity=0.865, Specificity=0.720\n  No improvement (5/20)\n----------------------------------------------------------------------------------------------------\n  Ep 15 [2088/2088] Loss: 0.0132 Acc: 90.78% (25.5 b/s, ETA: 0s))\nEpoch 15/100 (88.6s)\n  Train: Loss=0.0132, Acc=90.78%\n  Val:   Loss=0.0420, Acc=79.36%, AUC=0.8762\n         Prec=0.752, Rec=0.817, F1=0.783\n         Sensitivity=0.817, Specificity=0.774\n  No improvement (6/20)\n----------------------------------------------------------------------------------------------------\n  Ep 16 [2088/2088] Loss: 0.0127 Acc: 91.07% (26.1 b/s, ETA: 0s))\nEpoch 16/100 (86.5s)\n  Train: Loss=0.0127, Acc=91.07%\n  Val:   Loss=0.0498, Acc=80.09%, AUC=0.8850\n         Prec=0.820, Rec=0.722, F1=0.768\n         Sensitivity=0.722, Specificity=0.867\n  No improvement (7/20)\n----------------------------------------------------------------------------------------------------\n  Ep 17 [2088/2088] Loss: 0.0120 Acc: 91.70% (25.7 b/s, ETA: 0s))\nEpoch 17/100 (87.5s)\n  Train: Loss=0.0120, Acc=91.70%\n  Val:   Loss=0.0322, Acc=79.00%, AUC=0.8869\n         Prec=0.722, Rec=0.879, F1=0.792\n         Sensitivity=0.879, Specificity=0.716\n  No improvement (8/20)\n----------------------------------------------------------------------------------------------------\n  Ep 18 [2088/2088] Loss: 0.0115 Acc: 92.23% (26.0 b/s, ETA: 0s))\nEpoch 18/100 (86.6s)\n  Train: Loss=0.0115, Acc=92.23%\n  Val:   Loss=0.0554, Acc=80.25%, AUC=0.8898\n         Prec=0.804, Rec=0.749, F1=0.776\n         Sensitivity=0.749, Specificity=0.847\n  No improvement (9/20)\n----------------------------------------------------------------------------------------------------\n  Ep 19 [2088/2088] Loss: 0.0109 Acc: 92.45% (26.0 b/s, ETA: 0s))\nEpoch 19/100 (86.7s)\n  Train: Loss=0.0109, Acc=92.45%\n  Val:   Loss=0.0440, Acc=81.92%, AUC=0.9043\n         Prec=0.817, Rec=0.778, F1=0.797\n         Sensitivity=0.778, Specificity=0.854\n  ✓ Best! (Acc=81.92%, F1=0.797, Sens=0.778, Spec=0.854)\n----------------------------------------------------------------------------------------------------\n  Ep 20 [2088/2088] Loss: 0.0100 Acc: 93.05% (25.7 b/s, ETA: 0s))\nEpoch 20/100 (87.8s)\n  Train: Loss=0.0100, Acc=93.05%\n  Val:   Loss=0.0713, Acc=80.41%, AUC=0.8873\n         Prec=0.838, Rec=0.707, F1=0.767\n         Sensitivity=0.707, Specificity=0.886\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 21 [2088/2088] Loss: 0.0093 Acc: 93.51% (25.4 b/s, ETA: 0s))\nEpoch 21/100 (88.6s)\n  Train: Loss=0.0093, Acc=93.51%\n  Val:   Loss=0.0490, Acc=81.64%, AUC=0.9050\n         Prec=0.823, Rec=0.762, F1=0.791\n         Sensitivity=0.762, Specificity=0.862\n  No improvement (2/20)\n----------------------------------------------------------------------------------------------------\n  Ep 22 [2088/2088] Loss: 0.0089 Acc: 93.87% (25.9 b/s, ETA: 0s))\nEpoch 22/100 (87.0s)\n  Train: Loss=0.0089, Acc=93.87%\n  Val:   Loss=0.0445, Acc=82.75%, AUC=0.9096\n         Prec=0.805, Rec=0.821, F1=0.813\n         Sensitivity=0.821, Specificity=0.833\n  ✓ Best! (Acc=82.75%, F1=0.813, Sens=0.821, Spec=0.833)\n----------------------------------------------------------------------------------------------------\n  Ep 23 [2088/2088] Loss: 0.0083 Acc: 94.36% (26.0 b/s, ETA: 0s))\nEpoch 23/100 (86.4s)\n  Train: Loss=0.0083, Acc=94.36%\n  Val:   Loss=0.0483, Acc=81.34%, AUC=0.8992\n         Prec=0.803, Rec=0.784, F1=0.793\n         Sensitivity=0.784, Specificity=0.838\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 24 [2088/2088] Loss: 0.0078 Acc: 94.63% (25.1 b/s, ETA: 0s))\nEpoch 24/100 (89.6s)\n  Train: Loss=0.0078, Acc=94.63%\n  Val:   Loss=0.0577, Acc=79.70%, AUC=0.8786\n         Prec=0.778, Rec=0.777, F1=0.777\n         Sensitivity=0.777, Specificity=0.814\n  No improvement (2/20)\n----------------------------------------------------------------------------------------------------\n  Ep 25 [2088/2088] Loss: 0.0074 Acc: 94.86% (26.3 b/s, ETA: 0s))\nEpoch 25/100 (85.6s)\n  Train: Loss=0.0074, Acc=94.86%\n  Val:   Loss=0.0705, Acc=78.94%, AUC=0.8761\n         Prec=0.788, Rec=0.737, F1=0.761\n         Sensitivity=0.737, Specificity=0.833\n  No improvement (3/20)\n----------------------------------------------------------------------------------------------------\n  Ep 26 [2088/2088] Loss: 0.0071 Acc: 95.23% (26.2 b/s, ETA: 0s))\nEpoch 26/100 (86.0s)\n  Train: Loss=0.0071, Acc=95.23%\n  Val:   Loss=0.0620, Acc=80.07%, AUC=0.8832\n         Prec=0.786, Rec=0.775, F1=0.780\n         Sensitivity=0.775, Specificity=0.823\n  No improvement (4/20)\n----------------------------------------------------------------------------------------------------\n  Ep 27 [2088/2088] Loss: 0.0065 Acc: 95.66% (25.9 b/s, ETA: 0s))\nEpoch 27/100 (87.4s)\n  Train: Loss=0.0065, Acc=95.66%\n  Val:   Loss=0.0616, Acc=81.31%, AUC=0.8902\n         Prec=0.790, Rec=0.805, F1=0.797\n         Sensitivity=0.805, Specificity=0.820\n  No improvement (5/20)\n----------------------------------------------------------------------------------------------------\n  Ep 28 [2088/2088] Loss: 0.0061 Acc: 96.02% (26.2 b/s, ETA: 0s))\nEpoch 28/100 (86.2s)\n  Train: Loss=0.0061, Acc=96.02%\n  Val:   Loss=0.0873, Acc=79.77%, AUC=0.8715\n         Prec=0.792, Rec=0.755, F1=0.773\n         Sensitivity=0.755, Specificity=0.834\n  No improvement (6/20)\n----------------------------------------------------------------------------------------------------\n  Ep 29 [2088/2088] Loss: 0.0058 Acc: 96.21% (25.5 b/s, ETA: 0s))\nEpoch 29/100 (88.3s)\n  Train: Loss=0.0058, Acc=96.21%\n  Val:   Loss=0.0672, Acc=79.89%, AUC=0.8787\n         Prec=0.774, Rec=0.790, F1=0.782\n         Sensitivity=0.790, Specificity=0.806\n  No improvement (7/20)\n----------------------------------------------------------------------------------------------------\n  Ep 30 [2088/2088] Loss: 0.0055 Acc: 96.50% (26.4 b/s, ETA: 0s))\nEpoch 30/100 (85.5s)\n  Train: Loss=0.0055, Acc=96.50%\n  Val:   Loss=0.0546, Acc=81.39%, AUC=0.8972\n         Prec=0.765, Rec=0.854, F1=0.807\n         Sensitivity=0.854, Specificity=0.780\n  No improvement (8/20)\n----------------------------------------------------------------------------------------------------\n  Ep 31 [2088/2088] Loss: 0.0050 Acc: 96.72% (26.3 b/s, ETA: 0s))\nEpoch 31/100 (85.9s)\n  Train: Loss=0.0050, Acc=96.72%\n  Val:   Loss=0.0872, Acc=82.50%, AUC=0.8990\n         Prec=0.829, Rec=0.776, F1=0.802\n         Sensitivity=0.776, Specificity=0.866\n  No improvement (9/20)\n----------------------------------------------------------------------------------------------------\n  Ep 32 [2088/2088] Loss: 0.0048 Acc: 96.91% (25.9 b/s, ETA: 0s))\nEpoch 32/100 (87.0s)\n  Train: Loss=0.0048, Acc=96.91%\n  Val:   Loss=0.0673, Acc=81.61%, AUC=0.8960\n         Prec=0.786, Rec=0.821, F1=0.803\n         Sensitivity=0.821, Specificity=0.812\n  No improvement (10/20)\n----------------------------------------------------------------------------------------------------\n  Ep 33 [2088/2088] Loss: 0.0047 Acc: 97.04% (26.2 b/s, ETA: 0s))\nEpoch 33/100 (86.0s)\n  Train: Loss=0.0047, Acc=97.04%\n  Val:   Loss=0.0762, Acc=80.18%, AUC=0.8880\n         Prec=0.809, Rec=0.740, F1=0.773\n         Sensitivity=0.740, Specificity=0.854\n  No improvement (11/20)\n----------------------------------------------------------------------------------------------------\n  Ep 34 [2088/2088] Loss: 0.0044 Acc: 97.21% (26.3 b/s, ETA: 0s))\nEpoch 34/100 (86.0s)\n  Train: Loss=0.0044, Acc=97.21%\n  Val:   Loss=0.0898, Acc=77.99%, AUC=0.8684\n         Prec=0.748, Rec=0.782, F1=0.764\n         Sensitivity=0.782, Specificity=0.779\n  No improvement (12/20)\n----------------------------------------------------------------------------------------------------\n  Ep 35 [2088/2088] Loss: 0.0041 Acc: 97.44% (26.2 b/s, ETA: 0s))\nEpoch 35/100 (86.2s)\n  Train: Loss=0.0041, Acc=97.44%\n  Val:   Loss=0.1201, Acc=78.74%, AUC=0.8692\n         Prec=0.836, Rec=0.664, F1=0.740\n         Sensitivity=0.664, Specificity=0.891\n  No improvement (13/20)\n----------------------------------------------------------------------------------------------------\n  Ep 36 [2088/2088] Loss: 0.0039 Acc: 97.63% (26.3 b/s, ETA: 0s))\nEpoch 36/100 (85.5s)\n  Train: Loss=0.0039, Acc=97.63%\n  Val:   Loss=0.0666, Acc=81.24%, AUC=0.8940\n         Prec=0.778, Rec=0.823, F1=0.800\n         Sensitivity=0.823, Specificity=0.803\n  No improvement (14/20)\n----------------------------------------------------------------------------------------------------\n  Ep 37 [2088/2088] Loss: 0.0037 Acc: 97.73% (26.4 b/s, ETA: 0s))\nEpoch 37/100 (85.6s)\n  Train: Loss=0.0037, Acc=97.73%\n  Val:   Loss=0.0647, Acc=81.10%, AUC=0.8942\n         Prec=0.799, Rec=0.783, F1=0.791\n         Sensitivity=0.783, Specificity=0.834\n  No improvement (15/20)\n----------------------------------------------------------------------------------------------------\n  Ep 38 [2088/2088] Loss: 0.0034 Acc: 97.86% (25.3 b/s, ETA: 0s))\nEpoch 38/100 (88.7s)\n  Train: Loss=0.0034, Acc=97.86%\n  Val:   Loss=0.0613, Acc=83.92%, AUC=0.9183\n         Prec=0.829, Rec=0.816, F1=0.822\n         Sensitivity=0.816, Specificity=0.859\n  ✓ Best! (Acc=83.92%, F1=0.822, Sens=0.816, Spec=0.859)\n----------------------------------------------------------------------------------------------------\n  Ep 39 [2088/2088] Loss: 0.0033 Acc: 97.96% (25.4 b/s, ETA: 0s))\nEpoch 39/100 (88.5s)\n  Train: Loss=0.0033, Acc=97.96%\n  Val:   Loss=0.1062, Acc=77.46%, AUC=0.8615\n         Prec=0.763, Rec=0.734, F1=0.748\n         Sensitivity=0.734, Specificity=0.809\n  No improvement (1/20)\n----------------------------------------------------------------------------------------------------\n  Ep 40 [2088/2088] Loss: 0.0032 Acc: 98.12% (25.7 b/s, ETA: 0s))\nEpoch 40/100 (87.6s)\n  Train: Loss=0.0032, Acc=98.12%\n  Val:   Loss=0.0838, Acc=82.53%, AUC=0.9060\n         Prec=0.821, Rec=0.789, F1=0.805\n         Sensitivity=0.789, Specificity=0.856\n  No improvement (2/20)\n----------------------------------------------------------------------------------------------------\n  Ep 41 [2088/2088] Loss: 0.0030 Acc: 98.11% (26.1 b/s, ETA: 0s))\nEpoch 41/100 (86.1s)\n  Train: Loss=0.0030, Acc=98.11%\n  Val:   Loss=0.0791, Acc=80.43%, AUC=0.8959\n         Prec=0.820, Rec=0.731, F1=0.773\n         Sensitivity=0.731, Specificity=0.865\n  No improvement (3/20)\n----------------------------------------------------------------------------------------------------\n  Ep 42 [2088/2088] Loss: 0.0028 Acc: 98.27% (26.4 b/s, ETA: 0s))\nEpoch 42/100 (85.3s)\n  Train: Loss=0.0028, Acc=98.27%\n  Val:   Loss=0.0994, Acc=80.11%, AUC=0.8973\n         Prec=0.854, Rec=0.681, F1=0.757\n         Sensitivity=0.681, Specificity=0.902\n  No improvement (4/20)\n----------------------------------------------------------------------------------------------------\n  Ep 43 [2088/2088] Loss: 0.0025 Acc: 98.47% (25.9 b/s, ETA: 0s))\nEpoch 43/100 (87.0s)\n  Train: Loss=0.0025, Acc=98.47%\n  Val:   Loss=0.0757, Acc=83.63%, AUC=0.9093\n         Prec=0.825, Rec=0.814, F1=0.819\n         Sensitivity=0.814, Specificity=0.855\n  No improvement (5/20)\n----------------------------------------------------------------------------------------------------\n  Ep 44 [2088/2088] Loss: 0.0025 Acc: 98.49% (26.1 b/s, ETA: 0s))\nEpoch 44/100 (86.4s)\n  Train: Loss=0.0025, Acc=98.49%\n  Val:   Loss=0.0876, Acc=82.28%, AUC=0.9036\n         Prec=0.826, Rec=0.775, F1=0.800\n         Sensitivity=0.775, Specificity=0.863\n  No improvement (6/20)\n----------------------------------------------------------------------------------------------------\n  Ep 45 [2088/2088] Loss: 0.0024 Acc: 98.60% (26.1 b/s, ETA: 0s))\nEpoch 45/100 (86.4s)\n  Train: Loss=0.0024, Acc=98.60%\n  Val:   Loss=0.1113, Acc=80.48%, AUC=0.8878\n         Prec=0.817, Rec=0.737, F1=0.775\n         Sensitivity=0.737, Specificity=0.862\n  No improvement (7/20)\n----------------------------------------------------------------------------------------------------\n  Ep 46 [2088/2088] Loss: 0.0022 Acc: 98.74% (26.5 b/s, ETA: 0s))\nEpoch 46/100 (85.0s)\n  Train: Loss=0.0022, Acc=98.74%\n  Val:   Loss=0.0955, Acc=81.56%, AUC=0.8979\n         Prec=0.823, Rec=0.759, F1=0.790\n         Sensitivity=0.759, Specificity=0.863\n  No improvement (8/20)\n----------------------------------------------------------------------------------------------------\n  Ep 47 [2088/2088] Loss: 0.0022 Acc: 98.70% (26.4 b/s, ETA: 0s))\nEpoch 47/100 (85.6s)\n  Train: Loss=0.0022, Acc=98.70%\n  Val:   Loss=0.0999, Acc=80.31%, AUC=0.8850\n         Prec=0.796, Rec=0.765, F1=0.780\n         Sensitivity=0.765, Specificity=0.835\n  No improvement (9/20)\n----------------------------------------------------------------------------------------------------\n  Ep 48 [2088/2088] Loss: 0.0021 Acc: 98.81% (26.0 b/s, ETA: 0s))\nEpoch 48/100 (86.7s)\n  Train: Loss=0.0021, Acc=98.81%\n  Val:   Loss=0.1093, Acc=80.24%, AUC=0.8916\n         Prec=0.834, Rec=0.707, F1=0.766\n         Sensitivity=0.707, Specificity=0.882\n  No improvement (10/20)\n----------------------------------------------------------------------------------------------------\n  Ep 49 [2088/2088] Loss: 0.0019 Acc: 98.85% (25.9 b/s, ETA: 0s))\nEpoch 49/100 (87.2s)\n  Train: Loss=0.0019, Acc=98.85%\n  Val:   Loss=0.1085, Acc=80.04%, AUC=0.8853\n         Prec=0.837, Rec=0.698, F1=0.761\n         Sensitivity=0.698, Specificity=0.886\n  No improvement (11/20)\n----------------------------------------------------------------------------------------------------\n  Ep 50 [2088/2088] Loss: 0.0019 Acc: 98.85% (25.9 b/s, ETA: 0s))\nEpoch 50/100 (87.2s)\n  Train: Loss=0.0019, Acc=98.85%\n  Val:   Loss=0.1038, Acc=80.48%, AUC=0.8864\n         Prec=0.810, Rec=0.748, F1=0.778\n         Sensitivity=0.748, Specificity=0.852\n  No improvement (12/20)\n----------------------------------------------------------------------------------------------------\n  Ep 51 [2088/2088] Loss: 0.0017 Acc: 98.99% (26.0 b/s, ETA: 0s))\nEpoch 51/100 (87.0s)\n  Train: Loss=0.0017, Acc=98.99%\n  Val:   Loss=0.0985, Acc=80.42%, AUC=0.8816\n         Prec=0.788, Rec=0.782, F1=0.785\n         Sensitivity=0.782, Specificity=0.823\n  No improvement (13/20)\n----------------------------------------------------------------------------------------------------\n  Ep 52 [2088/2088] Loss: 0.0016 Acc: 99.06% (26.2 b/s, ETA: 0s))\nEpoch 52/100 (86.1s)\n  Train: Loss=0.0016, Acc=99.06%\n  Val:   Loss=0.1112, Acc=82.13%, AUC=0.9081\n         Prec=0.858, Rec=0.729, F1=0.788\n         Sensitivity=0.729, Specificity=0.899\n  No improvement (14/20)\n----------------------------------------------------------------------------------------------------\n  Ep 53 [2088/2088] Loss: 0.0016 Acc: 99.11% (26.0 b/s, ETA: 0s))\nEpoch 53/100 (86.6s)\n  Train: Loss=0.0016, Acc=99.11%\n  Val:   Loss=0.1008, Acc=80.31%, AUC=0.8921\n         Prec=0.800, Rec=0.757, F1=0.778\n         Sensitivity=0.757, Specificity=0.841\n  No improvement (15/20)\n----------------------------------------------------------------------------------------------------\n  Ep 54 [2088/2088] Loss: 0.0016 Acc: 99.12% (25.9 b/s, ETA: 0s))\nEpoch 54/100 (86.7s)\n  Train: Loss=0.0016, Acc=99.12%\n  Val:   Loss=0.1166, Acc=80.38%, AUC=0.8870\n         Prec=0.834, Rec=0.712, F1=0.768\n         Sensitivity=0.712, Specificity=0.881\n  No improvement (16/20)\n----------------------------------------------------------------------------------------------------\n  Ep 55 [2088/2088] Loss: 0.0014 Acc: 99.23% (25.4 b/s, ETA: 0s))\nEpoch 55/100 (88.8s)\n  Train: Loss=0.0014, Acc=99.23%\n  Val:   Loss=0.1170, Acc=81.20%, AUC=0.9005\n         Prec=0.855, Rec=0.708, F1=0.775\n         Sensitivity=0.708, Specificity=0.899\n  No improvement (17/20)\n----------------------------------------------------------------------------------------------------\n  Ep 56 [2088/2088] Loss: 0.0013 Acc: 99.26% (25.4 b/s, ETA: 0s))\nEpoch 56/100 (88.6s)\n  Train: Loss=0.0013, Acc=99.26%\n  Val:   Loss=0.1015, Acc=81.25%, AUC=0.8937\n         Prec=0.816, Rec=0.761, F1=0.787\n         Sensitivity=0.761, Specificity=0.856\n  No improvement (18/20)\n----------------------------------------------------------------------------------------------------\n  Ep 57 [2088/2088] Loss: 0.0013 Acc: 99.26% (25.6 b/s, ETA: 0s))\nEpoch 57/100 (88.1s)\n  Train: Loss=0.0013, Acc=99.26%\n  Val:   Loss=0.1004, Acc=83.14%, AUC=0.9108\n         Prec=0.853, Rec=0.762, F1=0.805\n         Sensitivity=0.762, Specificity=0.890\n  No improvement (19/20)\n----------------------------------------------------------------------------------------------------\n  Ep 58 [2088/2088] Loss: 0.0012 Acc: 99.36% (25.9 b/s, ETA: 0s))\nEpoch 58/100 (86.9s)\n  Train: Loss=0.0012, Acc=99.36%\n  Val:   Loss=0.1013, Acc=82.37%, AUC=0.9017\n         Prec=0.833, Rec=0.768, F1=0.799\n         Sensitivity=0.768, Specificity=0.871\n  No improvement (20/20)\n----------------------------------------------------------------------------------------------------\n\nEarly stop at epoch 58\n\n====================================================================================================\nBEST - Accuracy: 83.92%, F1: 0.822\n====================================================================================================\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}